{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NTB_vojBoM3V"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5a60791d9ad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# spacy for lemmatization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import KFold, cross_val_score, RepeatedKFold\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import unicodedata\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling  import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "stopwords = set(stopwords.words('english'))\n",
    "import glob\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTgAzAN3oM3a"
   },
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "vocab_size = 10000\n",
    "embedding_dim = 64\n",
    "max_length = 200\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSkBi7ftoM3b"
   },
   "outputs": [],
   "source": [
    "# stopwords\n",
    "stop_words = stopwords\n",
    "extra_stopwords = ['the','said','say','shares','person','useful','govtech','cio','yonhap','size','tackle','right','day','tried','tested','make','sure','used','help','yesterday','today','tomorrow','percent','per', 'cent','could','many','add','use','need','goods','million','thousand','company','retailers','saw','see','new','like','today','tomorrow','guide',\n",
    " 'people','want','yet','way','time','back','whether','if','yes','older','noted','went','told','tell','younger','another','worth','noting','well','called','named','never','lee','quah','ong','ng','lim','tan','shared','says','say','said','cio', 'cios','month','top','world','zero','one','two','three','four','five','six','seven','eight','nine','ten','january', 'february', 'march', 'april', 'may', 'june', 'july',\n",
    "              'august', 'september', 'october', 'november', 'december','month','months','years','year','near','also','would','able']\n",
    "for word in extra_stopwords:\n",
    "    stop_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmMFkZHPoM3c",
    "outputId": "844b910b-bee8-46fb-cb05-78b1e054351c"
   },
   "outputs": [],
   "source": [
    "path2 ='../data'\n",
    "filenames = glob.glob(path2 + \"/*.csv\")\n",
    "\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "#     df['source'] =re.search('\\/([A-Za-z]+)[0-9]?\\.csv',filename)[1]\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all data into one DataFrame\n",
    "big_frame = pd.concat(dfs, ignore_index=True)\n",
    "big_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ud2UwcIjoM3d"
   },
   "outputs": [],
   "source": [
    "def thorough_cleaning(text):\n",
    "    text = ''.join(text)\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "    text = re.sub(\"[^0-9a-zA-Z]\",\" \", text)\n",
    "    text = re.sub('[0-9]{2,4}', ' ', text)\n",
    "    article_text = re.sub(r'\\s+', ' ', text)\n",
    "    article_text = ' '.join([w.lower() for w in article_text.split() if len(w) > 1 and w.lower() not in stop_words])\n",
    "    article_text = unicodedata.normalize(\"NFKD\", article_text)\n",
    "    return article_text\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text)\n",
    "\n",
    "def process_data(df):\n",
    "    #most articles append the header to the csv so cleaning is required\n",
    "#     df = df[(df['date'] != 'date') & (df['category'] != 'category')& (df['category'] != 'nation')&(df['date'] != None)]\n",
    "    #format dates\n",
    "    df['date'] = pd.to_datetime(df['date'], format = '%d/%m/%Y')\n",
    "    #remove duplicates and nan\n",
    "    df.drop_duplicates(subset =['title', 'category'], inplace=True)\n",
    "    df.dropna(axis =0, subset =['text', 'title'], inplace=True)\n",
    "    #cleaning the text to convert to lists\n",
    "    df['clean_text'] = df['text'].apply(lambda x:thorough_cleaning(x))\n",
    "    #word count of text\n",
    "    df['word_count'] = df['text'].apply(lambda x:count_words(x))\n",
    "    #remove those which are too short\n",
    "    df2 = df[df.word_count >=50]\n",
    "    return df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYNl9xv_oM3e",
    "outputId": "3afaadd7-0090-4f9f-eecf-4698eb1e6ce0"
   },
   "outputs": [],
   "source": [
    "# remove all those without category\n",
    "# data =df[~df.category.isna()]\n",
    "# data.head()\n",
    "df = process_data(big_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoBlh1w6oM3g",
    "outputId": "ee2111ba-ac78-4a11-c554-7f63a1b2fffc"
   },
   "outputs": [],
   "source": [
    "mapping ={v:i for i, v in enumerate(df.category.unique())}\n",
    "reverse_map = {str(i):v for i,v in  enumerate(df.category.unique())}\n",
    "df['labels'] = df.category.map(mapping)\n",
    "# catmap ={'digital-transformation':'digitalisation', 'analytics/ai/ml':'analytics', 'business':'business',\n",
    "#        'cybersecurity':'cybersecurity', 'apps/development/platforms':'apps'}\n",
    "# data.labels = data.new_cat.map(catmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df[['title','text','category','url','blurp']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count = {str(c): 0 for c in mapping.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count = {str(c): 0 for c in mapping.keys()}\n",
    "for l in df.labels:\n",
    "#     print(type(l))\n",
    "    cat_count[reverse_map[str(l)]] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(df[['title','clean_text']], df.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled['labels']=y_resampled\n",
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.pivot_table(df[['title','clean_text','labels']], index=['title','clean_text'], columns=['labels'], aggfunc=len, fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    algo=dict()\n",
    "    \n",
    "    for model in [('logreg',MultiOutputClassifier(estimator=LogisticRegression(multi_class='multinomial'))),('dt',DecisionTreeClassifier()),('rf',RandomForestClassifier()),('rf2',RandomForestClassifier(n_estimators=1000)),\n",
    "                  ('rf3',RandomForestClassifier(n_estimators=2000)),('gb',MultiOutputClassifier(estimator=GradientBoostingClassifier())),('knn',KNeighborsClassifier(n_neighbors=2)),('knn2',KNeighborsClassifier(n_neighbors=4))]:\n",
    "        steps = [ ('tfidf', TfidfVectorizer(stop_words=stop_words)), ('m', model[1])]\n",
    "        models[model[0]] = Pipeline(steps=steps)\n",
    "#         print(model[0], algo)\n",
    "    \n",
    "    return models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y,scoring_metric = 'accuracy'):\n",
    "    cv = KFold(n_splits=10, random_state=1, shuffle = True)\n",
    "    scores = cross_val_score(model, X, y, scoring=scoring_metric, cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    " \n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "scores = evaluate_model(models['logreg'], data.clean_text, data[[0,1,2,3,4]],'accuracy')\n",
    "roc_auc = evaluate_model(models['logreg'], data.clean_text, data[[0,1,2,3,4]], 'roc_auc')\n",
    "results.append(scores)\n",
    "\n",
    "print('logreg  accuracy: %.4f roc_auc:%.4f (%.4f)' % ( np.mean(scores),np.mean(roc_auc), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "scores = evaluate_model(models['rf'], data.clean_text, data[[0,1,2,3,4]],'accuracy')\n",
    "roc_auc = evaluate_model(models['rf'], data.clean_text, data[[0,1,2,3,4]], 'roc_auc')\n",
    "results.append(scores)\n",
    "\n",
    "print('random forest  accuracy: %.4f roc_auc:%.4f (%.4f)' % ( np.mean(scores),np.mean(roc_auc), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "scores = evaluate_model(models['rf2'], data.clean_text, data[[0,1,2,3,4]],'accuracy')\n",
    "roc_auc = evaluate_model(models['rf2'], data.clean_text, data[[0,1,2,3,4]], 'roc_auc')\n",
    "results.append(scores)\n",
    "\n",
    "print('random forest  accuracy: %.4f roc_auc:%.4f (%.4f)' % ( np.mean(scores),np.mean(roc_auc), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "scores = evaluate_model(models['rf3'], data.clean_text, data[[0,1,2,3,4]],'accuracy')\n",
    "roc_auc = evaluate_model(models['rf3'], data.clean_text, data[[0,1,2,3,4]], 'roc_auc')\n",
    "results.append(scores)\n",
    "\n",
    "print('random forest  accuracy: %.4f roc_auc:%.4f (%.4f)' % ( np.mean(scores),np.mean(roc_auc), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "scores = evaluate_model(models['dt'], data.clean_text, data[[0,1,2,3,4]],'accuracy')\n",
    "roc_auc = evaluate_model(models['dt'], data.clean_text, data[[0,1,2,3,4]], 'roc_auc')\n",
    "results.append(scores)\n",
    "\n",
    "print('decision tree  accuracy: %.4f roc_auc:%.4f (%.4f)' % ( np.mean(scores),np.mean(roc_auc), np.std(scores)))\n",
    "# plot model performance for comparison\n",
    "# plt.boxplot(results, labels=names, showmeans=True)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluate_model(models['knn'], data.clean_text, data[[0,1,2,3,4]])\n",
    "roc_auc = evaluate_model(models['knn'], data.clean_text, data[[0,1,2,3,4]], 'roc_auc')\n",
    "results.append(scores)\n",
    "\n",
    "print('KNN accuracy: %.4f roc_auc:%.4f (%.4f)' % (np.mean(scores),np.mean(roc_auc), np.std(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluate_model(models['gb'], data.clean_text, data[[0,1,2,3,4]])\n",
    "roc_auc = evaluate_model(models['gb'], data.clean_text, data[[0,1,2,3,4]], 'roc_auc')\n",
    "results.append(scores)\n",
    "\n",
    "print('GB accuracy: %.4f roc_auc:%.4f (%.4f)' % (np.mean(scores),np.mean(roc_auc), np.std(scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dB7LTUZ9oM3i"
   },
   "source": [
    "#### Tokenize and form sequence\n",
    "remove punctuation, transform to lower and split sentence into words\n",
    "Form sequence of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0KpqIL7noM3j"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nNNJ_uFoM3k",
    "outputId": "4e40a881-392d-4c42-a011-26148052377d"
   },
   "outputs": [],
   "source": [
    "dict(list(word_index.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kh8wAXyAoM3k"
   },
   "outputs": [],
   "source": [
    "#### Convert token into list of sequence\n",
    "train_sequences = tokenizer.texts_to_sequences(texts=X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDT6PlbXoM3k"
   },
   "source": [
    "#### Standardize length\n",
    "For NLP texts would have to be the same length, hence padding is required to concat those text which is too long and add more text if it is too short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcK5pEUYoM3l"
   },
   "outputs": [],
   "source": [
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ze5wUF5koM3l",
    "outputId": "3d6d70af-6953-424e-aa63-8acfdc5dcbc1"
   },
   "outputs": [],
   "source": [
    "print(len(train_sequences[0]))\n",
    "print(len(train_padded[0]))\n",
    "\n",
    "print(len(train_sequences[1]))\n",
    "print(len(train_padded[1]))\n",
    "\n",
    "print(len(train_sequences[10]))\n",
    "print(len(train_padded[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVrVGakLoM3l",
    "outputId": "7d48b368-a5c5-4aa8-b578-86a0de255c92"
   },
   "outputs": [],
   "source": [
    "y_train.groupby(y_train).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZf01ZoSoM3m",
    "outputId": "920abfb9-3d64-4570-c528-b872503cf863"
   },
   "outputs": [],
   "source": [
    "y_test.groupby(y_test).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0wTnM63oM3m"
   },
   "source": [
    "#### Do the same transformation to validation/ test\n",
    "Tokenize, make sequence and pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHC1rA2yoM3m",
    "outputId": "f50aa083-8869-452b-8983-6c28204b3a5d"
   },
   "outputs": [],
   "source": [
    "validation_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "print(len(validation_sequences))\n",
    "print(validation_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xX9ITuaoM3n"
   },
   "outputs": [],
   "source": [
    "#as tokenize labels\n",
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(data.labels)\n",
    "\n",
    "training_label_seq = np.array(label_tokenizer.texts_to_sequences(y_train))\n",
    "validation_label_seq = np.array(label_tokenizer.texts_to_sequences(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jb8qsq_poM3n",
    "outputId": "8fdfb3d3-54f8-42e4-edb5-8360fd8b4ac6"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAAJAafWoM3n"
   },
   "outputs": [],
   "source": [
    "\n",
    "weight_dict = max(y_train.groupby(y_train).size())/y_train.groupby(y_train).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WITcqfbdoM3o",
    "outputId": "24053998-2603-43db-9096-46cf634e1df9"
   },
   "outputs": [],
   "source": [
    "weight_dict= weight_dict.to_dict()\n",
    "weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4_nSLHSoM3o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prDCHSPOoM3o",
    "outputId": "bdeb8331-79f1-43c7-a26d-5574fca244fc"
   },
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_article(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "print(decode_article(train_padded[10]))\n",
    "print('---')\n",
    "print(X_train.reset_index().loc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fydcCw1zoM3o"
   },
   "outputs": [],
   "source": [
    "### Baseline model without adding any weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZQsm8mboM3o"
   },
   "source": [
    "### Ways to reduce overfitting\n",
    "\n",
    "Neural networks might overfit on the training set resulting in poor performance on the test set we can reduce overfitting by\n",
    "Regularization\n",
    "1)L2 & L1 regularization\n",
    "L1 and L2 are the most common types of regularization. These update the general cost function by adding another term known as the regularization term.\n",
    "2)Dropout\n",
    "At every iteration, it randomly selects some nodes and removes them along with all of their incoming and outgoing connections as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hISEEzBoM3p",
    "outputId": "305f0604-5dac-4252-f6ee-ba3f80ad6c73"
   },
   "outputs": [],
   "source": [
    "#testing model with dropout\n",
    "model = tf.keras.Sequential([\n",
    "    # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "#    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    # Add a Dense layer with 6 units and softmax activation.\n",
    "    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xahHsSlQoM3p"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWLo7B2ooM3p",
    "outputId": "1ed3b19d-2bb4-4d34-9cc2-b786de0a5746"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "# history = model.fit(train_padded, training_label_seq, epochs=num_epochs, validation_data=(validation_padded, validation_label_seq), verbose=2)\n",
    "history = model.fit(train_padded, y_train, epochs=num_epochs, validation_data=(validation_padded, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Soq-pJYSoM3q",
    "outputId": "e023cd15-b425-40e5-eb5e-56458034c781"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()\n",
    "  \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4gC1C1ToM3q",
    "outputId": "fb4d1a26-c9f5-49f4-d227-692c73ab5aa3"
   },
   "outputs": [],
   "source": [
    "#testing model with L1&L2 regularization\n",
    "model = tf.keras.Sequential([\n",
    "    # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "#    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    tf.keras.layers.Dense(units=64,kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    #6, kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "    # Add a Dense layer with 6 units and softmax activation.\n",
    "    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJNudlmboM3q"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeN8HRAroM3r",
    "outputId": "7828441d-346b-4799-e679-14fdec7141cd"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(train_padded, training_label_seq, epochs=num_epochs, validation_data=(validation_padded, validation_label_seq), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VELuD0lboM3r"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HH_-EiVoM3r"
   },
   "outputs": [],
   "source": [
    " label_dict= label_tokenizer.word_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEZ34r9BoM3r",
    "outputId": "372559c8-0622-4057-d905-c0e1379a995e"
   },
   "outputs": [],
   "source": [
    "class_weight = {label_dict[k] : v for k, v in weight_dict.items()}\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3v-iTF0oM3s",
    "outputId": "60b68041-b2a7-4671-c7de-7c934a9b0944"
   },
   "outputs": [],
   "source": [
    "## adding weights to the model for imbalanced classes\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8AJmBx_qoM3s",
    "outputId": "27deb9bd-7e90-4cae-e13e-55f54c6a3f50"
   },
   "outputs": [],
   "source": [
    "weighted = model.fit(train_padded, training_label_seq, epochs=num_epochs, validation_data=(validation_padded, validation_label_seq),class_weight=class_weight, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGYGJ2NUoM3s"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# get the model\n",
    "def get_model(n_inputs, n_outputs):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='sigmoid'))\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "\n",
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y):\n",
    "\tresults = list()\n",
    "\tn_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\t# define evaluation procedure\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# enumerate folds\n",
    "\tfor train_ix, test_ix in cv.split(X):\n",
    "\t\t# prepare data\n",
    "\t\tX_train, X_test = X[train_ix], X[test_ix]\n",
    "\t\ty_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\t\t# define model\n",
    "\t\tmodel = get_model(n_inputs, n_outputs)\n",
    "\t\t# fit model\n",
    "\t\tmodel.fit(X_train, y_train, verbose=0, epochs=100)\n",
    "\t\t# make a prediction on the test set\n",
    "\t\tyhat = model.predict(X_test)\n",
    "\t\t# round probabilities to class labels\n",
    "\t\tyhat = yhat.round()\n",
    "\t\t# calculate accuracy\n",
    "\t\tacc = accuracy_score(y_test, yhat)\n",
    "\t\t# store result\n",
    "\t\tprint('>%.3f' % acc)\n",
    "\t\tresults.append(acc)\n",
    "\treturn results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(data.clean_text)\n",
    "\n",
    "# evaluate model\n",
    "results = evaluate_model(X.toarray(),  data[[0,1,2,3,4]])\n",
    "# summarize performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(results), np.std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "for train_ix, test_ix  in cv.split(X):\n",
    "    print(test_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
