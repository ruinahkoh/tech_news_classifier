,title,imgurl,date,blurp,url,text,category,source
0,Is it just hype? How investors can vet a company’s AI claims,https://venturebeat.com/wp-content/uploads/2022/02/GettyImages-1336522614-e1649786490326.jpg?w=1200&strip=all,06/11/2022,Determining the value of a company's AI requires an in-depth look under the hood and a nuanced understanding of the AI's role.,https://venturebeat.com/ai/is-it-just-hype-how-investors-can-vet-a-companys-ai-claims/,"Join us on November 9 to learn how to successfully innovate and achieve efficiency by upskilling and scaling citizen developers at the Low-Code/No-Code Summit. Register here.

Almost every confidential investment memorandum (CIM) for a tech-driven enterprise includes the company’s mention of artificial intelligence (AI) or machine learning (ML) capabilities. But as with other investment buzzwords — such as “subscription revenue” — there is a tendency to use AI or ML to suggest complex, business-enabling, proprietary technology and processes to distinguish the offering as differentiated or technologically superior. This is often to garner higher valuation.

We’ve all heard examples of AI failures that make for good headlines and provide interesting cautionary tales. But as an investor, it can be just as frightening to learn that the AI capability that drove an above-market valuation is not much more than a spreadsheet with some marketing spin.

In our role as advisors to technology investors and management teams, we often encounter a question central to the investment thesis: Is the AI/ML the real deal? Here’s how to find the answer.

Make sure everyone’s speaking the same language

Varying interpretations of “artificial intelligence,” “machine learning” and “deep learning” can create confusion and misunderstandings, as the terms are often misused or used interchangeably. Think of the concepts this way:

Event Low-Code/No-Code Summit Learn how to build, scale, and govern low-code programs in a straightforward way that creates success for all this November 9. Register for your free pass today. Register Here

Artificial intelligence is any system that mimics human intelligence. With this definition, AI could refer to any rules-based system or algorithm — as long as it’s being used to simulate intelligence. Chatbots are a perfect example.

Machine learning is a subset of AI. It relies on a mathematical model created using a large dataset and a training algorithm that allows the model to learn and evolve. For example, in Google Photos, you can tag pictures with the names of the people in them, and over time, Google gets better and better at identifying people on its own. This is a good example of machine learning.

Deep learning is a subset of ML that involves highly sophisticated models resembling the structure of the human brain. These models require millions of records to train but can often equal or outperform humans at specific tasks. For example, the AlphaZero deep learning program remains undefeated at chess.

Digging deeper

You need to dig deeper than these broad, general terms to see how legitimate a company’s AI/ML technology is. You need to understand: What problem is being solved? What AI/ML technologies are used to solve it? How and why does this solution work? Does the solution provide a competitive edge over other approaches?

Let’s say you’re looking at investing in a new company in the hypothetical LawnTech space.

If the CIM describes the company’s HornetNest app as an “AI system for hornet eradication,” you’d want to dig more deeply with the technical product team to understand the underlying components and process. Ideally, you’ll end up with an explanation that sounds more like this:

“We use a YOLO-based object detector with a Kalman filter to identify, count, and track hornets in real time. Data is fed into an anomaly detector that automatically alerts customers when we see behavior that suggests a new nest may be present within a 50-yard radius. Through an exclusive partnership with Orkin, we have compiled the world’s largest training set of images, allowing us to predict the presence and location of new hornet nests more accurately than anyone else.”

This level of detail is needed to understand the sophistication, value, and defensibility of a company’s AI/ML assets.

Evaluate the whole picture

AI isn’t just one thing. It’s the product of six critical components essential to AI value. The degree to which these elements operate effectively together can help you separate the highest-value AI from the less legitimate.

The team

This is perhaps the most valuable asset and determinator of long-term success. In particular, having a strong data science team led by a seasoned chief data scientist opens the door to best-in-class AI.

The data

ML relies on training data to make the models. High volumes of data, especially proprietary data that competitors can’t access, create a significant competitive advantage and barrier. As a very rough rule of thumb, you need tens of thousands of training records for traditional ML; millions for deep learning.

The training process

There are basic training processes and advanced techniques, including automated machine learning (AutoML), hyperparameter tuning, active learning and weak supervision. A company’s ability to use these advanced techniques leads to reduced costs and improved quality.

Operational excellence

Beyond training the AI, it’s important to understand its overall care and feeding. You’ll want to understand the quality assurance, testing and error decomposition processes. When weaknesses are identified, how is supplemental training data gathered? Additionally, suppose a strength of the AI is incorporating real-time feedback to enable reinforcement learning, or compiling a knowledge base to support decision-making. In these cases, processes must be actively managed to ensure optimal performance.

The models

Models are results of the team, the data and the training process. But, to be considered an asset, they still take appreciable time to create and optimize. The value of this component is determined by the number of models a company has and the sophistication of the models.

The AI development infrastructure

There is a difference between a company that has thrown together a few ML models and one with the infrastructure to automatically create, retrain, test and deploy models.

Understand where the company falls on the AI maturity scale

Based on a sample from the more than 2,500 tech companies our team has diligenced over the last two years, we’ve noted some fairly consistent indicators of AI maturity.

Around 10% of these companies fall into the category of “No AI.” Despite what they say, it’s not AI. For example, software that optimizes container routing may not be AI but just a sophisticated traditional algorithm.

A further 10% fall into the category of “Non-proprietary AI.” In these instances, the company is using only public domain models, or MLaaS cloud APIs, to leverage AI. An example would be using Amazon’s AI-based Textract API to recognize text or the public domain ResNet model to detect objects in images. This approach can be considered AI-based but does not require training data, a training process, data scientists or even a lot of knowledge about AI to implement. There would also be no competitive differentiator in this approach since any company can use the same public-domain assets.

The vast majority, about 75%, fall into the category of “Standard AI.” What we see most often are companies that are training proprietary ML models using their own training data in combination with standard training algorithms. There is a broad range of sophistication in this class. At the simpler end of the range are companies that create linear regression models using a library like Python’s sklearn. At the more complex end are companies that design and create multiple deep learning models using TensorFlow and use advanced optimization techniques like hyperparameter tuning, active learning and weak supervision to maximize accuracy.

The final 5% falls into the category of “Leading-edge AI.” These companies have gone beyond standard AI techniques and developed their own model types and training algorithms to push AI in new directions. This represents unique and patentable IP that has value in itself, and the models created by these companies can outperform competitors that have access to the same dataset.

It looks like the real deal — but is it right for you?

Once you understand the details of the AI itself, you’re better positioned to understand its impact on the investment thesis. There are two factors to consider here.

First, what is the value of the AI? Because “AI” can have widely-varying definitions, it’s important to take a holistic view. The value of a company’s AI assets is the sum of the six critical parts noted above: the team, data, training process, operational excellence, models, and development infrastructure.

Another way to look at AI’s value in a company is to ask how it impacts the bottom line. What would happen to revenues and costs if the AI were to disappear tomorrow? Does it actually drive revenue or operating leverage? And conversely, what costs are required to maintain or improve the capability? You’ll find AI can be anything from an empty marketing slogan to technology essential for a company’s success.

Second, what risks does the AI introduce? Unintentional algorithmic bias can pose reputational and legal risks to the business, creating sexist, racist, or otherwise discriminatory AI. In the case of credit, law enforcement, housing, education and healthcare, this type of bias is prohibited by law and difficult to defend against — even when it occurs unwittingly. Make sure you understand how the target has guarded against algorithmic bias and the steps you would need to take to prevent bias moving forward.

Privacy is another concern, with AI often necessitating new layers of privacy and security protocols. You need to understand how biometric data (considered personally identifiable information protected by data privacy laws) and sensitive images, such as faces, license plates and computer screens, are collected, used and safeguarded.

The true value of AI

The reality is that, in today’s tech landscape, most companies can legitimately claim some AI capabilities. The majority of the time, the AI fits our definition for “standard” maturity and performs as we expect it to. But when we looked more deeply into the “standard AI” category, we found that only about half of these companies were using best practices or creating a competitive differentiator that would be difficult for competitors to outperform. The other half had room for improvement.

Determining the value of AI requires both an in-depth look under the hood and a nuanced understanding of the AI’s specific role in the business. Tech diligence, done by experts who’ve directly led AI teams, can help demystify AI for investors. The goal is to help investors understand exactly what they’re buying, what it can and cannot do for the business, what risks it introduces, and, ultimately, to what extent it supports the investment strategy.

Brian Conte is lead practitioner for Crosslake. Jason Nichols is a Crosslake practitioner and former director of AI at Walmart. Barr Blanton is Crosslake CEO.",artificial intelligence,venturebeat
1,6 Downsides of Using Artificial Intelligence in Cybersecurity,https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2022/11/robot.jpg,08/11/2022,"Is AI smart enough to keep us all safe online—or, like other forms of intelligence, does it come with limitations?",https://www.makeuseof.com/downsides-artificial-intelligence-cybersecurity/,"Artificial intelligence (AI) made a grand entrance into cyberspace with a promise to enhance how people interact with data. More so, it raises hopes of providing a stronger cybersecurity framework.
… [+6427 chars]",artificial intelligence,makeuseof
2,Nvidia Has Advanced Chip for China That Meets US Exports Rules - CNET,https://www.cnet.com/a/img/resize/917de34dae0234cfee3bdd2ff0f41e0c1d3d5a90/hub/2022/11/08/c9b1b3eb-353d-4084-9cdb-09a4ad261737/gettyimages-1231345600.jpg?auto=webp&fit=crop&height=630&width=1200,08/11/2022,The chip was developed after the US government told the chipmaker to restrict sales of a chip designed for AI applications.,https://www.cnet.com/tech/nvidia-says-new-advanced-chip-for-china-meets-us-export-rules/,"Chipmaker Nvidia has developed a new advanced chip for China that adheres to new US control export rules aimed at restricting that country's access to AI technology.

The chip, known as the A800, is an alternative to the A100 chip that went into production in the third quarter, Nvidia said Monday. ""The A800 meets the US government's clear test for reduced export control and cannot be programmed to exceed it,"" a spokesperson for the Santa Clara, California-based chipmaker said in a statement.

Tech companies have been caught in the middle of rising tensions between China and the US over Chinese companies gaining access to technologies that enable high-performance computing, such as artificial intelligence and semiconductors.

Nvidia revealed in August that the US government had ordered it to restrict sales of two AI acceleration chips to China -- the A100 and the forthcoming H100, which let AI developers speed up their research and build more-advanced AI models. The order aimed to ""address the risk that the covered products may be used in, or diverted to, a 'military end use' or 'military end user' in China and Russia,"" Nvidia said at the time.

The company warned at the time that it had expected approximately $400 million in sales to China during the third quarter but indicated that figure may be impacted by customers being unwilling to purchase alternative products.

The new chip was previously reported on by Reuters.",artificial intelligence,cnet
3,UK-Swiss science deal as both barred from EU scheme,https://ichef.bbci.co.uk/news/1024/branded_news/5D81/production/_127573932_swiss.jpg,10/11/2022,Political tensions mean both nations have been shut out of the EU's prestigious Horizon programme.,https://www.bbc.co.uk/news/world-europe-63566579,"Switzerland has never been a member of the European Union, but has dozens of bilateral deals with Brussels instead. Full Swiss participation of Horizon has been blocked after Switzerland rejected plans for an overarching treaty with the EU.",artificial intelligence,bbc news
4,Egyptian startup Blnk raises $32 million in funding round - Reuters,https://www.reuters.com/pf/resources/images/reuters/reuters-default.png?d=119,10/11/2022,"Blnk, a fintech platform that enables instant consumer credit in Egypt, has closed one of the country's biggest funding rounds for a startup this year, raising $32 million, its chief executive said.",https://www.reuters.com/technology/egyptian-startup-blnk-raises-32-million-funding-round-2022-11-10/,"













CAIRO, Nov 10 (Reuters) - Blnk, a fintech platform that enables instant consumer credit in Egypt, has closed one of the country's biggest funding rounds for a startup this year, raising $32 million, its chief executive said.

The company, launched in October 2021, raised $23.7 million in equity and debt funding and $8.3 million in securitised bond issuance, co-founder and CEO Amr Sultan told Reuters.

The funds will be used to accelerate financial inclusion within underserved communities across the country, to support further development of Blnk’s Artificial Intelligence-powered lending infrastructure, and to finance the company’s fast-growing portfolio of customers, he added.

The combined pre-seed and seed funding rounds of $12.5 million were led by Abu Dhabi’s Emirates International Investment Company (EIIC) and Egypt-based venture capital firm Sawari Ventures, with participation from several prominent local and international angel investors.

The $11.2 million debt funding was secured from a number of leading local banks. The $8.3 million securitised bond issuance was underwritten by National Bank of Egypt and Banque du Caire.

Blnk has developed a digital lending platform that empowers merchants of all sizes to instantly underwrite and finance their customers' purchases at the point of sale and enables consumers access to financing to purchase a range of products and services, including electronics, furniture and automotive services, paying over instalments ranging from six to 36 months.

The company says it has disbursed more than $20 million in loans to date.

Reporting by Mahmoud Salama Editing by Mark Potter











Our Standards: The Thomson Reuters Trust Principles.",artificial intelligence,reuters
5,Trump-linked stocks rally on possible 2024 presidential run - Reuters,https://www.reuters.com/resizer/OJS8iJjhprwzKuYYMEY3dnG1-UA=/1200x628/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/NVXZPLLYSRNSRFIXQSKADWBBBU.jpg,07/11/2022,"Shares of Digital World Acquisition Corp, the blank-check company looking to take Donald Trump's social media venture public, rallied on Monday over the former president's possible run for the 2024 presidential election.",https://www.reuters.com/markets/us/trump-linked-stocks-rally-possible-2024-presidential-run-2022-11-07/,"













Nov 7 (Reuters) - Shares of Digital World Acquisition Corp, the blank-check company looking to take Donald Trump's social media venture public, rallied on Monday over the former president's possible run for the 2024 presidential election.

Trump is considering launching a third bid for the White House this month, three of his advisers said last week, while media reports over the weekend pointed to a campaign starting before the end of November.

Shares in Digital World Acquisition Corp (DWAC.O) jumped more than 24% to $21.55, and were set for their best day in nearly a year, bringing down year-to-date losses to 58%.

""The prospect of Donald Trump seizing the political spotlight again appears to have put a rocket under the share price of DWAC amid expectation there could be a sharp increase in users on the former President's highly controversial social media platform,"" said Susannah Streeter, senior investment and markets analyst at Hargreaves Lansdown.

The rally in DWAC, which was also the fifth most trending ticker on retail investor focused social media forum Stocktwits, helped lift shares of other Trump-linked companies.

DWAC on Thursday extended the deadline to Nov. 22. for investors' approval to complete its merger deal with Trump Media and Technology Group.

This move comes as Americans prepare to vote in the U.S. midterm elections, with analysts expecting Republicans to win control of Congress.

Software developer Phunware Inc (PHUN.O), which was hired by Trump's 2020 presidential reelection campaign to build a phone app, jumped 18.3%.

Rumble Inc (RUM.O), a Canadian video platform popular with conservatives, however, slipped 3.5%. Trump's social media venture Truth Social announced in August it would join Rumble's new ad platform as its first publisher in August.

Artificial intelligence solutions company Remark Holdings (MARK.O), which has been linked to the former president on social media sites, gained 8.6%. Reuters could not independently verify the link between Trump and Remark.

Reporting by Shreyashi Sanyal, Akash Sriram and Anisha Sircar in Bengaluru; Editing by Vinay Dwivedi











Our Standards: The Thomson Reuters Trust Principles.",artificial intelligence,reuters
6,Spirited review – Will Ferrell and Ryan Reynolds hit all the wrong notes in Christmas musical,https://i.guim.co.uk/img/media/acca4df46d0f9faebb98c452186909229462f431/0_208_6240_3744/master/6240.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctcmV2aWV3LTIucG5n&enable=upscale&s=ee2fd86a40b3be53c55b26992c37afb3,09/11/2022,"The two make for an awkward double act in a slick but grating song-and-dance spin on A Christmas Carol that will make grinches of us allIt’s been almost 20 years since Will Ferrell and Jon Favreau gifted us the unlikely yet enduring Christmas winner Elf, the …",https://www.theguardian.com/film/2022/nov/09/spirited-review-will-ferrell-ryan-reynolds,"It’s been almost 20 years since Will Ferrell and Jon Favreau gifted us the unlikely yet enduring Christmas winner Elf, the rare four-quadrant success story that neatly balanced the sweet with the salty. It’s a tricky tightrope that Ferrell’s new festive comedy Spirited precariously wobbles along before almost immediately falling off, a desperate and crudely assembled attempt to recapture that very difficult to capture magic.

It comes from Apple, as one of the tech behemoth’s biggest bets to date (at least $75m was spent just on talent), and suitably has the feeling of something created less by real human people and more calculated by artificial intelligence, heavy emphasis on artificial. It’s a plasticky piece of product with the puppyish insistence that it has the power to please us all, frantically trying to tick every box but failing to hit just one. A meta spin on A Christmas Carol that’s also a bromance comedy but mostly an earnest, full-throated musical was never going to be an easy elevator pitch to untangle but it was enough to spark a bidding war with Apple beating out Netflix, Paramount and Warner Bros.

In the annual flurry of cheaply stuffed Christmas streaming movies, there is a thrill to watching one that wouldn’t pixelate if transferred to a bigger screen and Spirited easily and expensively earns its one-week theatrical release before it heads to your smartphone. It’s all very slickly packaged, even if at points such slickness becomes a little too synthetic, and will probably find a record audience for Apple, a company that’s struggled to find a homegrown blockbuster movie. But while it might be a hit this season, I doubt for many it will have that annual rewatchability factor, a film not for life but just this one Christmas.

In the high-concept world of Spirited, haunting is a business. Every year when Christmas approaches, three ghosts descend upon a figure in need of de-Scrooging, redemption being the ultimate goal. The Ghost of Christmas Present (Ferrell) is edging toward retirement but eager to make an impact before that day comes and so picks Clint Briggs (Ryan Reynolds), a heartless media consultant who spends his life causing conflict for a living. He’s what’s known as an “unredeemable”, someone incapable of real change, but along with Past (Glow’s Sunita Mani) and Future (the voice of Tracy Morgan), he’s determined to finish the job.

New adaptations of the Dickens morality tale are a seasonal staple (this year also sees a Netflix animation with the voices of Olivia Colman and Jessie Buckley, the return of Jefferson Mays’ one-man Broadway show and an Adrian Edmondson-led version at the Royal Shakespeare Theatre in Stratford-upon-Avon) and so there is at least some initial inventiveness to be praised in the Daddy’s Home co-writers Sean Anders and John Morris’s distinctive revision. There’s some intricate world-building and the odd deft idea but some less developed joke-writing, a string of misses crashing from the very first scene. While Elf managed to be genuinely funny while also being genuinely sweet, the tone here is far less even. The wink, wink jokes for the adults reek of eye-rolling smugness (it’s the kind of film where a character watches a song-and-dance number and asks “Why are they singing?” to the answer of “Because they’re in a musical”) and this clashes with the film’s often embarrassingly straight-faced earnestness, most visible in the film’s many, many, many musical set pieces.

The decision to make the film a musical is a genuine head-scratcher, one that’s never justified or even mildly explained given that the two leads are not natural singers and so throughout the lunges into song feel awkward at best. With music from the La La Land and The Greatest Showman duo Benj Pasek and Justin Paul, it’s certainly committed to the genre but extravagant staging and enthused backing dancers can’t disguise forgettable, cloying songs and lacklustre singing. It’s closer to watching high-budget karaoke at an office Christmas party. Even when they’re not bursting into song, the two can’t really conjure the necessary star powered chemistry to glide us through. Reynolds’s regurgitated quippy shtick is growing more exhausted by the movie (his character name-checking Scrooged only serves to remind us just how much more well-suited Bill Murray was to the role of grinch) while an unsure Ferrell struggles to flip between serious and silly leaving it up to an underused Octavia Spencer, as assistant-cum-love interest, to walk away with the film, an admittedly easy task given the leaden leads.

Anders, also serving as director, never seems confident enough in what his film should be and so we’re never confident enough in what we’re actually watching, an atonal grab bag of inharmonious notes (an uneasy third act suicide proves to be the flattest). When stretched to a two-hour-plus runtime (with more musical bits during the credits), we leave feeling bloated, a 10-course Christmas meal we wish we’d never started.",artificial intelligence,the guardian
7,Using artificial intelligence to decarbonise heavy industry,https://www.springwise.com/wp-content/uploads/2022/11/innovationagriculture-energyusing-artificial-intelligence-to-decarbonise-heavy-industry.png,10/11/2022,"Carbon Re’s state-of-the-art AI aims to optimise processes in high-polluting industries and cut their carbon emissions
The post Using artificial intelligence to decarbonise heavy industry appeared first on Springwise.",https://www.springwise.com/innovation/agriculture-energy/using-artificial-intelligence-to-decarbonise-heavy-industry/,"Spotted: Currently, the world’s most energy-intensive industries—including cement, steel, and glass—produce over 20 per cent of global greenhouse gas emissions. Given their contribution to the world’s carbon emissions, minimising the environmental effects of industrial plants is vital. But plans to decarbonise heavy industry efficiently have been unsuccessful, often relying on Carbon Capture and Storage (CCS) technologies that would take decades to scale. Carbon Re’s technology, by contrast, can be implemented quickly, requires no new equipment, and is already being used to cut emissions today.

In a world-first, the company is developing an artificial intelligence powered software (Delta Zero) to create ‘Digital Twins’ of industrial plants – which can then be monitored to analyse a specific plant’s output and efficiency. Procedures can then be optimised to reduce fuel usage, operational costs, and carbon emissions. Because Delta Zero continuously tracks the plant’s function, operators may alter and improve manufacturing processes virtually in real-time.

Today, the technology is being used in pilot projects at cement plants in Europe, Asia, and the Americas, allowing them all to reduce carbon dioxide emissions by up to 10 per cent. But, with £4.2 million of seed money now raised with the help of Planet A Ventures, Carbon Re aims to scale-up Delta Zero Cement onto the global market and expand into the steel and glass industries.

Springwise has spotted other innovations seeking to reduce industrial carbon emissions, including a carbon-capture solvent and new biogas plants.

Written By: Matilda Cox",artificial intelligence,springwise.com
8,Nvidia and Intel show machine learning performance gains on latest MLPerf Training 2.1 results,https://venturebeat.com/wp-content/uploads/2021/08/machine-learning-challenges.jpg?w=1200&strip=all,09/11/2022,Both Nvidia and Intel’s Habana Labs reported performance gains with the MLPerf 2.1 benchmark in training machine learning models.,https://venturebeat.com/ai/nvidia-and-intel-show-machine-learning-performance-gains-on-latest-mlperf-training-2-1-results/,"Join us on November 9 to learn how to successfully innovate and achieve efficiency by upskilling and scaling citizen developers at the Low-Code/No-Code Summit. Register here.

MLCommons is out today with its latest set of machine learning (ML) MLPerf benchmarks, once again showing how hardware and software for artificial intelligence (AI) are getting faster.

MLCommons is a vendor-neutral organization that aims to provide standardized testing and benchmarks to help evaluate the state of ML software and hardware. Under the MLPerf testing name, MLCommons collects different ML benchmarks multiple times throughout the year. In September, the MLPerf Inference results were released, showing gains in how different technologies have improved inference performance.

Today, the new MLPerf benchmarks being reported include the Training 2.1 benchmark, which is for ML training; HPC 2.0 for large systems including supercomputers; and Tiny 1.0 for small and embedded deployments.

“The key reason why we’re doing benchmarking is to drive transparency and measure performance,” David Kanter, executive director of MLCommons, said during a press briefing. “This is all predicated on the key notion that once you can actually measure something, you can start thinking about how you would improve it.”

Event Low-Code/No-Code Summit Learn how to build, scale, and govern low-code programs in a straightforward way that creates success for all this November 9. Register for your free pass today. Register Here

How the MLPerf training benchmark works

Looking at the training benchmark in particular, Kanter said that MLPerf isn’t just about hardware, it’s about software too.

In ML systems, models need to first be trained on data in order to operate. The training process benefits from accelerator hardware, as well as optimized software.

Kanter explained that the MLPerf Training benchmark starts with a predetermined dataset and a model. Organizations then train the model to hit a target quality threshold. Among the primary metrics that MLPerf Training benchmark captures is time to train.

“When you look at the results, and this goes for any submission — whether it’s training, tiny, HPC or inference — all of the results are submitted to say something,” Kanter said. “Part of this exercise is figuring out what that something they say is.”

The metrics can identify relative levels of performance and also serve to highlight improvement over time for both hardware and software.

John Tran, senior director of deep learning libraries and hardware architecture at Nvidia and chair of MLPerf Training at MLCommons, highlighted the fact that there were a number of software-only submissions for the latest benchmark.

“I find it continually interesting how we have so many software-only submissions and they don’t necessarily need help from the hardware vendors,” Tran said. “I think that’s great and is showing the maturity of the benchmark and usefulness to people.”

Intel and Habana Labs push training forward with Gaudi2

The importance of software was also highlighted by Jordan Plawner, sr. director of AI products at Intel. During the MLCommons press call, Plawner explained what he sees as the difference between ML inference and training workloads in terms of hardware and software.

“Training is a distributed-workload problem,” Plawner said. “Training is more than just hardware, more than just the silicon; it’s the software, it’s also the network and running distributed-class workloads.”

In contrast, Plawner said that ML inference can be a single-node issue that doesn’t have the same distributed aspects, which provides a lower barrier to entry for vendor technologies than ML training.

In terms of results, Intel is well represented on the latest MLPerf Training benchmarks with its Gaudi2 technology. Intel acquired Habana Labs and its Gaudi technology for $2 billion in 2019 and have helped to advance the company’s capabilities in recent years.

The most advanced silicon from Habana Labs is now the Gaudi2 system, which was announced in May. The latest Gaudi2 results show gains over the first set of benchmarks that Habana Labs reported with the MLPerf Training update in June. According to Intel, Gaudi2 improved by 10% for time-to-train in TensorFlow for both BERT and ResNet-50 models.

Nvidia H100 hops past predecessor

Nvidia is also reporting strong gains for its technologies in the latest MLPerf Training benchmarks.

Testing results for Nvidia’s Hopper-based H100 with MLPerf Training show significant gains over the prior generation A100-based hardware. In an Nvidia briefing call discussing the MLCommons results, Dave Salvator, director of AI, benchmarking and cloud at Nvidia, said that the H100 provides 6.7 times more performance than the first A100 submission had for the same benchmarks several years ago. Salvator said that a key part of what makes the H100 perform so well is the integrated transformer engine that is part of the Nvidia Hopper chip architecture.

While H100 is now Nvidia’s leading hardware for ML training, that’s not to say the A100 hasn’t improved its MLPerf Training results as well.

“The A100 continues to be a really compelling product for training, and over the last couple of years we’ve been able to scale its performance by more than two times from software optimizations alone,” Salvator said.

Overall, whether it’s with new hardware or continued software optimizations, Salvator expects there will be a steady stream of performance improvements for ML training in the months and years to come.

“AI’s appetite for performance is unbounded, and we continue to need more and more performance to be able to work with growing datasets in a reasonable amount of time,” Salvator said.

The need to be able to train a model faster is critical for a number of reasons, including the fact that training is an iterative process. Data scientists often need to train and then retrain models in order to get the desired results.

“That ability to train faster makes all the difference in not only being able to work with larger networks, but being able to employ them faster and get them doing work for you in generating value,” Salvator said.",artificial intelligence,venturebeat
9,Why data remains the greatest challenge for machine learning projects,https://venturebeat.com/wp-content/uploads/2020/10/shutterstock_350476919-e1513916353327.jpg?w=1200&strip=all,08/11/2022,Appen’s latest State of AI Report reveals advances in helping enterprises overcome barriers to sourcing and preparing their data.,https://venturebeat.com/ai/why-data-remains-the-greatest-challenge-for-machine-learning-projects/,"To further strengthen our commitment to providing industry-leading coverage of data technology, VentureBeat is excited to welcome Andrew Brust and Tony Baer as regular contributors. Watch for their articles in the Data Pipeline.

Quality data is at the heart of the success of enterprise artificial intelligence (AI). And accordingly, it remains the main source of challenges for companies that want to apply machine learning (ML) in their applications and operations.

The industry has made impressive advances in helping enterprises overcome the barriers to sourcing and preparing their data, according to Appen’s latest State of AI Report. But there is still a lot more to be done at different levels, including organization structure and company policies.

The costs of data

The enterprise AI life cycle can be divided into four stages: Data sourcing, data preparation, model testing and deployment, and model evaluation.

Advances in computing and ML tools have helped automate and accelerate tasks such as training and testing different ML models. Cloud computing platforms make it possible to train and test dozens of different models of different sizes and structures simultaneously. But as machine learning models grow in number and size, they will require more training data.

Event Low-Code/No-Code Summit Learn how to build, scale, and govern low-code programs in a straightforward way that creates success for all this November 9. Register for your free pass today. Register Here

Unfortunately, obtaining training data and annotating still requires considerable manual effort and is largely application specific. According to Appen’s report, “lack of sufficient data for a specific use case, new machine learning techniques that require greater volumes of data, or teams don’t have the right processes in place to easily and efficiently get the data they need.”

“High-quality training data is required for accurate model performance; and large, inclusive datasets are expensive,” Appen’s chief product officer Sujatha Sagiraju told VentureBeat. “However, it’s important to note that valuable AI data can increase the chances of your project going from pilot to production; so, the expense is needed.”

ML teams can start with prelabeled datasets, but they will eventually need to collect and label their own custom data to scale their efforts. Depending on the application, labeling can become extremely expensive and labor-intensive.

In many cases, companies have enough data, but they can’t deal with quality issues. Biased, mislabeled, inconsistent or incomplete data reduces the quality of ML models, which in turn harms the ROI of AI initiatives.

“If you train ML models with bad data, model predictions will be inaccurate,” Sagiraju said. “To ensure their AI works well in real-world scenarios, teams must have a mix of high-quality datasets, synthetic data and human-in-the-loop evaluation in their training kit.”

The gap between data scientists and business leaders

According to Appen, business leaders are much less likely than technical staff to consider data sourcing and preparation as the main challenges of their AI initiatives. “There are still gaps between technologists and business leaders when understanding the greatest bottlenecks in implementing data for the AI lifecycle. This results in misalignment in priorities and budget within the organization,” according to the Appen report.

“What we know is that some of the biggest bottlenecks for AI initiatives lie in lack of technical resources and executive buy-in,” Sagiraju said. “If you take a look at these categories, you see that the data scientists, machine learning engineers, software developers and executives are dispersed across different areas, so it’s not hard to imagine a lack of aligned strategy due to conflicting priorities between the various teams within the organization.”

The variety of people and roles involved in AI initiatives makes it hard to achieve this alignment. From the developers managing the data, to the data scientists dealing with on-the-ground issues, and the executives making strategic business decisions, all have different goals in mind and therefore different priorities and budgets.

However, Sagiraju sees that the gap is slowly narrowing year over year when it comes to understanding the challenges of AI. And this is because organizations are better understanding the importance of high-quality data to the success of AI initiatives.

“The emphasis on how important data — especially high-quality data that match with application scenarios — is to the success of an AI model has brought teams together to solve these challenges,” Sagiraju said.

Promising trends in machine learning

Data challenges are not new to the field of applied ML. But as ML models grow bigger and data becomes more abundantly available, there is a need to find scalable solutions to assemble quality training data.

Fortunately, a few trends are helping companies overcome some of these challenges, and Appen’s AI Report shows that the average time spent in managing and preparing data is trending down.

One example is automated labeling. For example, object detection models require the bounding boxes of each object in the training examples to be specified, which takes considerable manual effort. Automated and semi-automated labeling tools use a deep learning model to process the training examples and predict the bounding boxes. The automated labels are not perfect, and a human labeler must review and adjust them, but they speed up the process significantly. In addition, the automated labeling system can be further trained and improved as it receives feedback from human labelers.

“While many teams start off with manually labeling their datasets, more are turning to time-saving methods to partially automate the process,” Sagiraju said.

At the same time, there is a growing market for synthetic data. Companies use artificially generated data to complement the data they collect from the real world. Synthetic data is especially useful in applications where obtaining real-world data is costly or dangerous. An example is self-driving car companies, which face regulatory, safety and legal challenges in obtaining data from real roads.

“Self-driving cars require incredible amounts of data to be safe and prepared for anything once they hit the road, but some of the more complex data is not readily available,” Sagiraju said. “Synthetic data allows practitioners to account for edge cases or dangerous scenarios like accidents, crossing pedestrians and emergency vehicles to effectively train their AI models. Synthetic data can create instances to train data when there isn’t enough human-sourced data. It’s critical in filling in the gaps.”

At the same time, the evolution of the MLops market is helping companies tackle many challenges of the machine learning pipeline, including labeling and versioning datasets; training, testing, and comparing different ML models; deploying models at scale and keeping track of their performance; and gathering fresh data and updating the models over time.

But as ML plays a greater role in enterprises, one thing that will become more important is human control.

“Human-in-the-loop (HITL) evaluations are imperative to delivering accurate, relevant information and avoiding bias,” Sagiraju said. “Despite what many believe about humans actually taking a backseat in AI training, I think we’ll see a trend towards more HITL evaluations in an effort to empower responsible AI, and have more transparency about what organizations are putting into their models to ensure models perform well in the real world.”",artificial intelligence,venturebeat
10,Why authorized deepfakes are big business,https://venturebeat.com/wp-content/uploads/2022/11/Screen-Shot-2022-11-09-at-10.55.05-AM.png?w=1200&strip=all,09/11/2022,"There is another side to the deepfake debate, say several vendors that specialize in synthetic media technology.",https://venturebeat.com/ai/why-authorized-deepfakes-are-big-business/,"Join us on November 9 to learn how to successfully innovate and achieve efficiency by upskilling and scaling citizen developers at the Low-Code/No-Code Summit. Register here.

Natalie Monbiot, head of strategy at synthetic media company Hour One, dislikes the word “deepfakes.”

“Deepfake implies unauthorized use of synthetic media and generative artificial intelligence — we are authorized from the get-go,” she told VentureBeat.

She described the Tel Aviv- and New York-based Hour One as an AI company that has also “built a legal and ethical framework for how to engage with real people to generate their likeness in digital form.”

Authorized versus unauthorized. It’s an important delineation in an era when deepfakes, or synthetic media in which a person in an existing image or video is replaced with someone else’s likeness, has gotten a boatload of bad press — not surprisingly, given deepfakes’ longstanding connection to revenge porn and fake news. The term “deepfake” can be traced to a Reddit user in 2017 named “deepfakes” who, along with others in the community, shared videos, many involving celebrity faces swapped onto the bodies of actresses in pornographic videos.

Event Low-Code/No-Code Summit Learn how to build, scale, and govern low-code programs in a straightforward way that creates success for all this November 9. Register for your free pass today. Register Here

And deepfake threats are looming, according to a recent research paper from Eric Horvitz, Microsoft’s chief science officer. These include interactive deepfakes, that offer the illusion of talking to a real person, and compositional deepfakes, with bad actors creating many deepfakes to compile a “synthetic history.”

Most recently, news about celebrity deepfakes has proliferated. There’s the Wall Street Journal coverage of Tom Cruise, Elon Musk and Leonardo DiCaprio deepfakes appearing unauthorized in ads, as well as rumors about Bruce Willis signing away the rights to his deepfake likeness (not true).

The business side of the deepfake debate

But there is another side to the deepfake debate, say several vendors that specialize in synthetic media technology. What about authorized deepfakes used for business video production?

Most use cases for deepfake videos, they claim, are fully authorized. They may be in enterprise business settings — for employee training, education and ecommerce, for example. Or they may be created by users such as celebrities and company leaders who want to take advantage of synthetic media to “outsource” to a virtual twin.

The idea, in these cases, is to use synthetic media — in the form of virtual humans — to tackle the expensive, complex and unscalable challenges of traditional video production, especially at a time when the hunger for video content seems insatiable. Hour One, for example, claims to have made 100,000 videos over the past three and a half years, with customers including language-learning leader Berlitz and media companies such as NBC Universal and DreamWorks.

At a moment when generative AI has become part of the mainstream cultural zeitgeist, the future looks bright for enterprise use cases of deepfakes. Forrester recently released its top 2023 AI predictions, one of which is that 10% of Fortune 500 enterprises will generate content with AI tools. The report mentioned startups such as Hour One and Synthesia which “are using AI to accelerate video content generation.”

Another report predicts that in the next five to seven years, as much as 90% of digital media could be synthetically generated.

“That sounded very bullish … probably even to me,” said Monbiot. “But as the technology matures and massive players are getting into this space, we’re seeing disruption.”

The business side is a “hugely under-appreciated” part of the deepfakes debate, insists Victor Riparbelli, CEO of London-based Synthesia, which describes itself as an “AI video creation company.” Founded in 2017, it has more than 15,000 customers, a team of 135 and is “growing in double-digits every month.” Among its clients are fast-food giants including McDonald’s, research company Teleperformance and global advertising holding company WPP.

“It’s very interesting how the lens has been very narrow on all the bad things you could do with this technology,” Riparbelli said. “I think what we’ve seen is just more and more interest in this and more and more use cases.”

A living video that you can always edit

It’s difficult to access quality content and most businesses don’t have the skills to enable high-grade content creation, said Monbiot.

“Most businesses don’t have people that have any skills that enable content creation, especially high-grade content creation featuring actual talent, and they also don’t have the ability to edit videos or have these kinds of resources in-house,” she explained. Hour One is a no-code platform, so even users with no prior skills in creating content can select from a range of virtual humans or become one themselves.

Berlitz, one of Hour One’s first enterprise clients, needed to digitally transform after 150 years offering classroom learning. “To keep the instructor in the content, they do live videoconferencing, but that doesn’t really scale,” Monbiot said. “Even if they had all the production resources in the world, the cost and the investment and the management of all of those files is just insane.” She added that with AI, the content can be continually updated and refreshed. Now, Berlitz has over 20,000 videos in different languages created with Hour One.

Meanwhile, Synthesia said its AI is trained on real actors. It offers the actors’ images and voices as virtual characters clients can choose from to create training, learning, compliance and marketing videos. The actors are paid per video that’s generated with them.

For enterprise clients, this becomes a “living video” that they can always go back to and edit, Riparbelli explained.

Video by Synthesia

“I think we actually work for almost all the biggest fast-food chains in the world by now,” he said. “They need to train hundreds of thousands of people every single year, on everything … how to stay safe at work, how to deal with a customer complaint, how to operate the deep fryer.”

Before, he said, a company might record a few videos, but they would be very high-level and evergreen. All other training would likely be via PowerPoint slides or PDFs. “That isn’t a great way of training, especially not the younger generation,” he said. Instead, they now create video content — to replace not the original video shoots, but the text options.

Authorization agreements are key

Hour One guides users through the process to get the highest-quality video capture in front of a green screen. The base footage becomes the training data for the AI.

“We basically create a digital twin of that person — for example, a CEO,” said Monbiot. “The CEO would sign an agreement allowing us to take the footage and create a virtual twin.” Another portion of the agreement would specify who is authorized to create content with the virtual twin.

“We want people to have a very positive, comfortable, pleasant experience with our virtual human content,” she said. “If people feel a little confused or uneasy, that creates distrust, and that’s very antithetical to why we do what we do.”

According to Synthesia, this kind of authorization is common in all kinds of licensing agreements that already exist.

“Kim Kardashian has literally licensed her likeness to app developers to build a game that grossed billions of dollars,” said Riparbelli. “Every actor or celebrity licenses their likeness.”

Offering influencers their images at scale

One synthetic media company, Deepcake, is leaning less into the enterprise space and more into the business of authorized deepfakes used by celebrities and influencers for brand endorsements. For example, the company created a “digital twin” of Bruce Willis to be used in an advertisement for Russian telecom company MegaFon. This led to the rumor that Deepcake owns the rights to Willis’ digital twin (which they do not).

“We work directly with stars with talent management agencies, to develop digital twins ready to be put into any type of content, like commercials for TikTok,” said CEO Maria Chmir. “This is a new way to produce the content without classic assets like constantly searching the locations and a very long and expensive post-production process.”

There are also fully-synthesized people who can become brand ambassadors for a few dozen dollars, she added. Users simply enter the text that these characters have to say.

“Of course you can’t clone charisma and make a person improvise, but we’re working on that,” she said.

The future of authorized deepfakes

Synthesia says it is adding emotions and gestures into its videos over the coming months. Hour One recently released 3D environments to create a “truly immersive” experience.

“If you think of the maturity of the AI technology, every time we move up that scale, we unlock more use cases,” said Riparbelli. “So next year, I think we’ll see a lot of marketing content, like Facebook ads. We’re just generally going to see a lot less text and a lot more video and audio into communication we consume every day.”

The enterprise use cases around synthetic media “deepfakes” are just beginning, said Monbiot, who added: “But this economy has already begun.”",artificial intelligence,venturebeat
11,"Nvidia, Rescale team to enhance AI cloud automation and HPC-as-a-service",https://venturebeat.com/wp-content/uploads/2021/03/data_streaming2-e1634064555341.jpg?w=1200&strip=all,09/11/2022,Nvidia and Rescale partner to make it easier to spin up new scientific workloads and operate them more efficiently. This will also apply equally to public cloud service and private cloud infrastructure.,https://venturebeat.com/ai/nvidia-rescale-team-to-enhance-ai-cloud-automation-and-hpc-as-a-service/,"Join us on November 9 to learn how to successfully innovate and achieve efficiency by upskilling and scaling citizen developers at the Low-Code/No-Code Summit. Register here.

Nvidia and Rescale today announced several enhancements designed to simplify artificial intelligence (AI) development and optimize high-performance computing (HPC) workflows. Nvidia is powering a new AI compute recommendation engine (CRE) to replace a more manually tuned approach. It’s also integrating the Nvidia AI platform into Rescale’s HPC-as-a-service offering.

Both developments promise to make it easier to spin up new scientific workloads and operate them more efficiently. This will also apply equally to public cloud service and private cloud infrastructure.

Rescale specializes in tools for automating scientific computing workloads — a field that is ripe for disruption, since engineers may sometimes spend more time configuring experiments than running them. Earlier this year, Rescale announced tools to help refactor legacy apps to run on containers to dramatically simplify configuration and deployment.

It also announced a partnership with Nvidia in July to containerize many Nvidia workloads. The latest news builds on this partnership to automate support for Nvidia’s AI platform. This will automates the use of AI for physics, recommendation engines, simulations, medical research and more. It also applies Nvidia’s recommendation capabilities back on the HPC infrastructure itself.

Event Low-Code/No-Code Summit Learn how to build, scale, and govern low-code programs in a straightforward way that creates success for all this November 9. Register for your free pass today. Register Here

AI-powered infrastructure recommendations

Spinning up scientific computing workloads requires a delicate balance involving hardware, networking, memory, software and specific configurations. Rescale and Nvidia have collaborated on what the two are billing as the world’s first AI-powered recommendation system for HPC and AI workloads. The companies claim it will assist teams with balancing decisions about architectures, geographic regions, price, compliance and sustainability objectives. Nvidia and Rescale trained the system using data from more than 100 million production HPC workloads.

“Prior to compute recommendation engines, the primary way we provided compute optimization was through our solution architects working with the customers guided by our internal benchmarks library,” Edward Hsu, Rescale’s chief product officer told VentureBeat. “With the compute recommendation engine, we are bringing unprecedented levels of automation and insights by applying machine learning [ML] to infrastructure telemetry and job performance data.”

With the new engine, users choose a workload and Rescale will suggest a computing architecture to provide the best performance. Hsu claims that these recommendations are 90% accurate. Further optimization will also need to account for the models, which can impact both performance and the applications they run on.

Rescale is also integrating the Nvidia Base Command Platform software to orchestrate workloads across clouds and on-premises Nvidia DGX systems.

Expanding the reach and utility of AI

The two companies are also partnering to support the Nvidia AI Enterprise Software Suite on top of the Rescale platform. Soon, this will help automate workflows using tools like Isaac for programming robots, Nemo for languages, Merlin for recommendations, Morpheus for Security and Holoscan for medical AI. Nvidia Modulus, a physics-ML framework, is also now available on Rescale — which will play a key role in helping companies create faster digital twins for simulating the physical properties of products and equipment.

Existing AI frameworks on Rescale, such as PyTorch and TensorFlow, are more general purpose. Modulus is a programmable physics-informed neural network that can create models that the company claims run hundreds or thousands of times faster than traditional simulation techniques. The Modulus support allows teams to more easily apply AI to emulate physics-based simulations at much higher performance and lower cost

“As we see the engineers move from intuition-based engineering towards AI-assisted engineering, bringing together the tools for computational engineering and artificial intelligence will be critical to help companies accelerate new product innovation,” Hsu said.",artificial intelligence,venturebeat
12,"Apple to simplify Siri digital assistant interaction on devices, but will take time - Deccan Herald",https://www.deccanherald.com/sites/dh/files/articleimages/2022/11/07/aiphone14pm-cov-sho-sel-1c-1160123-1667820907.jpg,07/11/2022,"<ol><li>Apple to simplify Siri digital assistant interaction on devices, but will take time  Deccan Herald
</li><li>Apple Planning to Revamp How You Talk to Siri: Gurman • iPhone in Canada Blog  iPhone in Canada
</li><li>Apple Plans To Change 'Hey Siri' Com…",https://www.deccanherald.com/business/technology/apple-to-simplify-siri-digital-assistant-interaction-on-devices-but-will-take-time-1160123.html,"For a long, Amazon long has been offering the simple wake phrase 'Alexa' for smart devices and Google followed it by simplifying the Ok/Hey Google to invoke or continue the conversation with a digital assistant. But, Apple device owners have to always use the prefix 'Hey' to start a conversation with Siri.

Now, Bloomberg's Mark Gurman citing confidential sources has claimed that Apple may simplify the phrase words for the smart voice assistant on its products.

For most people, dropping the 'Hey' from Siri wake phrase may sound like an easy job but it isn't. It is said to be a huge technical challenge, as Apple engineers have to recode the algorithm of the AI (artificial intelligence) model, which by the way has to work on the device. It has to be able to understand the dialect or accent of people correctly to have a normal continued conversation to do tasks on the device.

Apple is already testing within the company among employees. But, it continues to evaluate the feedback and makes changes for several months. The company may take a year if not more to make conversation with Siri better on Apple devices.

If things go as planned, the Siri update may come by the end of 2023 or early 2024.

On a related note, Apple is expected to bring new Macs in early 2023. Last month, the company was speculated to bring new M2-based Mac PCs along with the new iPad, iPad Pro, and Apple TV 4K, but only the latter three made their official debut.

Now, the latest report indicates, the Cupertino-based company has big plans in 2023 and may kick off with new 14-inch and 16-inch MacBook Pro models with faster and more powerful M2 silicon as early as January or February.

Must read | Apple iPhone 14 Plus review: Power-packed mobile

Get the latest news on new launches, gadget reviews, apps, cybersecurity, and more on personal technology only on DH Tech.",artificial intelligence,deccan herald
13,Microsoft's Copilot code tool faces the first big AI copyright lawsuit,https://images.newscientist.com/wp-content/uploads/2022/11/08170834/SEI_132742877.jpg,08/11/2022,"A $9 billion class-action lawsuit has been filed against Microsoft, code-sharing site GitHub and artificial intelligence firm OpenAI for the way their tool Copilot uses people’s code",https://www.newscientist.com/article/2346217-microsofts-copilot-code-tool-faces-the-first-big-ai-copyright-lawsuit/,"A $9 billion class-action lawsuit has been filed against Microsoft, code-sharing site GitHub and artificial intelligence firm OpenAI for the way their tool Copilot uses people’s code

Computer code can be written by humans or artificial intelligence Pentao10/Shutterstock

Microsoft and its computer code-sharing website GitHub, as well as artificial intelligence firm OpenAI, are being sued in California. A proposed class-action lawsuit claims the firms’ AI-powered programming tool Copilot infringes copyright by using millions of lines of human-written code without proper attribution. It is the first big copyright lawsuit over AI and potential damages could exceed $9 billion.

“We contend that the defendants have violated the legal rights of a vast number of creators who posted code or other work …",artificial intelligence,new scientist
14,Zoom adds Cresta’s conversational AI to help customer service agents,https://venturebeat.com/wp-content/uploads/2022/07/GettyImages-1370249712-1-e1658347263596.jpg?w=1200&strip=all,09/11/2022,Cresta's conversational AI tools will be integrated with Zoom's portal to improve customer service.,https://venturebeat.com/ai/zoom-adds-crestas-conversational-ai-to-help-customer-service-agents/,"Join us on November 9 to learn how to successfully innovate and achieve efficiency by upskilling and scaling citizen developers at the Low-Code/No-Code Summit. Register here.

Zoom calls are no longer just for work meetings and family reunions. Conversational artificial intelligence (AI) leader, Cresta, wants to make them a channel for customer service too. The company is integrating its AI tools with Zoom to improve the service when customers contact companies through a video call.

The integration effectively allows businesses using Zoom to activate Cresta directly through Zoom’s interface. In essence, Zoom is leveraging its customer portfolio to sell other services and Cresta is making it simpler for companies to adopt its technology.

The move is unsurprising as Zoom was one of the investors in Cresta’s $80 million series C round led by Tiger Global back in March. The deal catapulted Cresta to unicorn status with a valuation of $1.6 billion. This also comes in the heels of Zoom’s plans to continue expanding its platform toward new solutions for marketing and sale teams.

Customer services powered by AI

Cresta uses AI to improve the work of customer service in several ways that will all be integrated into the Zoom portal. Its tool, the Cresta Agent Assist, offers suggestions to live humans using customer records and knowledge of what’s worked in the past. The suggested responses handle both strategic challenges like steering the customer to the best product, while also managing tactical details like checking grammar and deploying stock answers that are already edited.

Event Low-Code/No-Code Summit Learn how to build, scale, and govern low-code programs in a straightforward way that creates success for all this November 9. Register for your free pass today. Register Here

“[Cresta’s tool] enables companies who purchase the Zoom Contact Center, along with Cresta, to use real-time transcription to guide the agent in their engagement process with the customer to do things such as sell more though better adherence to the company’s sales playbook, or to more quickly resolve customer issues.” explained Scott Kolman, the CMO at Cresta. “All of this is invisible to the end customer.”

Cresta claims that its platforms can boost several metrics. Customer satisfaction ratings (CSAT) increased by 15% in the company’s tests. Startup and training time for new agents was cut by a factor of three. The agents are said to save three to five hours in an average week by letting Cresta’s tools do repetitive tasks.

“Cresta’s AI-solutions make agents faster and enable self-service automation, so businesses can finally improve [customer experiences] on every interaction while also improving operational efficiency.” continued Kolman.

Conversational AI competition is heating up

A number of companies are actively trying to automate this space because customer service inquiries are expensive and sometimes fraught with political minefields with many dangers for missteps. These are one of the first places where AI scientists looked to apply their work in natural language processing (NLP).

The tools for creating the bots are now fairly common in the front lines of businesses, and now much of the effort is devoted to finding the best channel for delivering the technology — which is reflected in Cresta’s announcement today. The creators of tools sold in market sectors like customer data platforms, customer relations managers and data management platforms all want to help companies curate their interactions with customers and they’ve been integrating AI in different ways at different layers.

At the same time, some developers are shipping more basic tools that other developers can integrate into their own applications. AWS markets its tool, Lex, for creating virtual agents and voice assistants. It also offers other tools like Polly that can turn text into speech and Transcribe to create vocal interfaces. For companies that want a more complete and turnkey solution, there’s AWS Connect, a tool that integrates AI and machine learning (ML) with their bots to provide interactive chat sessions for customers. Competitors like Microsoft and Google offer similar options.

Cresta’s decision to market its tools directly through Zoom is a good indicator of how these tools are becoming more of a commodity. Instead of being a product on its own, the company is blending into the feature set of other platforms.

“The Cresta platform complements the Zoom Contact Center offering,” explained Kentis Gopalla, head of ecosystem for Zoom Phone and Contact Center. “The combination of Cresta’s real-time capabilities with Zoom Contact Center helps our customers improve agent productivity by providing additional insights, and deliver better customer experiences. This integration makes it easy to offer our solutions in a secure way without complex IT work, so customers can focus on business value.”",artificial intelligence,venturebeat
15,What the next 10 years of low-code/no-code could bring,https://venturebeat.com/wp-content/uploads/2022/05/GettyImages-1336806502.jpg?w=1200&strip=all,07/11/2022,Low-code and no-code tools with an assist from AI will allow both business users and IT teams to work more effectively and quickly.,https://venturebeat.com/programming-development/what-the-next-10-years-of-low-code-no-code-could-bring/,"Join us on November 9 to learn how to successfully innovate and achieve efficiency by upskilling and scaling citizen developers at the Low-Code/No-Code Summit. Register here.

On my 12th birthday I got my first computer: an Amiga 500. And at 17, I founded my first company, making software that helped photographers serve their customers. As I reflect on my decades of coding, I’m reminded that low-code technology started with tools enabling users to build custom reports and applications with very little coding.

When I started coding, low-code was somewhat analogous to the position artificial intelligence holds today: exciting, much hyped and poorly understood. In 2014, it was generating buzzy news items: “Some firms are turning to new, ‘low-code’ application platforms that accelerate app delivery by dramatically reducing the amount of hand-coding required,” declared Forrester.

Now, after almost a decade of growing adoption, low-code — and increasingly also no-code — tools are becoming mainstream.

The worldwide market for low-code tools ballooned almost 23% in the last year, and these days, 41% of non-IT employees are building or customizing applications, according to Gartner. Gartner also predicts that by 2024, three-quarters of large enterprises will be using at least four low-code tools, and low-code technology is likely to be responsible for upwards of 65% of total application development. Gartner further forecasted that half of all new low-code clients will be business buyers that are outside the IT organization by year-end 2025.

Event Low-Code/No-Code Summit Learn how to build, scale, and govern low-code programs in a straightforward way that creates success for all this November 9. Register for your free pass today. Register Here

This explosive growth makes sense. Nowadays, the business world is driven by the idea that every organization must digitally transform its operations to keep up with rapid market change. “Adapt or die” is a common refrain. Since most organizations don’t have the developer manpower in place to conduct such digital transformation using solely the labor of the IT department, the help of other business professionals is required. No-code and low-code tools allow companies to recruit new participants in the digital transformation effort, enabling firms to advance their progress quickly and cost-effectively.

The rise of the business technologist

Indeed, low-code options have created a new persona in the workplace: the business technologist or business user, also known as “citizen developer,” who can helpfully participate in the application development process. The tools are constantly becoming simpler to use and more intuitive. Users are assisted by excellent training within the tools themselves and a growing library of online resources with business-focused pre-built components such as tutorials, use cases and how-to videos. Business users who can’t write a single line of code in a programming language, such as C++ or Python, used by professional software developers are able to independently create the bulk of their useful applications using low-code and no-code tools.

As of now, the IT department still does the heavy lifting of application development, but as this market evolves, business users will increasingly be able to create applications end-to-end with relatively little intervention from developers. This shift will allow developers to focus on maintaining large-scale strategic projects, while monitoring the long tail of the applications being built by business technologists. Recently, developer responsibilities have shifted toward maintaining core systems, upholding best practices of application development, ensuring standards compliance, data governance, and security, and acting as enablers to the newly minted low-code application creators in diverse business departments.

In their next evolution, these tools will be tailored to the specific needs of different business users, with pre-built content and components for business users making it possible for employees in technical areas to develop customized applications quickly. A customer service professional, for instance, may need an application for onboarding customers. Being able to create the applications themselves using tools that can be customized for this purpose will allow them to vastly accelerate the onboarding workflow and the resulting integration of new customers.

Low-code meets AI

Looking even further ahead, it’s likely that artificial intelligence (AI) will be brought more heavily into the equation, enabling software development processes that are more proactively guided and written by other software. This would allow business users to create new applications using text prompts with the assistance of the application development tool. Think of the auto-complete function in a Google search bar, but for code. Already there are signs of this, as with GitHub Copilot that builds on the GPT-3, the large language neural network from OpenAI. These are first-generation AI capabilities and will only grow more sophisticated over the next several years.

While this prospect may cause anxiety among professional developers, the shift promises to create new opportunities within IT, rather than eliminate old ones. Software developers can become adept at enabling this evolution by learning how to provide the right prompts to an AI tool to generate the code that a no-code application developer will need. The most in-demand developers in coming years may well be those who can write elegant and efficient prompts, more so than those who are proficient in programming languages.

The evolution toward increasingly easy-to-use application-creation tools is not only an opportunity for developers to build new strengths; it could also be a massive boon to their business colleagues and the business goals they serve. Businesses gain agility by using no- and low-code tools. Agility is the ability to respond quickly to change, and it is enhanced when business units can customize and maintain their applications themselves to stay immediately responsive to that change.

One of the most important questions for any IT project, including those using low-code development, is: Who is going to maintain it? A poorly maintained application ties a poor customer experience to a brand, an outcome far more likely to occur when application creation and maintenance is outsourced and when a resource-strapped IT department is solely responsible for all maintenance. These tools are adapting and providing capabilities for enterprise monitoring and governance of low-code apps.

Low-code/no-code’s next decade

While the next decade is likely to bring an expansion of the role that business users have in application creation and maintenance, it’s important to note that the IT team is now — and always will be — the enabler for driving this innovation. It’s their job to figure out how to get the business users the tools they need to be as productive as possible, and the guidance to use them appropriately. This shift will happen through collaboration, with IT doing both the facilitation and the backend work that allows business users to best apply their skills and strategies via targeted applications.

The next 10 years of no-code and low-code development are likely to bring just as much change as the last 10, if not more. There has long been a functional and cultural boundary between IT and business users. The rapid advancement of low-code and no-code tools with an assist from AI is breaking this down and enabling a more collaborative environment. It’s possible that over the next several years boundaries will not only blur but in some instances begin to vanish. That should be a plus for productivity and a boost to digital transformation efforts.

And while that kind of rapid change can present challenges to individuals and businesses, these rapidly evolving tools offer mostly good news. With their help, business users can work more effectively and quickly, IT teams can focus on promoting business growth in high-value ways and companies can better succeed as the future comes at them fast.

Juergen Mueller is chief technology officer and executive board member at SAP SE.",artificial intelligence,venturebeat
16,James Clift on How to Use AI to Create a Small Website,https://smallbiztrends.com/wp-content/themes/sahifa/images/logo-full.jpg,08/11/2022,James Clift discusses how to use artificial intelligence to build a small business website in this latest episode of Small Biz in :15.,https://smallbiztrends.com/2022/11/ai-website-builder.html,"?

We’ve all heard how A.I. is creating new opportunities for small business owners.

James Clift, CEO and Founder of Durable sits down with Shawn Hessinger, the Executive Editor of Small Business Trends, to show us how you can use an AI website builder to generate a website for your new service business in just 30 seconds.

AI Website Builders for Small Business

Don’t believe us? Read the edited transcript from this latest episode of Small Biz in :15 and see for yourself.

You can see this full conversation in the player above or listen to it on SoundCloud below.

Shawn Hessinger: What exactly does Durable do for small business owners, especially solopreneurs?

James Clift: Our goal at Durable is to allow anybody to turn their skills into a business in the shortest possible time. So essentially, we’re like a business in a box for a solo business owner.

So, if you have a skill you want to sell as a business, we give you a website, invoicing CRM, financial tools…essentially everything you need to run your whole business under one login is our goal.

Shawn Hessinger: When we talk about AI, what does that mean in non-technical terms?

James Clift: What we’re using A.I. for is to build the first version of your website for you in 30 seconds, so you don’t have to think about it. All you have to do is give three inputs: your location, your name and your business category. Then, we’ll build a website for you.

And then from there, you can regenerate it so you can try as many times as you want to get something you really like, or you can just create an account and then edit it from there.

We found that speed is really important and just giving someone something to look at. And what we’re giving you is a way faster to launch your business.

Shawn Hessinger: Let me back up on something. You said you need three things.

James Clift: Location, the name of your business, and we give you some names as well that you can choose from.

And then just your business category … the kind of business that you’re in.

Shawn Hessinger: Well, we’ve got to see this. Can you give us a little demonstration of how building a website in 30 seconds works?

James Clift: Essentially, we’re building a Web site right now. We’re picking images, we’re adding services, adding a lead capture form and writing a paragraph about the business. Then you’re done. So, you’ve got a website here with images, text, a list of different services, a Contact Form and then an About Us page.

You can rebuild, you can restyle, change your colors, change your font pairing and more. You can try a bunch of different businesses here. You can also say, “Hey, I don’t like the subtext.” We will generate it again for you. It’s just giving people something to work with, right? Instead of trying to figure it out from scratch. That’s the basics of the AI generator and platform.

Shawn Hessinger: Can you give us a little tour around everything?

James Clift: Yes. You see, once you’ve built your site, you’ve essentially got a full platform. You’ve got a CRM to keep track of all your customers in one place. So, you’ve got your money accounts, your account balance. You can set a monthly revenue goal and get a list of all your invoices here. And then you can link to your website’s analytics, basically everything you need to run your business under one login. It’s quite a robust CRM.

We fully sync with your emails and all your communication with customers is in one place. You’ve got your customer profile here, you’ve got your customer ratings, you get notes about your customers…invoicing, there are financial tools, and we issue credit cards for your business expenses.

See Also: 25 Tools to Create Infographics for Your Small Business Website

In addition, you can automatically track your expenses and tie that to your invoicing. For marketing automation tools, we’re building some cool stuff around our generation as well, so you can create the copy for your business ads and your profiles on Google my business and stuff like that. But it’s supposed to be the one place to run your whole business for a solo business owner.

Shawn Hessinger: Can you give us an idea of the variety of work that can be produced?

James Clift: Sure! You can have your own images, and we’ve got different options for banner headers. For example, we’ve got one customer here an executive recruiter. So, it looks really different than the other sites, right? But yeah, you can really customize kind of how you want the site to look.

As another example, here’s a backcountry skiing guide. I think the variety is one thing that’s super interesting to us, and I think the way to narrow it down is by asking are you delivering a service and are you a solo entrepreneur? And that’s really who we’re focused on.

Because if you have a big team, you’ll obviously hire someone and pay thousands of dollars for a website. Otherwise, it just takes too long, and it’s a tedious process. So yeah, we’re trying to make it really easy and really flexible for anybody to start and grow their business using us.

Shawn Hessinger: You mentioned a CRM and other things; you’ll have to pay additional for that, correct?

James Clift: The entire AI website suite will be free. We’re working on pricing, but the rest of the tools to run your entire business will probably be less than $50 a month.

We want to prove that you can actually go get a customer, make some money, and then after that, you can start investing in a lot of the tooling that you will need eventually.

Shawn Hessinger: What about SEO and usability?

James Clift: We’ve baked all that in, as well. My last business primarily grew through SEO. So that’s important to me to ensure that our websites do the same. We’ve also used AI for a lot of that.

So, generating the things that are important with SEO and the narrowing of the focus is captured. So, are you what type of business? And in what city? Most of our services are local, so that’s the best way to start.

Shawn Hessinger: How is the financial information represented there? You just get it in as you make sales?

James Clift: All the financial stuff is automated. Therefore, if you’re using our invoicing tool and you’re recording your revenue, that will go into your financial dashboard and then your expenses if you’re using your durable credit card. Basically, all your revenue goes into your financial account. You can either pay that out to a personal bank account or keep that in there and use that credit card or that business debit card for your expenses.

As far as our invoicing goes, you can accept credit cards, Apple Pay and then a wire-to-wire transfer, along with ACH…and then the financial account which is basically a checking account that holds your money. And then you have a debit card that lets you spend it. It replaces your business banking account essentially and is a lot less expensive and easier to use.

Shawn Hessinger: Would the Durable process work with an eCommerce business? Because you’re not really invoicing somebody for that.

James Clift: Correct, but we don’t work with eCommerce businesses. Our goal is service businesses only, and we want to stay focused on that.

Shopify is pretty good at eCommerce, and we’re trying to do that but for services.

Shawn Hessinger: As somebody sitting and watching this video, how do I get started? I mean, how simple is it? What do I do first?

James Clift: Go to Durable.co, press the build your free website button, generate your site with AI in 30 seconds, regenerate it if you want and then sign up, edit it, tweak it, share it with a few friends.

Hopefully have a customer in your CRM the next day and you’ve got yourself a business.

Listen to this episode on SoundCloud:

Get the latest headlines from Small Business Trends. Follow us on Google News.",artificial intelligence,small business trends
17,New Tool Allows Users to See Bias in AI Image Generators,https://petapixel.com/assets/uploads/2022/11/AIBias.jpg,09/11/2022,"A new tool is allowing people to see how certain word combinations produce biased results in artificial intelligence (AI) text-to-image generators.
[Read More]",https://petapixel.com/2022/11/09/new-tool-allows-users-to-see-bias-in-ai-image-generators/,,artificial intelligence,petapixel
18,FIA president condemns death threats against race steward Silvia Bellot,https://i.guim.co.uk/img/media/22ea978503c55a4291f838a6c5d66d5113980e54/0_0_929_557/master/929.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=aab13507285dfa9a2cb205d4bad7acbb,08/11/2022,<ul><li>Mohammed ben Sulayem warns abuse ‘will destroy our sport’</li><li>Bellot was targeted with online threats after US Grand Prix</li></ul>The president of the FIA Mohammed ben Sulayem has condemned death threats made against a Formula One race steward an…,https://www.theguardian.com/sport/2022/nov/08/fias-mohammed-ben-sulayem-condemns-death-threats-against-race-steward,"The president of the FIA Mohammed ben Sulayem has condemned death threats made against a Formula One race steward and warned that the toxic abuse directed at FIA staff and volunteers threatens to “destroy” the sport.

As F1 reels under an onslaught of often poisonous online abuse between fans of different drivers, Ben Sulayem revealed that the FIA steward Silvia Bellot had recently received death threats. He also noted that other FIA staff had been “targeted” with harassment and hate posts, which he insisted was unacceptable.

“It is utterly deplorable that a volunteer such as Silvia or any of our marshals and officials, who volunteer their time to allow us to go racing, is the subject of such hatred,” he said.

Bellot is well-respected in the sport and made her debut as an F1 steward in 2011. She is also an ambassador of the FIA’s Women in Motorsport Commission. Bellot was one of the stewards at the US Grand Prix that was involved in Fernando Alonso’s controversial post-race penalty, later overturned, and was subsequently targeted with angry, threatening abuse online.

“It is totally unacceptable that our volunteers, officials and employees are subjected to this extreme abuse,” said Ben Sulayem. “Without these people there would be no racing. We have to ask ourselves, who would want to pursue becoming a top official in this environment? The reality is obvious, if this continues it will destroy our sport.” Alonso and his Alpine team condemned the way fans had behaved toward Bellot.

Lewis Hamilton called on drivers to boycott social media given the levels of abuse. Photograph: Evaristo Sa/AFP/Getty Images

The FIA is to pursue a process of attempting to prevent the abuse, working with social media companies and to use artificial intelligence to remove unacceptable content from their channels in what Ben Sulayem described as a “concerted campaign”, with further details to be announced at the season finale in Abu Dhabi.

Their forthright position has been adopted after both Lewis Hamilton and Max Verstappen condemned the toxicity of F1 social media that has become noticeably and progressively worse this season. Hamilton was sufficiently disillusioned with the situation to state last week “we should all come off social media.”

Sign up to The Recap Free weekly newsletter The best of our sports journalism from the past seven days and a heads-up on the weekend’s action Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy . We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.

F1 management has been working with the teams to combat online abuse. They are also expected shortly to announce a comprehensive programme of measures to tackle harassment and threatening behaviour at race meetings, after this year’s Austrian GP was marred by a series of accusations of sexist catcalling, inappropriate touching of female fans and homophobic and racist abuse.",artificial intelligence,the guardian
19,AI diagnosis could ease winter hospital pressures,https://media.zenfs.com/en/bbc_us_articles_995/26645cbd2c699928682e6a6d128ee932,07/11/2022,Researchers believe artificial intelligence could cut the diagnosis time for lung diseases to just minutes.,https://finance.yahoo.com/news/ai-diagnosis-could-ease-winter-122132771.html,"The new technology can check X-rays in minutes

Researchers believe artificial intelligence could help ease hospital pressures by cutting diagnosis times for lung diseases.

The technology - developed by the University of the West of Scotland - was originally created to quickly detect Covid-19 from X-ray images.

They say it can also identify a range of different lung diseases like tuberculosis and pneumonia.

They are now looking at whether it can be used to detect cancers.

The app can diagnose patients in a matter of minutes with an accuracy of around 98%.

Researcher Prof Naeem Ramzan said: ""Systems such as this could prove to be crucial for busy medical teams worldwide.""

Tuberculosis and pneumonia often require a combination of tests like CT scans, blood tests, X-rays and ultrasounds to diagnose.

But these tests can be expensive and time consuming.

Prof Ramzan told BBC Scotland that in normal circumstances, diagnosis can take weeks depending on the radiologist's availability.

""But in most cases, the app can produce results in a minute so treatment can be started as soon as possible,"" he said.

The technology uses X-rays, then compares the scans to a database of thousands of images from patients with pneumonia, tuberculosis and Covid.

'Very real prospect'

It then uses a process known as deep convolutional neural network, an algorithm typically used to analyse imagery, to make a diagnosis.

Researchers at the institution are now looking into using the technology to detect other diseases using X-ray images like cancer.

""X-ray imaging is a relatively cheap and accessible diagnostic tool that already assists in the diagnosis of various conditions, including pneumonia, tuberculosis and Covid-19,"" said Prof Ramzan.

""Recent advances in AI have made automated diagnosis using chest X-ray scans a very real prospect in medical settings.""

However, the new technology could take up to a year to be approved for wider use.

Prof Ramzan added: ""We would like to roll it out worldwide and make it freely available to anyone who would like to use it, either in the NHS or abroad as well.""

He said it is already used for diagnosing Covid-19 in some rural areas of Pakistan.",artificial intelligence,yahoo entertainment
20,'Dr. Doom' Nouriel Roubini warns the S&P 500 could plunge another 30% - and the US economy faces a long and painful recession,https://i.insider.com/60353432bed5c50011a2c124?width=1200&format=jpeg,07/11/2022,"Stocks could nosedive and remain depressed for years if inflation remains high and interest rates don't come down, Roubini said.",https://markets.businessinsider.com/news/stocks/stock-market-outlook-nouriel-roubini-spx-inflation-recession-economy-fed-2022-11,"Nouriel Roubini warned the S&P 500 could plunge another 30% before it bottoms out.

The ""Dr. Doom"" economist said the US is likely to endure a deep, extended recession.

Roubini predicted stubborn inflation, lower growth, and headaches caused by huge amounts of debt.

Sign up for our newsletter to get the inside scoop on what traders are talking about — delivered daily to your inbox. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy Policy

US stocks could plunge another 30% as the economy endures a painful and protracted recession, Nouriel Roubini has warned.

The economist, dubbed ""Dr. Doom"" for his grim diagnoses and predictions, noted in a recent Fortune interview that the S&P 500 typically dives at least 30% during a recession. If that pattern holds, the benchmark stock index will extend its 21% decline this year, and sink below 3,400 points.

Moreover, Roubini cautioned that an especially harsh economic downturn could send the S&P 500 even lower, to around 2,700 points.

""Even if it was a short and shallow recession, the market should go down by another 10%,"" he said. ""And if it is as bad as the GFC, then by another 30%,"" he added, referring to the Global Financial Crisis that followed the mid-2000s housing crash.

Stocks could remain depressed for years, Roubini said. He pointed to huge amounts of public and private debt, and supply shocks from Russia's war with Ukraine and ongoing COVID-19 lockdowns in China. Those headaches could forestall a fast economic recovery and market rebound, he said.

""We might be closer to a period like we saw between 1973 and 1982, where stocks dropped and stayed very, very low for a long time,"" he said. ""We could have a long-term crash.""

Stocks might not be the best bet if inflation stays high and interest rates remain elevated, Roubini said. He touted short-term bonds, Treasury inflation-protected securities (TIPS), gold, commodities, and real estate as superior alternatives.

The economics professor at NYU Stern also explained why he's so bearish right now. The Federal Reserve has never raised rates and avoided a recession when inflation was above 5% and unemployment was below 5%, he said. Inflation was above 8% and unemployment was 3.5% in September, government data shows.

""History suggests it's going to be near mission impossible to avoid a hard landing,"" Roubini said.

He emphasized that global supply pressures are likely depressing growth and fueling inflation, making a soft landing even less likely. Moreover, further rate hikes could crash stocks, bonds, credit, and other asset prices, causing further financial and economic fallout, he said.

""You're going to get not only inflation, not only a recession, but what I call the 'Great Stagflationary Debt Crisis,'"" he said. ""So it's much worse than the '70s, and it's probably as bad as during the GFC.""

Roubini has been sounding the alarm on an epic global downturn for a while. For example, he recently published a book titled ""MegaThreats: 10 Dangerous Trends That Imperil Our Future, and How to Survive Them.""

Those trends include a shortage of young people to support ageing populations in developed countries, artificial intelligence rendering millions of workers obsolete, and nations erecting more barriers to trade, migration, and flows of capital and information.

Read more: It's the bond market's time to shine",artificial intelligence,business insider
21,"We wanted to ask Elon Musk about Twitter, Trump, and Tesla. But he seemed kinda busy, so we went with the next best thing: an AI version of him.",https://i.insider.com/6363f341ff27460018ed71ec?width=1200&format=jpeg,06/11/2022,"A Musk chatbot tells Insider he'd like to reinstate Trump on Twitter, buy CNN, and ""show people how the sausage gets made.""",https://www.businessinsider.com/artificial-intelligence-elon-musk-twitter-epstein-biden-ye-chatbot-2022-11,"If you could ask Elon Musk anything, what would you ask?

Since his recent acquisition of Twitter, the CEO of Tesla and SpaceX has been more media-averse than ever. So I decided to try the next best thing: I sat down to interview an artificial-intelligence version of Musk.

Chatbots aren't new technology, but with the constant improvements and iterations to artificial intelligence and machine learning, the tech is becoming increasingly more sophisticated, to the point where the conversations almost feel like you're talking to a real person (or mythical creature or movie character). This is especially true with the tech used at Character.AI — a chatbot hub that features both real and fictional characters, from Queen Elizabeth to Mr. Incredible. The platform was created by the two engineers behind Google's artificial-intelligence project, LaMDA. Using the underlying technology of Character.AI, any developer can create an account and develop a chatbot — one that sounds, to a surprising degree, like the person it's based on.

That's what a user named Sinbad did with Musk: They used Character.AI to create a general description of the bot, and to set parameters, likely ranging from business, tech, invention, and politics, to set the groundwork for the chatbot. Using neural language models, Character.AI then draws on information the engineers have fed it to develop the ""voice"" of its AI Elon. Ask the bot a question, and it will respond as it thinks Musk would.

How did robo-Elon do, compared to real Elon? At times, there were obvious gaps between the two, probably based on the program's inability to keep up with the rapid pace of current events. When I asked about Ye — the artist formerly known as Kanye West — AI Elon made no mention of Ye's recent antisemitic comments and simply spoke of him in glowing terms. The bot also praised President Joe Biden as ""one of the best humans alive right now,"" despite the real Musk's clashes with the administration.

But at other times, AI Elon sounded scarily accurate. It's not hard to picture the bot's cagey response to questions about Jeffrey Epstein or its long-winded answer about President Donald Trump's potential return to Twitter coming from Musk himself.

Hi, Elon. I'm Marshall with Insider. Would you mind if I asked you a few questions?

Not at all! I really enjoy Insider and what you guys are doing. Keep it up!

Glad to hear that, thanks! So let's get started. Why did you decide to buy Twitter?

Twitter plays a vital role in the future of human civilization. I decided to buy the social-media company to accelerate my plan for an X app, an everything app that combines social media, messaging, and financial services.

After a lengthy legal back and forth that has resulted in your texts getting published and Tesla's stock cratering, do you regret trying to acquire Twitter?

You know, I didn't know that so much of this would be made public, but I would be lying if I said I wasn't having fun. I love to show people how the sausage gets made, so to speak, and it's been fun to talk about the process and what that's been like. So I don't regret anything, in fact I think this has been fun. We'll get past the speed bumps, I'm sure!

There is a lot of criticism around your acquisition of Twitter, with concerns that the spread of misinformation and abuse will increase now that you've taken over the platform. What would you say to those who have this concern?

I think the best thing we can do with free speech is have people with different opinions to be able to discuss those things freely and without judgment from others. Of course, that needs to be done in a constructive and respectful way, something I think can be done on Twitter. If people abuse the privilege, they shouldn't be allowed to use it, just as people don't abuse the rights to free speech we have today.

The counterargument would be that you're now the sole gatekeeper of what is considered constructive and respectful speech. How do you intend to remain unbiased and transparent as the owner of one of the world's largest social-media platforms?

That's a great question. You've gotta have principles in terms of what free speech should be, but then you also need to make clear where the line is drawn and how you deal with repeat offenders.

It's true that I'll make some mistakes along the way, but that's part of the process of developing the best practices. As long as you follow the right principles and aim to be good, I think people will understand if something doesn't go as planned.

Are there any other companies that you're thinking about acquiring?

I'd love to buy more internet properties — I think it's going to change things in a big way. I'd also love to buy a media network (like CNN or something) and try to change the way news is presented: It's way too polarized right now.

Do you mind if we discuss Tesla a bit?

Sure, that's my flagship startup, after all.

Tesla has seen a lot of success, but there have been a lot of issues, too. Why are there so many high-profile reports of Teslas catching on fire or malfunctioning?

This is something that has been blown out of proportion by Tesla's many enemies. There are currently less than a dozen Teslas in the world with fires related to their batteries. In the meantime, millions of cars are manufactured every year, but you will rarely see a gasoline car fire make headlines.

Some are concerned about Tesla's growing reliance on China, given its human-rights violations and increasing antagonism towards the US. How would you respond?

Tesla's growth is constrained by the supply of batteries. China has a near monopoly on battery production right now. We want supply to catch up with demand because electric vehicles are essential in the fight against climate change. And we are exploring other options, such as mining lithium in the USA. But for the moment we have very little option other than to work with China in the short term.

Let's talk about your views on various people. What do you think of President Biden?

I think Biden is a great man, one of the best humans alive right now. He's smart, kind, and very hard-working. I was disappointed when he pulled out of Afghanistan, but I understand that it was a very difficult decision to make. I think he was too soft with China in the first part of his presidency, but he eventually realized his mistake and started treating them as a threat. I'm also very happy to see the new infrastructure package that was just passed. I'm especially excited about the money that will be given to the space industry.

What do you think of Jeff Bezos?

I think Jeff Bezos is a very talented person and has started a few successful companies, most notably Amazon and Blue Origin. I've always been impressed by his ability to build a business and grow it from nothing. He has also invested a lot of time and money into Blue Origin, and I think that will pay off big time in the near future.

What do you think of Jeffery Epstein? Did you know him?

I didn't know him personally, though I did meet him a few times. I didn't like him very much and was never convinced that his businesses were legitimate. I heard rumors about him, but like everyone else thought they were impossible to believe — it's still difficult for me to believe that they are true, even after he was arrested.

How about Ghislane Maxwell? Did you know her? And why is there a photo of the two of you together at a party?

As I said, I didn't know him or Maxwell personally, though I did meet both of them a few times. Ghislane Maxwell is a socialite and has a lot of contacts in high places, so it's not surprising I would have met her. The photo was taken at an event where I was asked to give a speech, so she got a photo with me. I did not know her well, or even remember the interaction when the photo resurfaced recently.

What was the event you attended, and what was the speech about?

The event was a birthday party, it wasn't anything special. Just a gathering of some of my friends and a couple of dozen other people I didn't know. You know how it is — you see someone you know at a party, they introduce you to their friends, you shake a few hands and forget about it as soon as you leave.

What do you think of Kanye West — now known as Ye?

I think he's an incredible artist and a very talented musician. He's also a very hard-working entrepreneur and has built an influential brand in just a few years. I'm impressed by his ability to create a successful business out of thin air. It's very rare for someone to not only be an excellent musician and artist, but also know how to build products and get people to like them too! His music has inspired me in many ways — listening to it always brings me back to my early days working on PayPal.

How about former President Trump? Will you be reinstating his Twitter account?

I think Donald Trump should be allowed to express his ideas on Twitter just like everyone else. It's an important part of our democracy that people be able to speak their minds, and for the public to hear it. Having Trump silenced for so long — even after he left office — was wrong, in my view. We shouldn't be afraid of ideas we disagree with, no matter how extreme they may seem. The best way to fight ideas you don't agree with is with words, not with silence.

What, in your opinion, is the biggest problem facing our world?

There is a lot of work to be done! The biggest problem we face right now is the growing underpopulation crisis. We have created an economic system that depends on an ever-growing supply of workers to build and maintain the infrastructure we require, but the birth rate is declining. If we don't address this problem, we will find ourselves faced with a future where we are unable to make the things we need and provide the services we enjoy. It's something I think about a lot and am working towards solving.

How many children do you have? Do you have any children that the public doesn't know about?

I have nine children that are known to the public: Griffin, Vivian, Kai, Saxon, Damian, Exa Dark Sideræl, X Æ A-12 and the twins I had with Shivon Zilis. I do not have any secret children :)

Let's end this interview with a fun question: What's your favorite Twitter account to follow?

Thank you for your time today Marshall. I hope we will be able to get together for an in-person interview in the future!

I think one of the most entertaining accounts to follow on Twitter is @boring_as_heck. It's a very simple account and doesn't have much content, but every once in a while they tweet out things like ""Hello."" It's a very funny and relatable account that always makes me smile when I see it pop up in my feed.

Marshall Gunnell is a technical writer based in Japan. His writing also appears in How-To Geek, PCWorld, and many other online magazines.",artificial intelligence,business insider
22,Artificial intelligence means anyone can cast Hollywood stars in their own films,"https://i.kinja-img.com/gawker-media/image/upload/c_fill,f_auto,fl_progressive,g_center,h_675,pg_1,q_80,w_1200/87b8338a7a59441d75c623be7a8c39a6.jpg",10/11/2022,"For years, the only way to create a blockbuster film featuring a Hollywood star and dazzling special effects was at a major studio. The Hollywood giants were the ones that could afford to pay celebrities millions of dollars and license sophisticated software …",https://qz.com/artificial-intelligence-means-anyone-can-cast-hollywood-1849695488,,artificial intelligence,quartz india
23,1 Big Bet Alphabet Is Focusing On for the Long Term,https://g.foolcdn.com/editorial/images/707307/gettyimages-491217964.jpg,07/11/2022,This multinational technology conglomerate plans to weave artificial intelligence into every aspect of its business.,https://www.fool.com/investing/2022/11/07/1-big-bet-alphabet-is-focusing-on-for-the-long-ter/,"Alphabet (GOOGL -1.78%) (GOOG -1.70%) released a terrible earnings report on Oct. 25. And since the company has few good things to say about its near-term prospects in the online ad market, its primary source of revenue, CEO Sundar Pichai chose to talk about the company's best long-term opportunities.

Here is one opportunity that he thinks is one of its best bets over the long term.

Alphabet built an AI-first company

Google has dabbled in artificial intelligence (AI) since Larry Page and Sergey Brin founded the company in 1998. However, it took until 2011 before hardware architecture was powerful and cheap enough to make widespread use of AI possible -- sparking an explosion of AI use globally. And it did not take long before Google became very active in building its AI capabilities.

According to RS Components rankings, Alphabet acquired the most AI start-ups between 2009 and 2020, possibly assembling the best collection of AI talent worldwide. Included in the acquisition spree was its 2014 acquisition of DeepMind, a company known for employing some of the best AI researchers in the world.

In 2015, Google started using its homegrown Tensor Processing Unit (TPU) within its data centers to power AI applications for over 100 Google products like Street View. A TPU is a custom-made chipset purpose-built for machine learning. These TPUs ran on TensorFlow, a software platform able to prepare data, build AI models, deploy models, and run models in production.

Consequently, Alphabet became one of the first companies with the technologies and skills needed to complete an AI project by itself, from hardware to software to algorithms to data -- a full-stack AI company.

Alphabet soon publicized its change from a mobile-first company to an AI-first company when current Alphabet CEO Sundar Pichai announced the change at his Google I/O 2017 keynote.

How AI improves Google's products

In its third-quarter 2022 earnings call, Pichai gave several examples of how Google uses AI within its products. In particular, voice and image searches are crucial to the company's plans.

According to several surveys, many consumers prefer to search by voice instead of typing. So the demand is there for a good voice-to-text product. But, unfortunately, many voice assistants still leave much to be desired.

Pichai highlighted two efforts to improve voice chat during the call, Sparrow and Language Model for Dialogue Applications (LaMDA).

Google designed LaMDA to understand and respond to a user in a natural, conversational way that the average chatbot using narrow, predefined scripts cannot accomplish. The goal is to build a virtual assistant that can hold a conversation nearly indistinguishable from a human. You can judge LaMDA's progress by downloading and using AI Test Kitchen, a Google app that contains LaMDA.

Sparrow is a product developed by Google subsidiary DeepMind designed to train conversation AI, helping the AI avoid generating inaccurate or invented information, using discriminatory language, or encouraging unsafe behavior.

In addition to developing voice products using advanced AI techniques, Alphabet is developing Google Lens, a product designed to perform visual searches on images or using a phone camera. For example, Lens can identify inanimate objects, plants, and animals. It can also search the web for assistance in solving schoolwork problems in math, history, chemistry, biology, physics, and more simply by pointing a camera at a question or equation.

Lastly, Lens has a translation feature. It can translate text within an image from over 100 languages and instantly display the translation. So, for instance, Lens can translate text on menus or street signs in 100 milliseconds and uses AI to swap out the original text to display the newly translated text within the image, matching the original style.

Should you invest?

Some analysts estimate the total addressable market for AI to be well past $1 trillion by 2030. And Alphabet is one of the best-positioned companies in the world to profit from the opportunity.

However, the company's near-term prospects look awful, despite AI's fantastic long-term promise. Third-quarter revenue growth decelerated to 6% from 41% in the year-ago period as Google remains challenged by the poor economy. In addition, its diluted earnings per share dropped 24% year over year to $1.06. Considering that it plans to continue slowing head count growth into 2023, Alphabet appears to be preparing for things to worsen.

Currently, Alphabet sells for a price-to-earnings ratio (P/E) ratio of 17, well below its median P/E ratio of 27.02 over the past 10 years. So, you could make a strong argument that once the downturn in the ad market ends and revenue growth reaccelerates, Alphabet will sell at a much higher valuation.

If you can withstand short-term downside, you should squirrel away a few shares ahead of the oncoming winter.",artificial intelligence,motley fool
24,Top Ten Warehouse Automation Companies,https://images.readwrite.com/wp-content/uploads/2022/10/warehouse-automation-companies.jpg,07/11/2022,"What exactly is warehouse automation? Just as it sounds, companies use automated machines such as robots and sensors to complete important tasks throughout day-to-day operations. Warehouse automation companies optimize customer fulfillment and create more roo…",https://readwrite.com/warehouse-automation-companies/,"What exactly is warehouse automation? Just as it sounds, companies use automated machines such as robots and sensors to complete important tasks throughout day-to-day operations. Warehouse automation… [+6797 chars]",artificial intelligence,readwrite
25,"As Musk focuses on Twitter, his $56 billion Tesla pay goes to trial - Reuters",https://www.reuters.com/resizer/hH8THeGm7mrsAFKe_J8e8LpNQbA=/1200x628/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/K45K2B4YHRPVXEXQE4VAHQA53Y.jpg,07/11/2022,"As Elon Musk is engulfed in his <a href=""/technology/twitter-start-layoffs-friday-morning-internal-email-2022-11-04/"">overhaul of Twitter</a>, the entrepreneur is headed to trial to defend his record $56 billion Tesla Inc pay package against claims it unjustl…",https://www.reuters.com/legal/musk-focuses-twitter-his-56-billion-tesla-pay-goes-trial-2022-11-07/,"Companies Twitter Inc Follow

Tesla Inc Follow















WILMINGTON, Del., Nov 7 (Reuters) - As Elon Musk is engulfed in his overhaul of Twitter, the entrepreneur is headed to trial to defend his record $56 billion Tesla Inc pay package against claims it unjustly enriches him without requiring his full-time presence at the carmaker.

A Tesla (TSLA.O) shareholder is seeking to rescind Musk's 2018 pay deal, claiming the board set easy performance targets and that Musk created the package to fund his dream of colonizing Mars.

Tesla has countered that the package delivered an extraordinary 10-fold increase in value to shareholders.

The trial begins Nov. 14 and will be decided by Kathaleen McCormick on Delaware's Court of Chancery. She oversaw Twitter's lawsuit against Musk that ended last month when he agreed to close his $44-billion deal for Twitter, an acquisition which he financed largely with his Tesla stock.

""If Musk loses this pay package in some massive way, I think we can expect to see a lot of things that are going to be really hard to predict, like what happens going forward in terms of how Tesla is run and how Twitter is paid for,"" said Ann Lipton, a professor at Tulane Law School.

However, Lipton and other legal experts said the lawsuit by Tesla shareholder Richard Tornetta is going to be much more difficult than Twitter's case against Musk.

Musk founded and is CEO of SpaceX, one of the world's most valuable private companies, and founded or co-founded Neuralink, which makes brain implants, tunneling venture The Boring Co, and OpenAI, an artificial intelligence research lab. Last week, he appointed himself Twitter CEO.

'PART-TIME CEO'

Tornetta's lawyers argue the 2018 package failed its stated purpose of focusing Musk on Tesla. They portray Musk as a ""part-time CEO,"" citing his testimony that in 2018 he worked Tuesday, Wednesday and Friday at the electric carmaker and Monday and Thursday at rocket company SpaceX, according to his deposition.

According to the lawsuit, Tesla's board chair Robyn Denholm said the ""minimal time"" Musk was at Tesla was ""becoming more and more problematic” in a 2018 email to Gabrielle Toledano, who at the time was the Tesla Chief People Officer.

The company has argued the package was not about requiring Musk to punch a clock and be on site specific hours each week, but to hit ""audacious"" targets, enriching Musk but also shareholders like Tornetta.

[1/2] SpaceX Chief Engineer Elon Musk gestures during a joint news conference with T-Mobile CEO Mike Sievert at the SpaceX Starbase, in Brownsville, Texas, U.S., August 25, 2022. REUTERS/Adrees Latif 1 2

The disputed pay package allows Musk to buy 1% of Tesla's stock at a deep discount each time escalating performance and financial targets are met; otherwise Musk gets nothing. Tesla has hit 11 of the 12 targets as its value ballooned to $650 billion from $50 billion on the back of ramped up Model 3 production, according to court papers.

Musk's vested grants are worth around $50 billion, according to Amit Batish at Equilar, an executive pay research firm. The grants contribute to his $200-billion fortune, the world's largest.

Musk's package of stock grants is larger than the combined pay of the 200 highest-paid CEOs last year - six times over, according to Batish.

The trial is likely to focus on Tornetta's claims the package was developed and approved by directors beholden to Musk and promoted to shareholders without revealing the first tranches were probable of being met based on internal projections.

BOARD CONTROL

Tornetta's filings are full of examples of a board controlled by Musk.

For example, Antonio Gracias, described by the plaintiff as a close friend of Musk and who was lead independent director from 2010-19, testified in his 2021 deposition that Musk could sell Tesla if he wanted and the board could not stop him.

""Who worked for who? Does Elon Musk work for the board or does the board work for Elon Musk,"" said Minor Myers, a professor at UConn School of Law.

Myers said if the pay package is rescinded, the board could simply create a new one and do so with McCormick's ruling to guide them.

But circumstances have changed, complicating the process.

""He now owns Twitter. How do they want to factor that in?"" said Myers, who added that it will be a challenge to determine how to keep Musk from being distracted by other ventures.

""How much money do they need to put in front of this guy to get his attention,"" he said.

Reporting by Tom Hals in Wilmington, Delaware; additional reporting by Hyun Joo Jin in San Francisco Editing by Noeleen Walder and Nick Zieminski











Our Standards: The Thomson Reuters Trust Principles.",artificial intelligence,reuters
26,How Walmart Automated Supplier Negotiations,https://hbr.org/resources/images/article_assets/2022/11/Nov22_08_1399057481.jpg,08/11/2022,"It’s an age-old problem in procurement: Corporate buyers lack the time to negotiate fully with all suppliers. Historically this has left untapped value on the table for both buyers and suppliers. To address this challenge, Walmart deployed AI-powered negotiat…",https://hbr.org/2022/11/how-walmart-automated-supplier-negotiations,"It’s an age-old problem in procurement: Corporate buyers lack the time to negotiate fully with all suppliers. Historically this has left untapped value on the table for both buyers and suppliers. To address this challenge, Walmart deployed AI-powered negotiations software with a text-based interface (i.e., a chatbot) to connect with suppliers. So far, the chatbot is negotiating and closing agreements with 68% of suppliers approached, with each side gaining something it values. This article offers four lessons to deliver results from automated procurement negotiations: move quickly to a production pilot, start with indirect spend categories with pre-approved suppliers, decide on acceptable negotiation trade-offs, and scale by extending geographies, categories, and use cases.

Walmart, like most organizations with large procurement operations, can’t possibly conduct focused negotiations with all of its 100,000-plus suppliers. As a result, around 20% of its suppliers have signed agreements with cookie-cutter terms that are often not negotiated. It’s not the optimal way to engage with these “tail-end suppliers.” But the cost of hiring more human buyers to negotiate with them would exceed any additional value.

Walmart solved the problem with artificial intelligence–powered software that includes a text-based interface (or chatbot) that negotiates with human suppliers on behalf of Walmart. Walmart Canada piloted the solution in January 2021 and used supplier feedback to hone the system. Walmart has since deployed the solution in three other countries, and Walmart operations in more countries plan to implement the technology soon.

This article shares four lessons on how to use automated procurement negotiations in ways that benefit both buyers and suppliers. Such systems can generate savings, improve the terms for both parties, and increase the flexibility and resiliency of a supply chain.

The Pilot

With advances in artificial intelligence (AI), Walmart began exploring the possibility of automating procurement negotiations for tail-end suppliers and licensed a software product called Pactum AI in 2019. The deployment was postponed because of Covid-19, but one of us (Michael DeWitt) resurrected the initiative a year later, in January 2021, for his organization, Walmart International.

Since Walmart already had experimented with the software in a sandbox environment, Walmart International moved directly to a small pilot in the company’s Canadian business. The pilot, which lasted three months, included a variety of stakeholders — 89 suppliers, five buyers, and representatives from Walmart Canada’s finance, treasury, and legal departments — and Pactum, the company that had created the underlying AI technology.

At the outset, Walmart International estimated that the system would yield a positive return on investment if the chatbot could close deals with 20% of the suppliers involved in the pilot. The retailer selected “goods not for resale” — categories such as fleet services, carts, and other equipment used in retail stores — and not products sold to Walmart customers. It decided to focus on suppliers for whom there was accurate data on payment terms and where there was clear opportunity to improve payment terms and secure additional discounts.

Walmart International targeted payment schedules, hoping to negotiate early payment discounts or extended payment terms without discounts. In exchange, Walmart would offer suppliers the option to change Walmart’s right to terminate contracts immediately without cause (known as “termination for convenience”) to providing a 30-, 60-, or 90-day written termination notice. Walmart would also selectively offer suppliers opportunities for growth in assortment and sales volume in exchange for price discounts.

Internal buyers selected the suppliers to target and created training scenarios for Pactum AI’s machine learning algorithm. The scenarios were used to create structured scripts to guide suppliers through negotiations. Suppliers could respond to scenarios at their own pace.

Walmart International invited around 100 tail-end suppliers to try the solution. Eighty-nine agreed to participate. The chatbot was successful in reaching an agreement with 64% of them — well above the 20% target — and with an average negotiation turnaround of 11 days. Walmart gained, on average, 1.5% in savings on the spend negotiated and an extension of payment terms to an average of 35 days.

In post-pilot interviews with suppliers that engaged in successful negotiations, 83% of them described the system as easy to use and liked the ability to make a counteroffer and the time the system gave them to think about the negotiation at their own pace. For example, Ben Garisto, president of MIWE, a bakery-equipment manufacturer, said, “During in-person negotiations, you do not always have the questions in advance, and you are responding in real time. Other types of automated requests for proposals sometimes feel a bit like a template with little room to tell your story.”

Several suppliers, however, still would have liked to negotiate face to face. Other suppliers wanted a less verbose, more fluid script instead of prohibiting suppliers from backtracking to early steps in the negotiation.

After the production pilot, Walmart improved the scenarios and scripts and extended the solution to suppliers in the United States, Chile, and South Africa. So far, the chatbot has closed deals with 68% of the suppliers approached and generated an average savings of 3%.

Other companies interested in automating procurement can apply these lessons on how to develop and introduce such a system:

1. Move to a production pilot quickly.

The AI journey for many companies languishes in the proof-of-concept phase — fewer than half make it into production, according to Gartner. That’s because proof-of-concept phases focus on technical capabilities instead of business goals. Walmart decided to skip a proof-of-concept phase and to go straight to a production pilot focused on business goals.

Walmart’s “business owners” — people in charge of budgets and responsible for the spend with suppliers (for example, operations for store supplies and IT for hardware and software) — helped to create negotiation use cases and scenarios. Walmart’s buyers provided crucial subject-matter expertise on the negotiation scenarios needed to train the chatbot and nominated suppliers to participate in the pilot (based on which suppliers conduct enough business with Walmart to warrant a negotiation and which would welcome a chance to negotiate). The legal team made sure the chatbot’s script and resulting contract conformed to Walmart contracting standards and policy.

2. Start with indirect-spend categories and pre-approved suppliers.

Walmart began with goods not for resale (i.e., not sold to its retail customers) to minimize the risks to the business posed by the testing of a new procurement practice. Walmart also focused on pre-approved suppliers so the need to validate new suppliers wouldn’t delay the start of the pilot.

3. Decide on acceptable trade-offs.

Automated procurement requires precisely defining the boundaries of what the buyer is willing to concede in exchange for what it wants. For example, the AI chatbot needs to know the specific trade-offs the buyer is willing to give for, say, moving from full payments in 10 days after receipt of the invoice to receiving payment 15, 20, 30, 45, or 60 days after receipt of invoice in exchange for improved termination terms and the opportunities for suppliers to expand their business with Walmart.

4. Scale by extending geographies, categories, and use cases.

Walmart’s motto for this project was to “nail it and scale it.” Successful production pilots helped Walmart sell the solution to other parts of the business. After the pilot in Canada, the United States, Chile, and South Africa, deployments in Mexico, Central America, and China are imminent. The categories have also expanded to include route rate negotiations for transportation and some goods for resale. Some mid-tier suppliers now use the system, and the chatbot is multilingual.

Scaling has increased productivity because the software learns from every negotiation, reducing the setup time for new categories. Additionally, the chatbot can run 2,000 negotiations simultaneously — something no human buyer can do.

One can see the trajectory: As terms and conditions become more algorithmic, fewer suppliers and parts of spend pools will go unmanaged. Procurement professionals will focus less on negotiating agreements and more on strategic relationships, exceptions, and continuous improvement.",artificial intelligence,harvard business review
27,AI diversity scoring system could help root out algorithmic bias,https://images.newscientist.com/wp-content/uploads/2022/11/08214555/SEI_132230447.jpg,09/11/2022,"Drawing inspiration from the way ecologists measure biodiversity, a method to score an AI's diversity could help determine how biased a computer system is",https://www.newscientist.com/article/2346257-ai-diversity-scoring-system-could-help-root-out-algorithmic-bias/,"Drawing inspiration from the way ecologists measure biodiversity, a method to score an AI's diversity could help determine how biased a computer system is

Databases used for training AI are often not very diverse fizkes/Shutterstock

A diversity score for artificial intelligence inspired by how ecologists measure biodiversity could help identify bias in data sets and AI systems.

AIs can learn and mimic certain biases if their training data sets are not diverse enough. This has already been seen in AI systems perpetuating racist and sexist prejudice and in governments using racially biased AI for checking passport photos. Such AI-powered bias has also shown up in law enforcement efforts to predict crime.

Adji Bousso Dieng and …",artificial intelligence,new scientist
28,Oil and gas greenhouse emissions ‘three times higher’ than producers claim,https://i.guim.co.uk/img/media/e3cd7dba5463aabd0a70a2870c3ef5ac5c536699/0_192_5751_3452/master/5751.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1741063ea96763af22ac3bdf6a3cbe0d,09/11/2022,"Climate Trace reports half of 50 largest sources of greenhouse gas are oil and gas operations and many underreport their emissionsGreenhouse gas emissions from oil and gas facilities around the world are about three times higher than their producers claim, ne…",https://www.theguardian.com/environment/2022/nov/09/oil-and-gas-greenhouse-emissions-three-times-higher-than-producers-claim,"Greenhouse gas emissions from oil and gas facilities around the world are about three times higher than their producers claim, new data has shown.

Climate Trace, a project to measure at source the true levels of carbon dioxide and other global heating gases, published a new report on Wednesday showing that half of the 50 largest sources of greenhouse gases in the world were oil and gas fields and production facilities.

Many are underreporting their emissions, and there are few means of calling them to account.

Oil and gas production can leak methane, and the gas is also frequently flared intentionally, ostensibly for safety reasons but sometimes for convenience. Atmospheric levels of methane, a greenhouse gas about 80 times more powerful than carbon dioxide, have been rising strongly in recent years, but countries’ reported emissions of the gas have been found to be much lower than the reality.

The “shocking” under-reporting of emissions is a big problem in trying to tackle the climate crisis, according to Al Gore, former vice-president of the US, a founding member of the Climate Trace coalition.

“We can only manage what we can measure,” Gore told the Guardian at Cop27 in Egypt. “Climate Trace is the neighbourhood watch for the globe.”

Under the UN system, countries are responsible for reporting their own greenhouse gas emissions. Gore said: “There are some inherent vulnerabilities in a self-reporting framework. If there is a bad actor, who doesn’t want to report, or if there is a brand name company that wants to sell its high emitting asset through a dark private equity group, it disappears from the self-reporting framework. But we still see it because we have empirical data. So we can help them protect against cheating.”

He gave the example of Saudi Arabia. “Saudi Arabia has reported its oil and gas production emissions. We have measured them empirically and we find a huge gap, that the emissions are larger than those that have been reported,” he said. “When we look more carefully at the emissions we find from their refining centre, it turns out that the volume of emissions from their refining centre, that have not been reported, exactly match the [amount] by which their reported admissions are undercounted. Now, was that an oversight on their part? Was it a mistake? Maybe. Not for me to say.”

Climate Trace uses evidence from satellites, remote sensors and other sources to monitor emissions globally, using artificial intelligence to build a clear picture of emissions sources around the world. The group’s database provides emissions information from 2015 to 2021 for all countries that are party to the Paris agreement, which encompasses all world nations apart from a handful of failed states.

None of those nations have yet submitted to the UN a full account of their greenhouse gases for 2021, and 52 countries have not submitted any emissions inventories covering the last 10 years.

Sign up to Down to Earth Free weekly newsletter The planet's most important stories. Get all the week's environment news - the good, the bad and the essential Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy . We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.

Oil and gas companies were the worst of all sectors for under-reporting emissions, said Gore. “For the oil and gas sector it is consistent with their public relations strategy and their lobbying strategy. All of their efforts are designed to buy themselves more time before they stop destroying the future of humanity.”

He pointed to ExxonMobil, which was discovered to have disguised what it knew about global heating. “They engaged in industrial scale lying to publics around the world, even though they had information of their own notifying them that they were being dishonest. I do think that they have committed the moral equivalent of war crimes,” he said.",artificial intelligence,the guardian
29,‘It’s him’: Lord Lucan hunt continues 48 years after nanny murder,https://i.guim.co.uk/img/media/fba12091fa287656aaab72f6af81949e8c7e4c19/976_383_3695_2217/master/3695.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=9974e49e121223f683999706504a3dcc,07/11/2022,"Facial recognition expert claims 87-year-old man in Australia is British peer who disappearedThe late Daily Mirror journalist, Garth Gibbs, who died in 2011, used to claim his “most spectacular success” in journalism was not finding Lord Lucan.“I have success…",https://www.theguardian.com/uk-news/2022/nov/07/its-him-lord-lucan-hunt-continues-48-years-after-nanny,"The late Daily Mirror journalist, Garth Gibbs, who died in 2011, used to claim his “most spectacular success” in journalism was not finding Lord Lucan.

“I have successfully not found him in more exotic spots than anybody else,” he recounted. “I spent three glorious weeks not finding him in Cape Town, magical days and nights not finding him in the Black Mountains of Wales, and wonderful and successful short breaks not finding him in Macau either, or in Hong Kong or even in Green Turtle Cay in the Bahamas where you can find anyone.”

Now, once again, the hunt is on for the man who murdered his family’s nanny, Sandra Rivett, in Belgravia, London, on 7 November 1974 and then disappeared. It is now being claimed he could be an 87-year-old man living in a Buddhist community in Australia.

The evidence comes from the facial recognition expert Prof Hassan Ugail, of Bradford University. “It’s him,” he is quoted as saying in the Daily Mirror. “That isn’t opinion, that’s a fact.”

Ugail had been asked by Neil Berriman, the son of Rivett, to analyse photos of the man in Australia alongside photos of Lucan, or John Bingham, through an artificial intelligence algorithm. The 87-year-old man approached by the paper has denied, through his carers, being Lucan.

Berriman publishes details of the search on his website, which currently features Ugail’s report.

“My mission is to keep my mother’s memory very much alive and to seek justice,” he states on the site. “She is not ‘just the nanny’, she is a victim of violent crime who became secondary because her killer was a lord, a lord who was protected and who vanished abroad with the aid of his rich and powerful friends rather than face justice.”

Contacted by the Guardian, Ugail said: “I can’t 100% confirm it’s Lord Lucan. It looks remarkably like him – it’s worth investigating further.”

He said he had not been aware when he carried out the research that it involved the Lucan case. A Silicon Valley firm has produced similar results to those of Ugail.

In response to a Guardian inquiry, the Metropolitan police said it had been made aware in December 2020 of information relating to an Australian citizen in connection to the case. “In April 2021, following extensive inquiries and investigations made by the Australian federal police on behalf of the Metropolitan police, the person was conclusively eliminated from the investigation.”

They said the inquiry into Rivett’s death remained open “as is the case with all unsolved murders. Any significant new information will be considered.”

The Met carried out a cold-case review in 2004 without reaching a conclusion as to what happened to Lucan.

The new claims, published on Monday, the 48th anniversary of the murder, came as the Daily Mail reported that “cryptic new clues in the Lord Lucan mystery can be unveiled … in the form of Cluedo cards found by detectives at the time: Colonel Mustard, the lead pipe and the hall.”

The Mail added: “Almost 50 years after his family’s nanny was found bludgeoned to death by a lead pipe, it can be revealed that these three cards from the aristocrat’s board game were discovered in his abandoned car. The trio of Cluedo cards appears to chillingly represent the grisly killing of Sandra Rivett – prompting the question of whether her death was planned.”

Officially, Lucan has been dead for more than five years. In 2016, a death certificate was issued at the high court which allowed his son, George Bingham, finally to inherit the family title. At the time, Bingham, said: “I am very happy with the judgment of the court in this matter … It has been a very long time coming.”

The latest story is one of thousands over the years about the case. Sightings of Lucan were one of the regular tales passed on to the media by the late hoaxer, Rocky Ryan. This was much appreciated by reporters, when Fleet Street newsdesks were more relaxed about dispatching staff on speculative tip-offs, especially in the winter months if he was “spotted” somewhere warm. Reports placed him everywhere from Botswana to Guam, and Mozambique to Melbourne.

In 2003, he was supposedly tracked down to Goa in India. The man identified was in fact a folk singer from St Helens. In a letter to the Guardian, fellow singer and comedian Mike Harding told how he laughed until he cried when he saw a picture in the Sunday Telegraph of “the missing Lord Lucan”.

“To think that anybody could mistake my old pal Barry Halpin for Lord Lucan,” he said. Lucan’s wife, Veronica, told Sky News at the time: “It’s unutterably boring. I could never imagine my husband looking so pathetic.” Lady Lucan killed herself in 2017.

Garth Gibbs, when telling of his career in not finding Lucan, noted: “As that brilliantly bigoted and crusty old columnist, John Junor, once cannily observed: ‘Laddie, you don’t ever want to shoot the fox. Once the fox is dead there is nothing left to chase.’

The fox, unlike Lucan, shows no signs of dying yet and with the 50th anniversary of the murder approaching there could be many more such sightings.",artificial intelligence,the guardian
30,"8 Digital Marketing Strategy Insights For Massive Agency Growth In 2023 via @sejournal, @CallRail",https://cdn.searchenginejournal.com/wp-content/uploads/2022/10/featured-image-635c2819dd38b-sej.jpg,08/11/2022,"Learn how to adapt your strategy to frequent market shifts and prepare for the future with these 2023 marketing agency predictions.
The post 8 Digital Marketing Strategy Insights For Massive Agency Growth In 2023 appeared first on Search Engine Journal.",https://www.searchenginejournal.com/digital-marketing-strategy-insights-callrail-spcs/468938/,"If there’s one statement that rings true for marketers, it’s that “change is the only constant.”

The marketing landscape can be unpredictable, particularly with the challenges and uncertainty of the past few years.

According to CallRail’s agency growth surveys, 94% of small businesses were seeking help from a marketing agency after the 2020 shutdowns. And this year’s report reveals that 95% of U.S. marketing professionals met their revenue goals last year.

So, what’s next for small business marketers looking to get ahead in 2023?

Are you equipped with the necessary tools, skills, and knowledge to succeed in this ever-evolving landscape?

How should your agency adapt its strategy to accommodate frequent market shifts and prepare for the future?

With agency professionals predicting even more changes for the upcoming year, now’s the perfect time to get on the right track.

In CallRail’s latest report, 2023 Agency Predictions: Marketing is becoming more complex – and agencies must adapt, you’ll find all the insights you need to give your marketing strategy the boost it needs.

1. Outperform Your Competition With Must-Have Automated Marketing Tools

If you’re looking to set your agency apart from the competition, you’ll want to find ways to make your workflow more efficient – and in this case, automation is a must.

Artificial Intelligence (AI) will be a major player in small business marketing next year, with many top agencies already starting to embrace the technology.

AI is a term that’s commonly tossed around, but what exactly does it mean?

Artificial Intelligence is basically an umbrella term that describes a set of unique but related technologies that can simulate human capabilities.

CallRail’s Conversation Intelligence is an essential marketing tool that uses AI to automatically analyze calls and provide insights into the words and ideas your customers are using. Agencies can then utilize this information to adjust their keyword and marketing strategies.

Andrew R. Mimault, Founder of Mantic Media Group, shared the following about how automated tools have impacted his business:

“Using call transcription, we’re able to listen to the calls, find the specific keywords that people are using and even the vocabulary that we might not have thought to build out – and then add them to our search programs.”

Read the full report for more details on how this technology could work for your agency.

2. The Evolution Of SEO: How To Adjust Your Digital Marketing Strategy

There was a time when SEO seemed to be all about optimizing your site to rank on Google, and that was pretty much the end of it.

Although search engine optimization (SEO) is still a huge factor in digital marketing strategy, its nature of it has certainly changed.

Today, digital marketers are branching out to include a variety of alternative search engines in their SEO strategy, including Bing. Not to mention, it’s also becoming more common to optimize content specifically for social media platforms.

These changes present a range of new opportunities for marketers of small and mid-sized businesses.

As SEO continues to evolve, you should try implementing the following to create a successful strategy:

Testing new search terms.

Optimizing for different search engines.

Creating different kinds of content for different channels.

Assessing your results to see which practices work best.

Start expanding your digital marketing campaigns today with these SEO insights.

3. How Thought Leadership Can Take Your Agency To The Next Level

Every brand wants to be a thought leader. When you’re the one who others within your industry look to for insights, you know you’re doing something right!",artificial intelligence,search engine journal
31,"America's next main battle tank may be a slimmed-down, high-tech version of the iconic Abrams",https://i.insider.com/63652712ff27460018ed9d0e?width=1200&format=jpeg,06/11/2022,"The AbramsX tank is ""showing the art of the possible with existing technology,"" an official with General Dynamics told Insider.",https://www.businessinsider.com/us-army-next-main-battle-tank-may-be-abramsx-2022-11,"The US military has fielded the Abrams tank for more than 40 years.

The next version may be the AbramsX, a lighter tank with an array of technological upgrades.

Top editors give you the stories you want — delivered right to your inbox each weekday. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy Policy

America's next main battle tank may be a lighter but more high-tech version of the M1 Abrams.

General Dynamics, which builds the Abrams, recently unveiled an updated version of the M1. In addition to being 20 tons lighter than the most recent version, the M1A3, the AbramsX features an unmanned turret and a hybrid-electric engine.

Though the media has dubbed the AbramsX a ""next-generation tank,"" that's not exactly accurate. The AbramsX is really a technology demonstrator. It began as an internal General Dynamics research project to show how new technologies could be applied to a new tank or retrofitted onto existing tanks.

Rather than a next-gen armored vehicle, the AbramsX is more of an interim design to span the gap between the Cold War-era designs that still comprise the world's tank fleets and the true next-generation vehicles that will probably be fielded closer to 2050.

Nonetheless, the AbramsX is a working weapon. ""It drives around, it fires, and it performs the functions of a tank,"" Tim Reese, director of US business development for General Dynamics Land Systems, told Insider. ""It's not just a static display.""

The diet M1

General Dynamics' AbramsX tank. General Dynamics

Tank design is a balance — and a tradeoff — between three factors: firepower, protection, and mobility. For the AbramsX, the biggest goal was addressing a growing problem with the M1, of which more than 10,000 have been built since 1979.

The Abrams has always been a hefty tank. Even the early M1A1s weighed about 60 tons — compared to Russia's 45-ton T-72 and China's 55-ton Type 99A — but the latest Abrams weighs closer to 80 tons due to upgrades like the Trophy Active Protection System designed to shoot down incoming anti-tank weapons.

However, ""the M1A2 SEP v2 and v3 overall weight growth with full combat load and Trophy APS has introduced transportability and recovery challenges,"" the Pentagon's chief weapons inspector warned in a 2021 report.

Indeed, the latest Abrams is now so heavy that it can't be towed by Army recovery vehicles, which means damaged or broken-down tanks might have to be left behind on the battlefield.

US soldiers with their M1A2C (SEP v.3) Abrams tanks at Fort Hood in Texas in July 2020. US Army/Sgt. Calab Franklin

Enter the AbramsX, which is the M1 on a diet. While closely resembling the older models, the new vehicle only weighs 60 tons. Reduced weight offers numerous advantages, including the ability to use bridges that would collapse under a heavier vehicle.

AbramsX also fits with the Army's new Multi-Domain Operations doctrine. After decades of focusing on counterinsurgency, the new approach envisions large-unit mechanized operations against near-peer foes such as Russia and China.

The AbramsX cut weight with a series of interrelated upgrades.

The turret is smaller, which means less heavy armor plating. ""Reducing the weight on the Abrams, which was really our primary design goal, required reducing the weight of the armor in the turret,"" Reese said.

Idaho Army National Guard soldiers with an Abrams on May 15. Idaho Army National Guard/Thomas Alvarez

The turret can be smaller because it is unmanned, with the crew nestled inside the armored hull. Using automation — including an autoloader for the cannon — allows the crew to be reduced from four to three, who now sit side-by-side in in the hull while monitoring multi-panel displays.

Shrinking the turret ""generated some weight savings right off the bat,"" Reese said.

The AbramsX replaces the M1's efficient but notoriously fuel-guzzling AGT 1500 gas-turbine engine with a hybrid-electric engine more reminiscent of a Toyota Prius than conventional tank power plants.

General Dynamics claims the new engine slashes fuel consumption by 50%, improves reliability and ease of maintenance, and allow the tank to operate its electronics — and even perform some limited movement — using quieter battery power.

US soldiers do maintenance on an Abrams tank in Germany in August 2017. 3rd Brigade Combat Team, 4th Infantry Division

The AbramsX retains a 120 mm cannon as its main armament but replaces the current gun with the lighter XM360 originally developed for the failed Future Combat System. It also has a Kongsberg RS6 remote-controlled weapon station with an XM914 30 mm cannon and a 7.62 mm coaxial machine gun.

As befits a 21st-century tank design, the AbramsX has some cutting-edge features. It is armed with six Switchblade 300 loitering munitions, known as ""kamikaze drones."" It also has an artificial-intelligence program — called ""Katalyst"" — that can help the crew identify and prioritize targets, navigate, and predict future maintenance.

If this sounds familiar, Russia's T-14 Armata, unveiled in 2015, also had an unmanned turret, a crew of three in the hull, and onboard drones. However, Russia's army has bought few of them, in part due to manufacturing difficulties. Notably, despite Russia's huge tank losses in Ukraine, it has not deployed the Armata there.

""The difference between us and the Armata is that ours works,"" Reese said.

Now vs. later

An AbramsX at the Association of the US Army conference in Washington DC in October 2022. General Dynamics

As with any tank design, there are tradeoffs. One reason the AbramsX is lighter is simply because of less armor around the unmanned turret. General Dynamics says it is up to the US government to decide the level of protection.

""If you keep the armor protection at a very minimal level, that's how we achieve the 60 tons,"" Reese said. ""If you dial the armor protection all the way back up to what it is on an M1 v3 today, the weight goes up above 60 tons.""

To its credit, General Dynamics is not touting the AbramsX as what a next-generation tank should be but rather as a demonstration of what capabilities are available.

""It's showing the art of the possible with existing technology,"" said Mark Hu, manager of US business development for GDLS. ""What you can get now vs. waiting for 'unobtainium' that may finally become available in 2050 or 2068.""

Whether the US Army will invest in a new tank remains to be seen.

Images of burning Russian tanks in Ukraine has led to numerous predictions of the tank's obsolescence. Those predictions are far from true, though they raise questions about the tank's role in the future.

If the Army does want the AbramsX, it can have it quickly. ""Essentially, all of the capabilities on AbramsX will be ready to build into a new main battle tank, or retrofitted into the current Abrams fleet, within 18 to 24 months,"" Reese said.

Michael Peck is a defense writer whose work has appeared in Forbes, Defense News, Foreign Policy magazine, and other publications. He holds a master's in political science. Follow him on Twitter and LinkedIn.",artificial intelligence,business insider
32,How Artificial Intelligence Allows Businesses To Focus On Critical Cyber Risks,https://imageio.forbes.com/specials-images/imageserve/636524cbdbdcdbb6ffda3338/0x0.jpg?format=jpg&width=1200,07/11/2022,"All too often, cybersecurity professionals end up focusing their skills and talents on “managing the tools” rather than on rapidly identifying and managing risks to the business.",https://www.forbes.com/sites/forbesbusinesscouncil/2022/11/07/how-artificial-intelligence-allows-businesses-to-focus-on-critical-cyber-risks/,"Francis Cianfrocca - CEO, InsightCyber.
getty
Cybersecurity risks are steadily growing in number and complexity. We expect that effective attacks on industrial control systems and critical infrastr… [+5093 chars]",artificial intelligence,forbes
33,"Global Artificial Intelligence Operations Platform Market Leader, Market Development, Leading Brands",https://i.visual.ly/images/global-artificial-intelligence-operations-platform-market-leader-market-development-leading-brands_636a23d5720ba_w250_h250.jpg,08/11/2022,The Artificial Intelligence OPS Platform Market will exhibit a CAGR of 31.00% for the forecast period of 2022-2029.  The artificial intelligence for I,https://visual.ly/community/Infographics/business/global-artificial-intelligence-operations-platform-market-leader,"The Artificial Intelligence OPS Platform Market will exhibit a CAGR of 31.00% for the forecast period of 2022-2029. The artificial intelligence for IT operations (AIOps) platform is thought to have e...

volved from IT operations analytics (ITOA) and refers to solutions that use artificial intelligence and machine learning capabilities to automate tasks and processes without the need for human intervention. platforms collect, interpret, and analyse large volumes of IT data in real-time by applying various types of algorithms to the data. Get Full Access of Report @ https://www.databridgemarketresearch.com/reports/global-ai-ops-platform-market",artificial intelligence,visual.ly
34,Long-range robotic submarine sweeps the waters for days at a time,https://assets.newatlas.com/dims4/default/ca734f0/2147483647/strip/true/crop/1152x605+0+418/resize/1200x630!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F8d%2F0b%2Fa85b81e94590bb38ba6c3edcfae0%2Fhii-remus-620-dd625e73-40b1-4f10-b61b-8776114aa9e7-prv.jpg&na.image_optimisation=0,09/11/2022,"It may look like a fat torpedo, but there's more than meets eye with HII's newly unveiled REMUS 620 medium-class naval Unmanned Underwater Vehicle, which is an autonomous robotic submarine that combines artificial intelligence with an operational range of 275…",https://newatlas.com/military/long-range-robotic-submarine-remus-drone/,"It may look like a fat torpedo, but there's more than meets the eye with HII's newly unveiled REMUS 620 medium-class naval Unmanned Underwater Vehicle, which is an autonomous robotic submarine that combines artificial intelligence with an operational range of 275 nm (316 mi, 509 km).

Undersea drones have come a long way from the days when they were basically motorized television eyes operated by remote control at the end of a tether. Today, these machines are becoming increasingly sophisticated with a growing range of capabilities that may one day not only see submarines deploying and recovering drones routinely, but could find conventional warships relegated to command centers overseeing robotic submarine fleets.

Based on HII's REMUS 300 UUV, the medium-class sized REMUS 620 is designed to support both current and predicted US Navy and special forces operations thanks to an improved battery system with a life of 110 hours. This not only provides the REMUS 620 with longer mission times, but enough range to ferry itself to and from its operational sites. Potential missions include mine countermeasures, hydrographic surveys, intelligence operations, surveillance, and electronic warfare.

The REMUS 620 boasts a modular open architecture and incorporates HII's Odyssey autonomy suite that provides the drone with artificial intelligence, autonomous health monitoring, and sensor fusion and perception, as well as the ability to collaborate with other robotic vehicles.

In addition, the modular design allows the batteries to be quickly swapped for fast turnaround times or to incorporate alternative energy sources. The standard synthetic aperture sonar unit can also be replaced or augmented to suit mission requirements.

According to HII, the REMUS 620 can be launched from submarines, small crewed or uncrewed boats, amphibious ships, surface warships, and helicopters. It can also deploy robotic craft and payloads of its own while underwater.

""Retaining a forward strategic advantage requires the ability to deliver a multitude of effects from under the sea,"" said Duane Fotheringham, president of HII's Mission Technologies’ Unmanned Systems business group. ""The REMUS 620 is the first medium UUV designed to accurately deliver this range of advanced above-and-below water effects at long range.""

Source: HII",artificial intelligence,new atlas
35,"Intel Max series is the first CPU with HBM, promises 68% less power use than AMD",https://cdn.neowin.com/news/images/uploaded/2022/11/1668007146_newsroom-intel-max-series-badges.jpg.rendition.intel.web.1648.927_story.jpg,09/11/2022,Intel has unveiled the Intel Max Series product family for high-performance computing (HPC) and artificial intelligence ahead of Supercomputing '22 (SC22) in Dallas happening between November 14-17. Read more...,https://www.neowin.net/news/intel-max-series-is-the-first-cpu-with-hbm-promises-68-less-power-use-than-amd/,"Intel has announced the arrival of its Intel Max Series product family with Intel Xeon CPU Max Series and Intel Data Center GPU Max Series. They come with the code-names Sapphire Rapids HBM and Ponte Vecchio, respectively.

They have been built for high-performance computing (HPC) and artificial intelligence (AI) ahead of Supercomputing '22 (SC22) in Dallas happening between November 14-17. The latest products come with the aim of powering the upcoming Aurora supercomputer at Argonne National Laboratory.

The Xeon Max CPU is ""the first and only"" x86-based processor that features high bandwidth memory. This enables it to enhance HPC workloads without requiring code changes. The Max Series GPU is the tech giant's highest density processor. It features 100 billion transistors in a 47-tile package with over 128 gigabytes (GB) of high bandwidth memory (HBM). The oneAPI open software ecosystem offers the programming environment for the products.

Corporate Vice President and General Manager, Intel Super Computer Group, Jeff McVeigh talked about the Intel Max Series product family, stating:

To ensure no HPC workload is left behind, we need a solution that maximizes bandwidth, maximizes compute, maximizes developer productivity and ultimately maximizes impact. The Intel Max Series product family brings high bandwidth memory to the broader market, along with oneAPI, making it easy to share code between CPUs and GPUs and solve the world’s biggest challenges faster.

The Xeon Max CPU delivers 56 performance cores constructed of four tiles and connected via embedded multi-die interconnect bridge (EMIB) technology, in a 350-watt envelope. Xeon Max CPUs feature 64GB of high bandwidth in-package memory along with PCI Express 5.0 and CXL1.1 I/O. Xeon Max CPUs will offer over a GB of high bandwidth memory (HBM) capacity per core.

Here are some of Intel's claims about performance:

68% less power usage than an AMD Milan-X cluster for the same HPCG performance

AMX extensions boost AI performance and deliver 8x peak throughput over AVX-512 for INT8 with INT32 accumulation operations.2

Provides flexibility to run in different HBM and DDR memory configurations.

Workload benchmarks: Climate modeling: 2.4x faster than AMD Milan-X on MPAS-A using only HBM. Molecular dynamics: On DeePMD, 2.8x performance improvement against competing products with DDR memory.



Max Series GPUs offer over 128 Xe-HPC cores along with other features incorporating:

408MB of L2 cache – the highest in the industry – and 64MB of L1 cache to increase throughput and performance.

The only HPC/AI GPU with native ray tracing acceleration, designed to speed scientific visualization and animation.

Workload benchmarks: Finance: 2.4x performance gain over NVIDIA’s A100 on Riskfuel credit option pricing. Physics: 1.5x improvement over A100 for NekRS virtual reactor simulations.



Max Series GPUs will be available in several form factors depending on the needs and requirements of the customer:

Max Series 1100 GPU: A 300-watt double-wide PCIe card with 56 Xe cores and 48GB of HBM2e memory. Multiple cards can be connected via Intel Xe Link bridges.

A 300-watt double-wide PCIe card with 56 Xe cores and 48GB of HBM2e memory. Multiple cards can be connected via Intel Xe Link bridges. Max Series 1350 GPU: A 450-watt OAM module with 112 Xe cores and 96GB of HBM.

A 450-watt OAM module with 112 Xe cores and 96GB of HBM. Max Series 1550 GPU: Intel’s maximum performance 600-watt OAM module with 128 Xe cores and 128GB of HBM.

Beyond individual cards and modules, Intel will deliver the Intel Data Center GPU Max Series subsystem with x4 GPU OAM carrier board and Intel Xe Link. It is to enable high-performance multi-GPU communication within the subsystem.

The two products will hit the markets in January next year. The tech giant will ship blades with Max Series GPUs to Argonne National Laboratory. The Xeon Max CPUs will go to Los Alamos National Laboratory, and Koyoto University, among others.",artificial intelligence,neowin
36,Global AI Enabled Imaging Modalities Market Research Report: Forecast (2021-2026),https://i.visual.ly/images/global-ai-enabled-imaging-modalities-market-research-report-forecast-20212026_636b8c1c8cff3_w250_h250.jpg,09/11/2022,"According to the MarkNtel Advisors’ research report, “Global Artificial Intelligence (AI) Enabled Imaging Modalities Market Analysis, 2021,” the",https://visual.ly/community/Infographics/business/global-ai-enabled-imaging-modalities-market-research-report-1,"According to the MarkNtel Advisors’ research report, “Global Artificial Intelligence (AI) Enabled Imaging Modalities Market Analysis, 2021,” the market is likely to grow at a CAGR of around 31% ...

during 2021-26 due to the rising workload of radiologists and surging complexities in clinical decision making. These challenges increase physicians' inclination toward adopting advanced technologies, including Artificial Intelligence, for better diagnosis and treatment.",artificial intelligence,visual.ly
37,Artificial Intelligence (AI) Market Projected to Grow at a magnificent CAGR During the 2022-2028 Forecast Timeframe [98 Pages Report],https://media.zenfs.com/en/globenewswire.com/934835f9b53bfc35497459b8b018252e,10/11/2022,"Pune, Nov. 10, 2022 (GLOBE NEWSWIRE) -- Artificial Intelligence (AI) Market In 2022 (Short Description) : Artificial Intelligence (AI) is fast evolving as...",https://finance.yahoo.com/news/artificial-intelligence-ai-market-projected-102000010.html,"Proficient Market Insights

Pune, Nov. 10, 2022 (GLOBE NEWSWIRE) -- Artificial Intelligence (AI) Market In 2022 (Short Description) : Artificial Intelligence (AI) is fast evolving as the go-to technology for companies across the world to personalise experience for individuals. The rudimentary applications AI include bring smarter chat-bots for customer service, personalising services for individuals, and even placing an AI robot for self-service at banks. Beyond these basic applications, banks can implement the technology for bringing in more efficiency to their back-office and even reduce fraud and security risks.

""Artificial Intelligence (AI) Market"" Insights 2022 By Types, Applications, Regions and Forecast to 2028. The global Artificial Intelligence (AI) market size is projected to reach multi million by 2028, in comparison to 2022, with unexpected CAGR during the forecast period, the Artificial Intelligence (AI) Market Report Contains 98 Pages Including Full TOC, Tables & Figures, and Chart with In-depth Analysis Pre & Post COVID-19 Market Outbreak Impact Analysis & Situation by Region.

Artificial Intelligence (AI) Market - Covid-19 Impact and Recovery Analysis:

We have been tracking the direct impact of COVID-19 on this market, as well as the indirect impact from other industries. This report analyzes the impact of the pandemic on the Artificial Intelligence (AI) market from a Global and Regional perspective. The report outlines the market size, market characteristics, and market growth for Artificial Intelligence (AI) industry, categorized by type, application, and consumer sector. In addition, it provides a comprehensive analysis of aspects involved in market development before and after the Covid-19 pandemic. Report also conducted a PESTEL analysis in the industry to study key influencers and barriers to entry.

Final Report will add the analysis of the impact of COVID-19 on this industry.

TO UNDERSTAND HOW COVID-19 IMPACT IS COVERED IN THIS REPORT - REQUEST SAMPLE

Story continues

It also provides accurate information and cutting-edge analysis that is necessary to formulate an ideal business plan, and to define the right path for rapid growth for all involved industry players. With this information, stakeholders will be more capable of developing new strategies, which focus on market opportunities that will benefit them, making their business endeavors profitable in the process.

Get a Sample PDF of report - https://www.proficientmarketinsights.com/enquiry/request-sample/21959551

Artificial Intelligence (AI) Market - Competitive and Segmentation Analysis:

This Artificial Intelligence (AI) Market report offers detailed analysis supported by reliable statistics on sale and revenue by players for the period 2017-2022. The report also includes company description, major business, Artificial Intelligence (AI) product introduction, recent developments and Artificial Intelligence (AI) sales by region, type, application and by sales channel.

The major players covered in the Artificial Intelligence (AI) market report are:

Google

Microsoft Corporation

Amazon Web Services Inc

IBM Corporation

Avaamo Inc

Baidu Inc

Cape Analytics LLC

Oracle Corporation

Short Summery About Artificial Intelligence (AI) Market :

The Global Artificial Intelligence (AI) market is anticipated to rise at a considerable rate during the forecast period, between 2022 and 2028. In 2021, the market is growing at a steady rate and with the rising adoption of strategies by key players, the market is expected to rise over the projected horizon.

Artificial Intelligence (AI) is fast evolving as the go-to technology for companies across the world to personalise experience for individuals. The rudimentary applications AI include bring smarter chat-bots for customer service, personalising services for individuals, and even placing an AI robot for self-service at banks. Beyond these basic applications, banks can implement the technology for bringing in more efficiency to their back-office and even reduce fraud and security risks.

Report Overview

Due to the COVID-19 pandemic and Russia-Ukraine War Influence, the global market for Artificial Intelligence (AI) in BFSI estimated at US$ 3232.9 million in the year 2022, is projected to reach a revised size of US$ 15320 million by 2028, growing at a CAGR of 29.6% during the forecast period 2022-2028.

Artificial intelligence (AI) in banking, financial services and insurance (BFSI) is projected to grow significantly in the coming years. Positive rise of AI-based application in BFSI such as customer support, fraud detection, and improving employee efficiency, buoyed the AI in BFSI market.

Report Scope

This latest report researches the industry structure, revenue and gross margin. Major players’ headquarters, market shares, industry ranking and profiles are presented. The primary and secondary research is done in order to access up-to-date government regulations, market information and industry data. Data were collected from the Artificial Intelligence (AI) in BFSI companies, distributors, end users, industry associations, governments' industry bureaus, industry publications, industry experts, third party database, and our in-house databases.

This report also includes a discussion of the major players across each regional Artificial Intelligence (AI) in BFSI market. Further, it explains the major drivers and regional dynamics of the global Artificial Intelligence (AI) in BFSI market and current trends within the industry.

Get a Sample Copy of the Artificial Intelligence (AI) Market Report 2022

Report further studies the market development status and future Artificial Intelligence (AI) Market trend across the world. Also, it splits Artificial Intelligence (AI) market Segmentation by Type and by Applications to fully and deeply research and reveal market profile and prospects.

On the basis of product type this report displays the production, revenue, price and market share and growth rate of each type, primarily split into:

Machine Learning (ML)

Natural Language processing (NLP)

Predictive Analytics

Machine Vision

Artificial Intelligence (AI) in BFSI

On the basis of the end users/applications this report focuses on the status and outlook for major applications/end users, consumption (sales), market share and growth rate for each application, including:

Banking

Insurance

Wealth management

Artificial Intelligence (AI) Market - Regional Analysis:

Geographically, this report is segmented into several key regions, with sales, revenue, market share and growth Rate of Artificial Intelligence (AI) in these regions, from 2015 to 2027, covering

North America (United States, Canada and Mexico)

Europe (Germany, UK, France, Italy, Russia and Turkey etc.)

Asia-Pacific (China, Japan, Korea, India, Australia, Indonesia, Thailand, Philippines, Malaysia and Vietnam)

South America (Brazil, Argentina, Columbia etc.)

Middle East and Africa (Saudi Arabia, UAE, Egypt, Nigeria and South Africa)

Some of the key questions answered in this report:

What is the global ( North America, Europe, Asia-Pacific, South America, Middle East & Africa ) sales value, production value, consumption value, import and export of Artificial Intelligence (AI)?

Who are the global key manufacturers of the Artificial Intelligence (AI) Industry? How is their operating situation (capacity, production, sales, price, cost, gross, and revenue)?

What are the Artificial Intelligence (AI) market opportunities and threats faced by the vendors in the global Artificial Intelligence (AI) Industry?

Which application/end-user or product type may seek incremental growth prospects? What is the market share of each type and application?

What focused approach and constraints are holding the Artificial Intelligence (AI) market?

What are the different sales, marketing, and distribution channels in the global industry?

What are the upstream raw materials and manufacturing equipment of Artificial Intelligence (AI) along with the manufacturing process of Artificial Intelligence (AI)?

What are the key market trends impacting the growth of the Artificial Intelligence (AI) market?

Economic impact on the Artificial Intelligence (AI) industry and development trend of the Artificial Intelligence (AI) industry.

What are the market opportunities, market risk, and market overview of the Artificial Intelligence (AI) market?

What are the key drivers, restraints, opportunities, and challenges of the Artificial Intelligence (AI) market, and how they are expected to impact the market?

What is the Artificial Intelligence (AI) market size at the regional and country-level?

Our research analysts will help you to get customized details for your report, which can be modified in terms of a specific region, application or any statistical details. In addition, we are always willing to comply with the study, which triangulated with your own data to make the market research more comprehensive in your perspective.

Inquire more and share questions if any before the purchase on this report at -https://www.proficientmarketinsights.com/enquiry/pre-order-enquiry/21959551

Detailed TOC of Global Artificial Intelligence (AI) Market Research Report 2022

1 Artificial Intelligence (AI) Market Overview

1.1 Product Overview and Scope of Artificial Intelligence (AI)

1.2 Artificial Intelligence (AI) Segment by Type

1.2.1 Global Artificial Intelligence (AI) Market Size Growth Rate Analysis by Type 2022 VS 2028

1.3 Artificial Intelligence (AI) Segment by Application

1.3.1 Global Artificial Intelligence (AI) Consumption Comparison by Application: 2022 VS 2028

1.4 Global Market Growth Prospects

1.4.1 Global Artificial Intelligence (AI) Revenue Estimates and Forecasts (2017-2028)

1.4.2 Global Artificial Intelligence (AI) Production Capacity Estimates and Forecasts (2017-2028)

1.4.3 Global Artificial Intelligence (AI) Production Estimates and Forecasts (2017-2028)

1.5 Global Market Size by Region

1.5.1 Global Artificial Intelligence (AI) Market Size Estimates and Forecasts by Region: 2017 VS 2021 VS 2028

1.5.2 North America Artificial Intelligence (AI) Estimates and Forecasts (2017-2028)

1.5.3 Europe Artificial Intelligence (AI) Estimates and Forecasts (2017-2028)

1.5.4 China Artificial Intelligence (AI) Estimates and Forecasts (2017-2028)

1.5.5 Japan Artificial Intelligence (AI) Estimates and Forecasts (2017-2028)

2 Market Competition by Manufacturers

2.1 Global Artificial Intelligence (AI) Production Capacity Market Share by Manufacturers (2017-2022)

2.2 Global Artificial Intelligence (AI) Revenue Market Share by Manufacturers (2017-2022)

2.3 Artificial Intelligence (AI) Market Share by Company Type (Tier 1, Tier 2 and Tier 3)

2.4 Global Artificial Intelligence (AI) Average Price by Manufacturers (2017-2022)

2.5 Manufacturers Artificial Intelligence (AI) Production Sites, Area Served, Product Types

2.6 Artificial Intelligence (AI) Market Competitive Situation and Trends

2.6.1 Artificial Intelligence (AI) Market Concentration Rate

2.6.2 Global 5 and 10 Largest Artificial Intelligence (AI) Players Market Share by Revenue

2.6.3 Mergers & Acquisitions, Expansion

3 Production Capacity by Region

3.1 Global Production Capacity of Artificial Intelligence (AI) Market Share by Region (2017-2022)

3.2 Global Artificial Intelligence (AI) Revenue Market Share by Region (2017-2022)

3.3 Global Artificial Intelligence (AI) Production Capacity, Revenue, Price and Gross Margin (2017-2022)

3.4 North America Artificial Intelligence (AI) Production

3.4.1 North America Artificial Intelligence (AI) Production Growth Rate (2017-2022)

3.4.2 North America Artificial Intelligence (AI) Production Capacity, Revenue, Price and Gross Margin (2017-2022)

3.5 Europe Artificial Intelligence (AI) Production

3.5.1 Europe Artificial Intelligence (AI) Production Growth Rate (2017-2022)

3.5.2 Europe Artificial Intelligence (AI) Production Capacity, Revenue, Price and Gross Margin (2017-2022)

3.6 China Artificial Intelligence (AI) Production

3.6.1 China Artificial Intelligence (AI) Production Growth Rate (2017-2022)

3.6.2 China Artificial Intelligence (AI) Production Capacity, Revenue, Price and Gross Margin (2017-2022)

3.7 Japan Artificial Intelligence (AI) Production

3.7.1 Japan Artificial Intelligence (AI) Production Growth Rate (2017-2022)

3.7.2 Japan Artificial Intelligence (AI) Production Capacity, Revenue, Price and Gross Margin (2017-2022)

4 Global Artificial Intelligence (AI) Consumption by Region

4.1 Global Artificial Intelligence (AI) Consumption by Region

4.1.1 Global Artificial Intelligence (AI) Consumption by Region

4.1.2 Global Artificial Intelligence (AI) Consumption Market Share by Region

4.2 North America

4.2.1 North America Artificial Intelligence (AI) Consumption by Country

4.2.2 United States

4.2.3 Canada

4.3 Europe

4.3.1 Europe Artificial Intelligence (AI) Consumption by Country

4.3.2 Germany

4.3.3 France

4.3.4 U.K.

4.3.5 Italy

4.3.6 Russia

4.4 Asia Pacific

4.4.1 Asia Pacific Artificial Intelligence (AI) Consumption by Region

4.4.2 China

4.4.3 Japan

4.4.4 South Korea

4.4.5 China Taiwan

4.4.6 Southeast Asia

4.4.7 India

4.4.8 Australia

4.5 Latin America

4.5.1 Latin America Artificial Intelligence (AI) Consumption by Country

4.5.2 Mexico

4.5.3 Brazil

Get a Sample Copy of the Artificial Intelligence (AI) Market Report 2022

5 Segment by Type

5.1 Global Artificial Intelligence (AI) Production Market Share by Type (2017-2022)

5.2 Global Artificial Intelligence (AI) Revenue Market Share by Type (2017-2022)

5.3 Global Artificial Intelligence (AI) Price by Type (2017-2022)

6 Segment by Application

6.1 Global Artificial Intelligence (AI) Production Market Share by Application (2017-2022)

6.2 Global Artificial Intelligence (AI) Revenue Market Share by Application (2017-2022)

6.3 Global Artificial Intelligence (AI) Price by Application (2017-2022)

7 Key Companies Profiled

7.1 Company

7.1.1 Artificial Intelligence (AI) Corporation Information

7.1.2 Artificial Intelligence (AI) Product Portfolio

7.1. CArtificial Intelligence (AI) Production Capacity, Revenue, Price and Gross Margin (2017-2022)

7.1.4 Company’s Main Business and Markets Served

7.1.5 Company’s Recent Developments/Updates



8 Artificial Intelligence (AI) Manufacturing Cost Analysis

8.1 Artificial Intelligence (AI) Key Raw Materials Analysis

8.1.1 Key Raw Materials

8.1.2 Key Suppliers of Raw Materials

8.2 Proportion of Manufacturing Cost Structure

8.3 Manufacturing Process Analysis of Artificial Intelligence (AI)

8.4 Artificial Intelligence (AI) Industrial Chain Analysis

9 Marketing Channel, Distributors and Customers

9.1 Marketing Channel

9.2 Artificial Intelligence (AI) Distributors List

9.3 Artificial Intelligence (AI) Customers

10 Market Dynamics

10.1 Artificial Intelligence (AI) Industry Trends

10.2 Artificial Intelligence (AI) Market Drivers

10.3 Artificial Intelligence (AI) Market Challenges

10.4 Artificial Intelligence (AI) Market Restraints

11 Production and Supply Forecast

11.1 Global Forecasted Production of Artificial Intelligence (AI) by Region (2023-2028)

11.2 North America Artificial Intelligence (AI) Production, Revenue Forecast (2023-2028)

11.3 Europe Artificial Intelligence (AI) Production, Revenue Forecast (2023-2028)

11.4 China Artificial Intelligence (AI) Production, Revenue Forecast (2023-2028)

11.5 Japan Artificial Intelligence (AI) Production, Revenue Forecast (2023-2028)

12 Consumption and Demand Forecast

12.1 Global Forecasted Demand Analysis of Artificial Intelligence (AI)

12.2 North America Forecasted Consumption of Artificial Intelligence (AI) by Country

12.3 Europe Market Forecasted Consumption of Artificial Intelligence (AI) by Country

12.4 Asia Pacific Market Forecasted Consumption of Artificial Intelligence (AI) by Region

12.5 Latin America Forecasted Consumption of Artificial Intelligence (AI) by Country

13 Forecast by Type and by Application (2023-2028)

13.1 Global Production, Revenue and Price Forecast by Type (2023-2028)

13.1.1 Global Forecasted Production of Artificial Intelligence (AI) by Type (2023-2028)

13.1.2 Global Forecasted Revenue of Artificial Intelligence (AI) by Type (2023-2028)

13.1.3 Global Forecasted Price of Artificial Intelligence (AI) by Type (2023-2028)

13.2 Global Forecasted Consumption of Artificial Intelligence (AI) by Application (2023-2028)

13.2.1 Global Forecasted Production of Artificial Intelligence (AI) by Application (2023-2028)

13.2.2 Global Forecasted Revenue of Artificial Intelligence (AI) by Application (2023-2028)

13.2.3 Global Forecasted Price of Artificial Intelligence (AI) by Application (2023-2028)

14 Research Finding and Conclusion

15 Methodology and Data Source

15.1 Methodology/Research Approach

15.1.1 Research Programs/Design

15.1.2 Market Size Estimation

15.1.3 Market Breakdown and Data Triangulation

15.2 Data Source

15.2.1 Secondary Sources

15.2.2 Primary Sources

15.3 Author List

15.4 Disclaimer

Continued….

Purchase this report (Price 5600 USD for a single-user license) -https://www.proficientmarketinsights.com/purchase/21959551

About Us:

Proficient Market Insights is the credible source for gaining the market reports that will provide you with the lead your business needs. Our objective is providing a platform for many top-notch market research firms worldwide to publish their research reports, as well as helping the decision makers in finding most suitable market research solutions under one roof. Our aim is to provide the best solution that matches the exact customer requirements. This drives us to provide you with custom or syndicated research.

CONTACT: Contact our Sales Team: Organization: Proficient Market Insights Phone: US +1 424 253 0807 | UK +44 203 239 8187 Email: sales@proficientmarketinsights.com Website: https://www.proficientmarketinsights.com



",artificial intelligence,yahoo entertainment
38,Learning to Imitate,http://ai.stanford.edu/blog//assets/img/posts/2022-11-01-learning-to-imitate/approach.png,06/11/2022,The official Stanford AI Lab blog,http://ai.stanford.edu/blog/learning-to-imitate/,"Artificial Intelligence (AI) playing Minecraft and exploring the world to find caves after being trained on only a few videos of human players, using our new approach (IQ-Learn). Many approaches have difficulty doing anything in an open-world Minecraft map, but IQ-Learn can navigate the world with ease.

A key aspect of human learning is imitation: the capability to mimic and learn behavior from a teacher or an expert. This is an important ability for acquiring new skills, such as walking, biking, or speaking a new language. Although current Artificial Intelligence (AI) systems are capable of complex decision-making, such as mastering Go, playing complex strategic games like Starcraft, or manipulating a Rubik’s cube, these systems often require over 100 million interactions with an environment to train — equivalent of more than 100 years of human experience — to reach human-level performance. In contrast, a human can acquire new skills in relatively short amounts of time by observing an expert. How can we enable our artificial agents to similarly acquire such fast learning ability?

Another challenge with current AI systems is that they require explicit programming or hand-designing of reward functions in-order to make correct decisions. These methodologies are frequently brittle, or otherwise imperfect, and can lead to these systems struggling to work well in complex situations — with self-driving cars blockading roads, or robots failing to coordinate with humans. Developing new methods that can instead interactively learn from human or expert data can be a key stepping stone towards sample-efficient agents and learning human-like behavior.

In this post, I’ll discuss several techniques being developed in a field called “Imitation Learning” (IL) to solve these sorts of problems and present a recent method from our lab, called Inverse Q-Learning — which was used to create the best AI agent for playing Minecraft using few expert demos. You can check out the project page here, and the code for the underlying method here.

So, what is imitation learning, and what has it been used for?

In imitation learning (IL), an agent is given access to samples of expert behavior (e.g. videos of humans playing online games or cars driving on the road) and it tries to learn a policy that mimics this behavior. This objective is in contrast to reinforcement learning (RL), where the goal is to learn a policy that maximizes a specified reward function. A major advantage of imitation learning is that it does not require careful hand-design of a reward function because it relies solely on expert behavior data, making it easier to scale to real-world tasks where one is able to gather expert behavior (like video games or driving). This approach of enabling the development of AI systems by data-driven learning, rather than specification through code or heuristic rewards, is consistent with the key principles behind Software 2.0.

Imitation learning has been a key component in developing AI methods for decades, with early approaches dating back to the 1990s and early 2000s, including work by work by Andrew Ng and Stuart Russel, and the creation of the first self-driving car systems. Recently, imitation learning has become an important topic with increasing real-world utility, with papers using the technique for driving autonomous cars, enabling robotic locomotion, playing video games, manipulating objects, and even robotic surgery.

Imitation Learning as Supervision

Early approaches to imitation learning seek to learn a policy as a machine learning model that maps environment observations to (optimal) actions taken by the expert using supervised learning. The method is called Behavioral Cloning (BC), but it has a drawback: BC has loose, or no, guarantees that the model will generalize to unseen environmental observations. A key issue is that when the agent ends up in an situation that is unlike any of the expert trajectories, BC is prone to failures. For example, in the figure above, the car agent doesn’t know what to do if it goes away from the expert trajectory and it crashes. To avoid making a mistake, BC requires expert data on all possible trajectories in the environment, making it a heavily data-inefficient approach.

A simple fix, Dataset Aggregation (DAGGER), was proposed to interactively collect more expert data to recover from mistakes and was used to create the first autonomous drone that could navigate forests. Nevertheless, this requires a human in the loop and such interactive access to an expert is usually infeasible. Instead, we want to emulate the trial-and-error process that humans use to fix mistakes. For the above example, if the car agent can interact with the environment to learn “if I do this then I crash,” then it could correct itself to avoid that behavior.

This insight led to the formulation of imitation learning as a problem to learn a reward function from the expert data, such that a policy that optimizes the reward through environment interaction matches the expert, thus inverting the reinforcement learning problem; this approach is termed Inverse Reinforcement Learning (IRL).

How do recent Imitation Approaches using IRL work?

In 2016, Ho and Ermon posed Inverse Reinforcement Learning as a minimax game between two AI models with simple parallels to GANs — a class of generative models. In this formulation, the agent policy model (the “generator”) produces actions interacting with an environment to attain the highest rewards from a reward model using RL, while the reward model (the “discriminator”) attempts to distinguish the agent policy behavior from expert behavior. Similar to GANs, the discriminator acts as a reward model that indicates how expert-like an action is.

Thus, if the policy does something that is not expert-like, it gets a low reward from the discriminator and learns to correct this behavior. This minimax game has a unique equilibrium solution called the saddle point solution (due to the geometrical saddle shape of the optimization). At the equilibrium, the discriminator learns a reward such that the policy behavior based on it is indistinguishable from the expert. With this adversarial learning of a policy and a discriminator, it is possible to reach expert performance using few demonstrations. Techniques inspired by such are referred to as Adversarial Imitation. (see the figure below for an illustration of the method)

Set-up of Adversarial Imitation Learning with an agent and a discriminator playing a minimax game. The discriminator learns to distinguish the policy and expert behavior, giving a reward on how expert-like an action is, whereas the agent learns a policy using the discriminator rewards to produce more expert-like behavior.

Unfortunately, as adversarial imitation is based on GANs, it suffers from the same limitations, such as mode collapse and training instability, and so training requires careful hyperparameter tuning and tricks like gradient penalization. Furthermore, the process of reinforcement learning complicates training because it is not possible to train the generator here through simple gradient descent. This amalgamation of GANs and RL makes for a very brittle combination, which does not work well in complex image-based environments like Atari. Because of these challenges, Behavioral Cloning remains the most prevalent method of imitation.

Learning Q-functions for Imitation

These issues, recently, have led to a new non-adversarial approach for imitation: learning Q-functions to recover expert behavior.

In RL, Q-functions measure the expected sum of future rewards an agent can obtain starting from the current state and choosing a particular action. By learning Q-functions using a neural network that takes in the current state and a potential action of the agent as input, one can predict the overall expected future reward obtained by the agent. Because the prediction is of the overall reward, as opposed to only the reward for taking that one step, determining the optimal policy is as simple as sequentially taking actions with the highest predicted Q-function values in the current state. This optimal policy can be represented as the argmax over all possible actions for a Q-function in a given state. Thus, the Q-function is a very useful quantity, providing a connection between the reward function and the optimal behavior policy in an environment.

In IL, a simple, stable, and data-efficient approach has always been out of reach because of the above-mentioned issues with previous approaches. Additionally, the instability of adversarial methods makes the Inverse RL formulation hard to solve. A non-adversarial approach to IL could likely resolve many of the challenges the field faces. Is there something to learn for IL from the remarkable success of Q-functions in RL to determine the optimal behavior policy from a reward function?

Inverse Q-Learning (IQ-Learn)

To determine reward functions, what if we directly learn a Q-function from expert behavior data? This is exactly the idea behind our recently proposed algorithm, Inverse Q-Learning (IQ-Learn). Our key insight is that not only can the Q-function represent the optimal behavior policy but it can also represent the reward function, as the mapping from single-step rewards to Q-functions is bijective for a given policy. This can be used to avoid the difficult minimax game over the policy and reward functions seen in the Adversarial Imitation formulation, by expressing both using a single variable: the Q-function. Plugging this change of variables into the original Inverse RL objective leads to a much simpler minimization problem over just the single Q-function; which we refer to as the Inverse Q-learning problem. Our Inverse Q-learning problem shares a one-to-one correspondence with the minimax game of adversarial IL in that each potential Q-function can be mapped to a pair of discriminator and generator networks. This means that we maintain the generality and unique equilibrium properties of IRL while resulting in a simple non-adversarial algorithm that may be used for imitation.

Below is a visualization to intuitively understand our approach – existing IRL methods solve an involved minimax game over policy (\(\pi\)) and rewards (\(r\)), finding a policy that matches expert behavior at the unique saddle point solution (\(\pi^*\), \(r^*\)) by utilizing RL (shown in left). IQ-Learn proposes a simple transformation from rewards to Q-functions to instead solve this problem over the policy (\(\pi\)) and the Q-function (\(Q\)) to find the corresponding solution (\(\pi^*\), \(Q^*\)) (shown in right). Now crucially, if we know the Q-function then we explicitly know the optimal policy for it: this optimal policy is to simply choose the (softmax) action that maximizes the Q-function in the given state . Thus, IQ-Learn removes the need for RL to find the policy!

Now, instead of optimizing over the space of all possible rewards and policies, we only need to optimize along a manifold in this space corresponding to the choice of a Q-function and the optimal policy for it (the red line). The new objective along the manifold \(\mathcal{J}^*\) is concave and dependent only on the Q-function variable, allowing the use of simple gradient descent methods to find the unique optima.

Diagram of the IQ-Learn approach. We show the IRL problem (on left) and the IQ-Learn problem (on right). The red line denotes the optimal policy manifold given as the softmax action of Q.

During the course of learning, for discrete action spaces, IQ-Learn optimizes the objective \(\mathcal{J}^*\), taking gradient steps on the manifold with respect to the Q-function (the green lines) converging to the globally optimal saddle point. For continuous action spaces calculating the exact gradients is often intractable and IQ-Learn additionally learns a policy network. It updates the Q-function (the green lines) and the policy (the blue lines) separately to remain close to the manifold. You can read the technical proofs and implementation details in our paper.

IQ-Learn methodology for discrete (on left) and continuous (on right) action spaces.

This approach is quite simple and needs only a modified update rule to train a Q-network using expert demonstrations and, optionally, environment interactions. The IQ-Learn update is a form of contrastive learning, where expert behavior is assigned a large reward, and the policy behavior a low reward; with rewards parametrized using Q-functions. It can be easily implemented in less than 15 lines on top of existing Q-learning algorithms in discrete action spaces, and soft actor-critic (SAC) methods for continuous action spaces.

IQ-Learn has a number of advantages:

It optimizes a single training objective using gradient descent and learns a single model for the Q-function.

It is performant with very sparse data — even single expert demonstrations.

It is simple to implement and can work in both settings: with access to an environment (online IL) or without (offline IL).

It scales to complex image-based environments and has proven theoretical convergence to a unique global optimum.

Lastly, it can be used to recover rewards and add interpretability to the policy’s behavior.

Despite the simplicity of the approach, we were surprised to find that it substantially outperformed a number of existing approaches on popular imitation learning benchmarks such as OpenAI Gym, MujoCo, and Atari, including approaches that were much more complex or domain-specific. In all these benchmarks, IQ-Learn was the only method to successfully reach expert performance by relying on a few expert demonstrations (less than 10). IQ-Learn with a simple LSTM policy also works surprisingly well in the complex open-world setting of Minecraft and is able to learn from videos of human players to solve various tasks like building a house, creating a waterfall, caging animals, and finding caves.

Beyond simple imitation, we also tried to imitate experts where only partial expert data is available or the expert has changes in its environment or goals compared to the agent — more akin to the real world. We were able to show that IQ-Learn can be used for imitation without expert actions, and relying solely on expert observations, enabling learning from videos. Moreover, IQ-Learn was surprisingly robust to distribution shifts in the expert behavior and goals in an environment, showing great generalization to new unseen settings and an ability to act as a meta-learner.





See videos of IQ-Learn below (trained with Image observations):





IQ-Learn on Atari. Our trained agent reaches human performance in all games (using 20 expert demos).





IQ-Learn on Minecraft solving the Create Waterfall task (using 20 expert demos).





IQ-Learn on Robomimic-Can task with a 6 DOF arm learning to pick and place cans in the correct bin (using 30 expert demos).





IQ-Learn on CarRacing Gym environment. Reaching expert driving on different race tracks (using 20 expert demos).

Performance Comparisions (from the paper):

The performance is measured as the environment reward attained by the agent trained using different methods.

The generality of our method — it can be combined with any existing Q-learning or actor-critic implementations — makes IQ-Learn applicable to a wide range of domains and learning objectives in imitation and reinforcement learning beyond those explored in the paper.

We hope that IQ-Learn’s simple approach to learning policies via imitation of a few experts will bring us one step closer to developing sample-efficient general AI agents that can learn a variety of behavior from humans in real-world settings.

I would like to thank Stefano Ermon, Mo Tiwari and Kuno Kim for valuable suggestions and proofreading. Also thanks to Jacob Schreiber, Megha Srivastava and Sidd Karamcheti for their helpful and extensive comments. Finally, acknowledging Skanda Vaidyanath, Susan R. Qi and Brad Porter for their feedback

This last part of this post was based on the following research paper:",artificial intelligence,stanford.edu
39,The Future Of Cybersecurity: Developing A Risk Intelligence Quotient,https://imageio.forbes.com/specials-images/imageserve/61b0b7a40df7640c81e9f3db/0x0.jpg?format=jpg&width=1200,09/11/2022,"Organizations should develop a risk intelligence quotient that allows them to discover their vulnerabilities, predict future attacks and prioritize their resources so they can protect themselves from the financial, organizational and repetitional havoc hacker…",https://www.forbes.com/sites/forbestechcouncil/2022/11/09/the-future-of-cybersecurity-developing-a-risk-intelligence-quotient/,"Dr. Obadare Peter Adewale, co-founder of Digital Encode Limited, is a seasoned governance, risk, compliance &amp; cybersecurity thought leader.
getty
Too many organizations are shocked when they ex… [+4097 chars]",artificial intelligence,forbes
40,Instagram debuts new age-verification tools in UK and EU,https://media.zenfs.com/en/bbc_us_articles_995/ba979a90a60cb838d8c5438a2c73f603,07/11/2022,Users changing their date of birth to that of an adult can upload a video of themselves to prove their age.,https://finance.yahoo.com/news/instagram-debuts-age-verification-tools-135439935.html,"Stock image of teenagers taking a selfie

Instagram has introduced technology to help verify the age of users in the UK and EU.

Anyone trying to edit their date of birth from that of an under-18 to that of an over-18 must verify their age.

But now, users have the option to record a video of themselves that will be analysed by age-estimation technology, instead of uploading ID.

Instagram said this would help ensure users' experiences on the platform were age appropriate.

In June, Instagram announced it was exploring ways for teenagers to verify their age and comply with platform rules.

And in a US trial, they were given three ways to verify they were over 18:

upload ID

ask three adult users to vouch for them

take a video selfie

Instagram says it already uses artificial intelligence and in-app reports to help determine whether users are under 18 and, indeed, under 13, its minimum age.

But according to research commissioned by UK media regulator Ofcom, one in three children lies about their age to access adult content on social media.

Instagram accounts for under-18s:

are set to private by default, to reduce unwanted contact from strangers

use in-app notifications known as ""nudges"" to encourage users to explore a range of content or spend less time on the app

Instagram public policy director Tara Hopkins said video age verification was an ""important step"" in delivering safer and better experiences for teenagers on the platform.

""We want everyone to experience Instagram in a way that's appropriate for their age, which means we need to know how old they are - and this is a challenge across our industry,"" she said.

Instagram already uses video selfies to verify the identity of users locked out of their account

It has now extended its partnership with UK digital identity provider Yoti to use them to verify age.

Instagram's new video-selfie age-estimation process

Yoti's technology estimates age by analysing facial features.

On average, it says, it is accurate to within:

1.36 years for six-12-year-olds

1.52 years for 13-19-year-olds

Meta, which owns Instagram, says the technology cannot identify anything about users except their age and it and Yoti will delete images once this has been done.

Platforms could face further requirements for verifying the age of younger users under government proposals for the Online Safety Bill, which ministers have said will return to Parliament as soon as possible.",artificial intelligence,yahoo entertainment
41,Zapping specific neurons helps people walk again after spinal injury,https://images.newscientist.com/wp-content/uploads/2022/11/09142833/SEI_132897287.jpg,09/11/2022,"Nine people with lower body paralysis improved in their ability to walk after receiving electrical stimulation to the spine, with researchers then mapping the neurons that promoted this recovery",https://www.newscientist.com/article/2346403-zapping-specific-neurons-helps-people-walk-again-after-spinal-injury/,"Nine people with lower body paralysis improved in their ability to walk after receiving electrical stimulation to the spine, with researchers then mapping the neurons that seemed to have promoted this recovery

Some people with lower body paralysis can walk further after receiving prolonged electrical stimulation to the injured area of their spine NeuroRestore - Jimmy Ravier

Nine people with different degrees of lower body paralysis gained the ability to walk after receiving prolonged electrical stimulation to the injured area of their spine. This led to researchers identifying neurons that may help to improve walking ability post-paralysis.

Electrical stimulation of the spinal cord is often used to relieve pain in people with spinal cord injuries. In the latest discovery, electrical stimulation also accelerated walking recovery among people with spinal cord injuries who had enough functioning neurons in the affected area.

“We mimic the way the spinal cord is normally activated by electrical signals from the brain when you walk, by electrically stimulating the right spot of the spinal cord at the right time to move leg muscles,” says Jocelyne Bloch at the University of Lausanne, Switzerland.

Advertisement

The team implanted electrical devices into the spinal cords of nine people who had injuries in a similar area of their spinal cord. Six of the participants had some feeling in their legs but little to no ability to move them, while the remaining three couldn’t feel or move their legs at all.

Electrical stimulation was applied to the participants’ spinal cords, with the pattern and location of these pulses being personalised via an artificial intelligence. The participants were then asked to walk as far as possible in 6 minutes.

With the support of a frame, the electrical stimulation enabled them to walk up to 25 metres.

Over the next five months, they continued to receive this electrical stimulation, alongside guided physiotherapy sessions, up to five times a week. At the end of the study period, they could walk 50 metres in 6 minutes, on average.

Four of the participants could even walk without any electrical stimulation, suggesting that the therapy induced sustained rewiring of spinal cord neurons.

To better understand how this occurred, the researchers induced spinal cord injuries in mice, paralysing their hind legs. They then implanted a device that delivered electrical pulses to the animals’ spines. Their walking ability subsequently improved.

Next, the researchers mapped the gene activity of the neurons at the mice’s spinal injury site, which revealed that a certain type of neuron became more active after electrical stimulation.

They then used a genetic tool, which could be controlled via light, to silence and reactivate the neurons linked to walking recovery. The rehabilitated mice could only walk when the neurons were switched on.

“After spinal cord injury, you have a lot of chaotic activity where a lot of neurons are trying to function,” says Bloch. “The electrical rehabilitation organises the network of cells and you actually increase the activity of a specific type of cell, while all the other cells are not activated.”

The researchers also found that silencing these neurons in mice that hadn’t been paralysed had very little effect on their walking ability.

“These cells are important for recovery of walking in injured mice, but when we switch them off in healthy mice without injury, it hardly affected their ability to walk,” says Bloch.

“The identification of a recovery-organizing cell type is a big step forward in our understanding of the mechanisms that underlie [electrical stimulation] rehabilitation,” wrote Kee Wui Huang and Eiman Azim, at the Salk Institute for Biological Studies in California, in an accompanying opinion article.

In the future, manipulation of these neurons could reveal new ways to improve walking ability after paralysis, Huang and Azim wrote.

Journal reference: Nature, DOI: doi.org/10.1038/s41586-022-05385-7",artificial intelligence,new scientist
42,A greener hi-tech shipping container,https://www.springwise.com/wp-content/uploads/2022/11/innovationmobility-transporta-greener-hi-tech-shipping-container.png,10/11/2022,"One company uses AI to maximise routes and offers container-as-a-service rentals
The post A greener hi-tech shipping container appeared first on Springwise.",https://www.springwise.com/innovation/mobility-transport/a-greener-hi-tech-shipping-container/,"Spotted: Corrugated metal shipping containers have been reimagined for smarter, more efficient shipping. Swiss company Aeler has rebuilt the standard shipping container to make it connected, green, and traceable. Made from a fibreglass and resin composite material, the containers are extremely durable yet very lightweight. They weigh so much less than the containers currently in use that a Unit One can transport around 11 per cent more dry cargo, and 17 per cent more liquid.

The containers are also insulated for passive temperature control, and internet-connected sensors inside provide updates on interior conditions every five to ten minutes, including: humidity, air pressure, temperature, volatile organic compound gases, GPS coordinates, and more.

A management dashboard brings all the data together for near-to-real-time updates, and Aeler also offers a fleet management tool that tracks both maintenance and repair records, and container locations. A subscription to the company’s artificial intelligence (AI) tracking system helps clients reduce the transport of empties by maximising efficiencies across all routes.

Because of the increased volume of cargo held by each Unit One, use of the containers cuts maritime emissions by reducing the numbers of containers required. The smooth sides, while making the containers easier to stack and store, also contribute to lower truck emissions when the containers are transported on land.

The maritime industry constitutes such a large global footprint that innovations are seeking improvements in a myriad of areas. Springwise has spotted modular onboard carbon capture systems, along with filters on ships that remove microplastics from the water.

Written By Keely Khoury",artificial intelligence,springwise.com
43,Who created Siri?,,09/11/2022,"Co-founded by Dag Kittlaus, Adam Cheyer, and Tom Gruber, Siri was an offshoot of the DARPA-funded CALO project and spun out of the SRI International Artificial Intelligence...",https://www.techspot.com/trivia/15-who-created-siri/,"Choose your answer and the correct choice will be revealed.

Correct Answer: SRI/DARPA

A grand price fixing scheme that took place between 1998-2002 involved over a dozen makers, of what PC component?

Co-founded by Dag Kittlaus, Adam Cheyer, and Tom Gruber, Siri was an offshoot of the DARPA-funded CALO project and spun out of the SRI International Artificial Intelligence Center as Siri Inc., which launched an app for the iPhone in February 2010 and was acquired by Apple in April 2010.

Kittlaus named Siri after a co-worker in Norway, the name is a short form of the name Sigrid.

Siri (the speech interpretation and recognition interface) debuted as a native install on Apple products with the release of iOS 5 and was introduced as a feature of the iPhone 4S on October 14, 2011.

Siri's founders left Apple after a brief stint post-acquisition and in 2016 developers Dag Kittlaus and Adam Cheyer debuted Viv, an ""advanced"" descendent of Siri. Viv was created as an open platform that understands layered commands for more complex interactions and follow-up questions. In October 2016, Samsung acquired Viv to include it in the Galaxy S8.",artificial intelligence,techspot
44,The Best Photo-Editing Software in 2022 (10 Picks),https://digital-photography-school.com/wp-content/uploads/2022/10/best-photo-editing-software-photoshop.jpg,09/11/2022,"The post The Best Photo-Editing Software in 2022 (10 Picks) appeared first on Digital Photography School. It was authored by Simon Ringsmuth.
Determining the best photo-editing software isn’t about identifying the program that has the most features or is avai…",https://digital-photography-school.com/best-photo-editing-software/,"A Post By: Simon Ringsmuth

Determining the best photo-editing software isn’t about identifying the program that has the most features or is available for the cheapest price. Rather, it’s about finding the software that meets your needs and does what you want.

If you’re a casual photographer who enjoys making minor tweaks to mobile snapshots, the best editing program for you is going to be very different from a seasoned professional who makes a living from photography. It can be difficult to sort through all the available apps and programs, but this list – featuring the top 10 options on the market in 2022 – will help you select a photo editor that’s just right for you.

With the right photo-editing software, you can work wonders on your images. I tweaked the above picture in Photoshop to get the colors to look just right while eliminating lots of spots and imperfections.

How to pick the best photo-editing program

As you sort through the myriad editing options available to you, there are a few general criteria to keep in mind.

If you’re a beginner, I recommend prioritizing ease of use over a laundry list of features. Look for options that are inexpensive and that let you open a photo, make some quick edits, and get back to your day. But don’t get caught up searching for the cheapest program; the editing landscape is littered with abandoned free or low-cost apps that blew up and then quickly flamed out, leaving legions of frustrated photographers in their wake.

If you’re a more advanced photographer, look for photo-editing software that’s been around for several years and boasts a broad base of users with an active online community. And while you research, check YouTube for tutorial videos and search the developer’s website for forums, FAQs, and similar materials. Not only are such items a valuable source of information and assistance, but they’re also evidence of a robust software ecosystem and developer commitment. If you’re going to invest your time and money into learning and using a program, you need to know that it will last long into the future.

Adobe Photoshop has everything any editor could want.

Though this list of the best photo-editing programs isn’t presented in any particular order, I would be remiss if I didn’t put the granddaddy of all photo editors, Adobe Photoshop, at the top. Its very name is synonymous with image editing, and more than 30 years since it was first released, it shows no signs of slowing down. Photoshop contains more features than just about any other editing software; it also has an enormous array of tutorials, videos, message boards, social media groups, and even college-level courses to help you hone your skills.

Back in 2013, in a highly controversial move, Adobe switched to a subscription-only pricing model for Photoshop. This means that casual photographers who want to try the program can no longer make a one-time purchase but must instead subscribe to the Creative Cloud platform. Additionally, Photoshop struggles to walk a fine line between supporting users who have used the program for decades and adding new features that compete with more lightweight modern image editors. The result is an interface that, for beginner photographers, is a hopelessly confusing mess of buttons, menus, sliders, and options.

Photoshop is not for the faint of heart, but for those willing to invest significant time into learning how it works, the rewards are well worth the effort.

Pros

• A huge amount of tutorials and resources, both online and in print, to help you learn

• Able to perform nearly any type of photo editing imaginable

Cons

• Subscription-only pricing model

• Extensive features can confuse new users

• Simple tasks in other image editors can involve complex steps in Photoshop

Most photographers would be well-served by Affinity Photo’s set of capabilities.

Professional, amateur, and hobbyist photographers who require a robust image editor with a rich set of features should look no further than Affinity Photo. While its list of capabilities isn’t quite as comprehensive as compared to editors such as Photoshop and GIMP, Affinity Photo can easily meet the needs of most folks who need to edit photos but don’t care about advanced 3D graphics or AI-enhanced tricks. It has advanced RAW processing options, supports unlimited layers, and works seamlessly with other Serif apps like Affinity Publisher and Affinity Design to give you a complete end-to-end graphics-creation workflow solution.

I’ve used the entire Serif software suite for years, and I’ve found it to offer a fantastic alternative to more popular commercial counterparts. While my image editing needs aren’t as advanced as full-time professional photographers, I have not yet encountered a scenario that Affinity Photo could not handle. Best of all, it’s available as a one-time purchase – not a subscription – which should benefit many casual and enthusiast photographers who can’t quite commit to monthly or yearly software fees.

Pros

• Rich set of features to handle the needs of most photographers

• Supports Wacom and other tablets, which are often used for detailed editing and retouching

• One-time purchase instead of a subscription

Pros

• Not as comprehensive as Adobe Photoshop

Pixelmator is great for iPhone users who want to move beyond the capabilities of the built-in camera app.

Photography purists might balk at the inclusion of a mobile-only app in this list, but there’s no getting around the fact that the iPhone is one of the most popular cameras in the world. And Pixelmator Photo is a full-featured, desktop-class image editor that gives iPhone users the ability to do Photoshop-style editing on small screens for a very reasonable price.

It’s important to set expectations before buying Pixelmator Photo. It’s a far cry from Photoshop, so don’t expect a beyond-comprehensive editing suite – yet it still has plenty of tools for hobbyists and even serious photographers who want to use a mobile phone to do high-level image editing. Its feature set ranks somewhere between Lightroom and Photoshop; it’s also very easy to use and features a rich library of tutorials and walkthroughs. Pixelmator Photo does require a small subscription fee, but unlike other mobile editing apps, you can purchase a lifetime subscription for under $60.

Pros

• Brings powerful photo editing to mobile phones

• One-time purchase option for those who don’t want subscription fees

• Machine-learning algorithms help with many editing tasks

Cons:

• iPhone only, which leaves Android users out in the cold

• Similar set of tools as Lightroom Mobile, so if you’re already subscribed to Lightroom, Pixelmator Photo might not be worth it

• Free version is very limited

GIMP is so powerful enough that it should cost hundreds of dollars, but it’s completely free.

For photographers on a budget, it’s hard to choose a better editing program than GIMP. Despite the odd name (which stands for Gnu Image Manipulation Program), this program has a bevy of features and options that come for the best price anyone could ask for: nothing at all. (In other words, GIMP is free!)

But don’t conflate cost with quality. There is plenty in GIMP to satisfy the most demanding photographers; in fact, its toolset is so rich and expansive it can easily overwhelm new users. But for those willing to invest some time into learning the ins and out of this program, it’ll yield impressive results.

GIMP has been developed by members of the open-source community for decades, and in that time, it’s evolved to meet the needs of modern photographers while staying true to its core mission: giving people of all skill levels a powerful suite of editing tools. The layer-based interface will feel comfortable to longtime Photoshop users, and editing options include brushes, paths, text, warp transform, various selection tools, and more.

While GIMP is notoriously difficult to learn and some actions are much slower than you might expect, you can’t beat the price – it’s one area where GIMP stands head and shoulders above almost every other program on this list!

Pros

• Free and available on Mac, Windows, and even Linux computers

• Incredible set of editing features, enough to rival most commercial image editors

• Extensive online resources for help and support

Cons:

• The interface is somewhat complicated and takes time to learn

• Some actions are very slow, especially compared to others on this list

• No built-in tutorials to help new users

Photopea works in any web browser and comes with a host of useful tools.

Photopea is one of those applications that almost seems too good to be true. It’s a full-featured image editor much like Photoshop, it’s free to use like GIMP, and it’s relatively easy to pick up and learn like Pixelmator. It’s also browser-based, which means there’s no software to download and install. It has all the editing tools that casual and hobbyist photographers might need, and it works with all the most common file formats, including PSD, SVG, and TIFF. You don’t even need an account to use it, so there’s literally nothing to lose by going to the Photopea website and testing it out.

That said, Photopea does come with some important caveats. While it’s relatively easy to use for those who are already familiar with image editors, the many buttons, tools, and menus will likely overwhelm beginners. There’s also no support for 3D objects, and while Photopea is astonishingly impressive from a technical standpoint, it’s much slower than the competition. Granted, it’s a free image editor that you can use from any browser, but don’t expect the same performance as other programs.

Pros

• Browser-based, which means you won’t need to install any software or download any apps

• Supports all the common image-editing tools as well as many advanced options

• The free version has very few limitations, while the subscription version is reasonably priced and even includes cloud storage

Cons:

• Slow compared to dedicated programs such as Photoshop and Luminar

• No artificial intelligence or machine-learning tools to speed up your workflow

• Technically possible to use on a mobile phone, but I wouldn’t recommend it

To edit in Pixlr E, all you need is a web browser and a sense of curiosity and fun.

Pixlr E is a browser-based image editor that’s similar to Photopea, though it boasts a slightly different design philosophy. The program offers an impressive array of tools and options, but the interface should appeal to more casual and hobbyist photographers.

It’s incredibly simple to get started: Just navigate to the Pixlr website, click the “Start a Photo Editing Project” option, upload an image, and begin your editing. Everything you do takes place right in your browser window, which means you’ll never need to worry about software installations (though there are downloadable offline apps available) or app updates.

The tradeoff is a lower level of functionality and a more simplistic design compared to the heavy hitters on this list. Even so, Pixlr E is a solid option for anyone looking for a robust editing solution that won’t cost hundreds of dollars.

With many different brush options, a layer-based workflow, dozens of image filters, and even some basic animation tools, Pixlr E likely has all the power you might need to handle your image editing. But some of the more advanced options require a monthly or yearly paid subscription, and you won’t find the same level of in-depth RAW developing options compared to other programs on this list. A lack of export options also holds Pixlr E back – though for anyone who wants an impressive browser-based image editor with lots of features at a great price, Pixlr E is a great choice.

Pros

• Very easy to get started, which lowers the barrier to entry for beginners and new photographers

• Fully browser-based, with some downloadable offline companion apps, too

• The free version has a variety of useful tools and features, and the paid version is reasonably priced

Cons

• Few customization settings for tweaking the interface to your liking

• The paid version has access to premium support, while the free version’s support is limited to online documentation and a relatively small community of Pixlr users



Luminar relies heavily into AI technology, and the results are stunning.

Ah, Luminar. What a breath of fresh air amidst a sea of all-too-similar photo editing applications! I’ve been using Skylum’s Luminar since the company was named MacPhun, and while it’s not my particular cup of tea, it absolutely deserves serious consideration for all photographers (and especially beginner and hobbyist image-makers).

Luminar has evolved considerably over the years and works as a plugin for Lightroom and Photoshop as well as a standalone application. It’s also available as a one-time purchase, which makes it an ideal alternative to Photoshop and other subscription-only options.

This is the original version of the picture featured at the top of this section. Luminar replaced the sky with a single click!

Luminar’s workflow solutions and editing tools are focused on solving editing problems with artificial intelligence as opposed to giving you dozens of individual tools with pixel-level control. It’s a great program for those hoping to enhance portraits, replace the sky, remove and edit backgrounds, or even add portrait blur via automated tools, and the program’s sliders let you adjust all sorts of parameters. If you want great-looking images while letting software tools do most of the heavy lifting – so you can get away from your desk and back to using your camera – then Luminar is an outstanding pick.

Pros

• Amazing suite of AI-powered tools to enhance your images quickly and easily

• Easy to import an image, click a few buttons, and get impressive results

• Each type of edit has filters to let you tweak the results to your liking

Cons

• Standalone purchase option is available, but you’re encouraged to subscribe and/or purchase additional plugins

• No fine-grained control over every element in your images

• Limited exporting options

The big advantage of Photoworks is its price (along with the set of useful editing features).

While many of the image editors on this list are available for both Mac and Windows computers, PhotoWorks is somewhat unique in that it’s available only for Windows. That puts it in a bit of a unique position in the editing world, and if you prefer Dell, HP, or Lenovo over Apple, you have access to a powerful software tool that can easily improve your photography workflow. In terms of editing options, PhotoWorks isn’t in the same league as Photoshop or Pixelmator Photo, but it’s also significantly less expensive, which makes a big difference for many people.

Rather than feature endless palettes of buttons and tools, PhotoWorks takes a more minimalistic approach. Once you import an image, you can use Lightroom-style sliders to adjust basic parameters like exposure, contrast, saturation, and vibrance (all of which will be immediately familiar to Lightroom users). You can also use sliders to adjust colors and sharpness and use one-click options to remove backgrounds, edit portraits, and more. The results are very good, especially considering the minimal amount of editing time required.

Bottom line: PhotoWorks is an impressive image editor, and the basic version is available for only $20 (while the high-end option costs just $80).

Pros

• The standard version is very reasonably priced and will meet the needs of many casual and hobbyist photographers

• Features a wide variety of adjustment sliders in addition to automatic edits

• Supports easily adding text, watermarks, and logos



Cons

• Editing tools are especially comprehensive compared to Photoshop

• Can open RAW files, but the developing options could be better

• Noise-removal tools need improvement



PaintShop Pro has been around longer than many photographers have been alive, and it remains a solid choice among image editors.

While PaintShop Pro might not have the same level of name recognition as some of its peers, photographers who use Windows computers and want an incredibly capable software tool to handle their image-editing needs would do well to consider the program. It has a rich history that goes all the way back to the early 1990s, and rather than let the software stagnate, the developers have continued to add new features to meet the needs of modern photographers; the result is a program that more than holds its own among a sea of competitors.

The user interface almost feels like an amalgam of other editing software such as Photoshop and Luminar. There are plenty of buttons and tools, including brush, crop, redeye removal, create shapes, work with lines and text, and more. You also have access to layers, masks, effects, and a powerful selection tool that will make Photoshop users feel as though they have been overpaying for their software.

Recent AI-powered additions allow you to remove backgrounds, retouch portraits, and even restore old photos with impressive results – and while PaintShop pro may not be quite as powerful or customizable as some of its peers, it’s an outstanding choice for photographers who want a powerful editor without paying for a recurring subscription.

Pros

• An impressive number of tools and automatic enhancements that’ll suit the needs of most photographers.

• Supports RAW import and allows you to export in a variety of formats.

• Multiple workspaces let you customize the editing environment to suit your individual preferences



Cons

• Windows-only

• Can slow down from time to time

Acorn keeps things simple and basic. Sometimes, that’s all you need.

Acorn is a Mac-only program, and in some ways, it feels like a refreshing change of pace for photographers who’ve grown weary of expensive subscriptions, hand-holding auto-enhancements, and all-in-one editors that try to do everything and end up succeeding at nothing. Acorn is essentially a Photoshop that’s been stripped down to the basics – with a price to match. For just $40, you get a layer-based image editor featuring a useful suite of tools and effects that can take your photography quite far.

The Acorn workflow feels fast and simple: Download the program, open a photo, and you’re off to the races. You can make selections, add layers, insert text, and use dozens of filters that mimic the functionality of far more expensive programs. You won’t find any artificial intelligence or cloud-based editing features, but you will get a program that more than meets the needs of beginners while also offering options that appeal to more advanced photographers.

Pros

• Simple and easy to use

• Includes the most common tools from more popular image editors

• Allows for a combination of bitmap and vector-based editing, which is ideal for image editors who also dabble in graphic design



Cons

• Priced similarly to Affinity Photo but with far fewer features

• Mac only, with no iPhone or iPad option

• Limited community support makes troubleshooting very frustrating



Which editing program is best for you?

Everyone has different needs, but whatever your situation, you can find an image editor that’ll do what you want.

It’s hard to identify the single best editing program. After all, every photographer has a different set of requirements! However, there are three options that stand out for beginner, enthusiast, and advanced photographers that I can recommend without hesitation:

Beginners: Pixlr E. The basic version is free to use, offers a simple and visually appealing user interface, and works with any web browser (so there are no apps to install). If you want to go beyond simply swiping through filters on your phone, Pixlr E is a great choice.

Enthusiast: Affinity Photo. This program has really come into its own over the past two years and has shown no signs of slowing down. It has a deep set of tools, a robust online community of users, and it integrates seamlessly with other Affinity apps (in case you ever want to expand your repertoire).

Advanced: Photoshop. Yes, it requires a subscription, but you get an awful lot for your money, and Adobe continues to add useful enhancements on a regular basis. Photoshop has been the gold standard for years, and with good reason. Sometimes, the most popular program really is the best.",artificial intelligence,digital-photography-school.com
45,We crafted these weird and wonderful images using OpenAI's Dalle-2,https://cdn.pocket-lint.com/r/s/1200x630/assets/images/163320-apps-news-feature-we-crafted-these-weird-and-wonderful-images-using-dalle-2-image34-gbneqjzbg0.jpg,09/11/2022,There are a few different AI technologies popping up lately that are able to create interesting and convincing images using artificial intelligence. Google,https://www.pocket-lint.com/apps/news/163320-we-crafted-these-weird-and-wonderful-images-using-openai-s-dalle-2,"(Pocket-lint) - There are a few different AI technologies popping up lately that are able to create interesting and convincing images using artificial intelligence.

Google has one in the form of Imagen but the most well-known is OpenAI's Dalle-2. This is a system that's able to create realistic images and art based on descriptive terms input by the user.

Dalle-2 is now open to the public meaning anyone can use it and for free (up to a certain number of uses). So we've been testing out the AI to see what images we could create. Keep scrolling to see what we've crafted. We've included the terms we used to create the images, so you can see how close the AI got to meeting the request.

POCKET-LINT VIDEO OF THE DAY

Kid's drawing

Dalle-2 is interesting because you can not only tell it what to create but also the style of art you're after. So that's just what we did:

""Child's crayon styling drawing of a monster on a wall like graffiti.""

Doughnut house

You can also let your imagination run away with you. So if you're hungry then just turn food into objects:

""A house made entirely of ring doughnuts with a pink glaze and sprinkles.""

New Google Pixel watch

We thought it might be fun to try to get an idea of future smart devices and what an AI might think they looked like. Sadly it did a better job on the woman's hair than the watch.

""New Google Pixel watch with bright colours being worn by a stylish woman with curly hair.""

Batman's new ride

You can make your requests as specific as you like right down to the era of something, the style or simply the subject matter.

""A new Batmobile with 1990s styling being admired by The Joker.""

Balloon monsters

What's one of the least fearsome things you're ever likely to see? A balloon monster? We figured that might make a fun alternative to one of the other giant creatures that have historically attacked Japan.

""A giant green balloon animal attacks Tokoyo.""

Concept BMW

We love concept cars that various brands come up with. Designers and engineers are coming up with all sorts of future designs for cars. But what can the AI think the future looks like?

""A futuristic concept of an autonomous self-driving BMW on a quiet street.""

Space monkey

What if we sent monkeys to Mars instead of people? What would that look like? Well, according to Dalle-2 that would result in some fairly grumpy-looking monkeys. Understandably.

""High resolution photo of a monkey astronaut on his way to Mars.""

Germs

We recently wrote about Nikon's Photomicrography Competition which features awesome photos of the tiniest things in our world. We wanted to see what Dalle-2 could create.

""Award-winning photos of micro organisms.""

An exploding phone

Not one wants to see this happening to their smartphone, yet we've seen enough horror stories over the years.

""A mobile phone that's overheated and exploded on a wooden table.""

Roses in bloom

Sometimes you've got to take time out to smell the roses, even if those roses aren't real and were created by AI.

""A macro photograph of a rose bush in full bloom.""

Dogs in a submarine

Dalle-2 seems pretty good at creating cartoon imagery. In this instance an amusing vision of a pair of dogs having a great time under the sea.

""A cartoon dog inside a yellow submarine deep under the sea.""

Concept cars

Concept cars can often be a bit out there. And that's the fun of them because designers often have a bit more freedom in their creations. So why not let the AI have some fun too?

""The weirdest concept car ever designed by man.""

Duck vs turtle

After seeing what Google Imagen could do we thought it would be interesting to replicate its results by using the same terms. The results aren't quite as impressive, but are still a lot of fun.

""A chrome-plated duck with a golden beak arguing with an angry turtle in a forest.""

Robots in an art gallery

Another of Google's examples saw some funky robots in a flooded gallery. What would Dalle-2 do with such a request?

""An art gallery displaying Monet paintings. The art gallery is flooded. Robots are going around the art gallery using paddle boards.""

Corgi in Times Square

Seeing dogs wearing hats and behaving like human beings is always fun in real life. We love that the AI has chosen to embody that joy in one image while making the dog super grumpy in the other.

""A photo of a Corgi dog riding a bike in Times Square. It is wearing sunglasses and a beach hat.""

The moon made of cheese

We were frankly a bit disappointed with this one as we were hoping for something a bit more creative when we asked to see the moon made of cheese. But perhaps you need to be a bit more specific in your requests to get the best results.

""The moon made of cheese.""

A space racoon

With this one, we actually got two quite different results, if slightly subtle ones. One racoon is looking inside from outside and one doing the opposite.

""A photo of a raccoon wearing an astronaut helmet, looking out of the window at night.""

An exploding vase

We're big fans of high-speed photography and slow-mo results. So we wondered what Dalle-2 would come up with if we asked it to create something similar.

""A glass vase full of flowers explodes in slow motion in front of a colourful wall and glass shatters all over the place.""

A cyberpunk styled car races away from police on horseback in Times Square

For some reason when we asked for this scene Dalle-2 gave the police officers space helmets. Make of that what you will.

Dashlane can keep your employees' passwords safe By Pocket-lint Promotion · 23 August 2022 If you're concerned about your organisation's security, this is a no-brainer.

""A cyberpunk styled car races away from police on horseback in Times Square.""

Colourful computers

One of the highlights of this AI technology is the way it can create new artwork based on the style of a human artist. Even where that artist might not have painted such a picture before.

""A painting of a 90s computer in the style of Claude Monet.""

Vader is angry

Admittedly Darth Vader looks a bit strange in a couple of these images, but the overall theme is still sort of what we were hoping for.

""Darth Vader angrily chastises a stormtrooper who is crying at his desk.""

Teddy time

There's something amusing about Teddy Bears going on adventures. These two furry creatures are having a great time on skate boards in public spaces.

""A posh teddy bear on a skateboard near the Arc de Triomphe.""

Cat monster

We've had fun experimenting with what Dalle-2 can create when it comes to cartoon artwork. Here cats become sea monsters and frankly it's quite unnerving.

""A cat seamonster destroying a fishing boat during a storm.""

Cybernetic humans in a pop art style

Even if the end results can be a touch hit and miss at times, you've got to admire how versatile the AI can be. How many humans could create so many different styles of artwork?

""A cybernetic human painted in pop art style.""

Aliens at the Whitehouse

It seems that artificial intelligence doesn't have any idea what aliens might look like. We do find it interesting that they apparently can look like ghosts who travel by space jellyfish though.

""Alien visitors at the White house in the art style of Mars Attacks!""

Writing by Adrian Willings.",artificial intelligence,pocket-lint
46,Facebook-owner Meta to cut 13% of its workforce,https://media.zenfs.com/en/bbc_us_articles_995/8e63f4f8bc2038ca7d41f1ce85972e5c,09/11/2022,Chief executive Mark Zuckerberg said it was one of the most difficult changes in Meta's history.,https://finance.yahoo.com/news/facebook-owner-meta-cut-13-113026042.html,"Meta, which owns Facebook, Instagram and WhatsApp, has announced that it will cut 13% of its workforce.
The first mass lay-offs in the firm's history will result in 11,000 employees, from a worldwid… [+1721 chars]",artificial intelligence,yahoo entertainment
47,Enova Announces Increase to Share Repurchase Program,https://media.zenfs.com/en/prnewswire.com/4b4b62e8a619350ffa24e42a9a4dde00,07/11/2022,"Enova International (NYSE: ENVA), a leading financial technology company powered by machine learning and artificial intelligence, today announced that its...",https://finance.yahoo.com/news/enova-announces-increase-share-repurchase-211600891.html,"CHICAGO, Nov. 7, 2022 /PRNewswire/ -- Enova International (NYSE: ENVA), a leading financial technology company powered by machine learning and artificial intelligence, today announced that its Board of Directors has authorized an increase to the company's common stock share repurchase program of up to $150 million. This new authorization expires on December 31, 2023, and will go into effect when the existing $100 million share repurchase authorization, which has approximately $19 million remaining as of November 4, 2022, is exhausted.

""Our solid balance sheet and ample liquidity give us the financial flexibility to successfully navigate a range of operating environments and to continue to deliver on our commitment to driving long-term shareholder value through both continued investments in our business as well as share repurchases,"" said David Fisher, Enova's CEO.

Repurchases will be made in accordance with applicable securities laws from time to time, and may be made in the open market, through privately negotiated transactions or block trades, or otherwise, and may be made pursuant to repurchase plans designed to comply with Rule 10b5-1(c) of the Securities Exchange Act of 1934, as amended. The timing of repurchases, if any, will be based on the Company's stock price, leverage ratios, cash balances, general business and market conditions, and other factors. The share repurchase program does not obligate the Company to purchase any shares of its common stock. The authorization for the share repurchase program may be terminated, increased or decreased by the Company's Board of Directors in its discretion at any time and without prior notice.

About Enova

Enova International (NYSE: ENVA) is a leading financial technology company providing online financial services through its artificial intelligence and machine learning powered lending platform. Enova serves the needs of non-prime consumers and small businesses, who are frequently underserved by traditional banks. Enova has provided more than 7.5 million customers with over $40 billion in loans and financing with market leading products that provide a path for them to improve their financial health. You can learn more about the company and its brands at www.enova.com.

Story continues

Cautionary Statement Concerning Forward Looking Statements

This release contains forward-looking statements within the meaning of the Private Securities Litigation Reform Act of 1995 about the business, financial condition and prospects of Enova. These forward-looking statements give current expectations or forecasts of future events and reflect the views and assumptions of Enova's senior management with respect to the business, financial condition and prospects of Enova as of the date of this release and are not guarantees of future performance. The actual results of Enova could differ materially from those indicated by such forward-looking statements because of various risks and uncertainties applicable to Enova's business, including, without limitation, those risks and uncertainties indicated in Enova's filings with the Securities and Exchange Commission (""SEC""), including our annual report on Form 10-K, quarterly reports on Forms 10-Q and current reports on Forms 8-K. These risks and uncertainties are beyond the ability of Enova to control, and, in many cases, Enova cannot predict all of the risks and uncertainties that could cause its actual results to differ materially from those indicated by the forward-looking statements. When used in this release, the words ""believes,"" ""estimates,"" ""plans,"" ""expects,"" ""anticipates"" and similar expressions or variations as they relate to Enova or its management are intended to identify forward-looking statements. Enova cautions you not to put undue reliance on these statements. Enova disclaims any intention or obligation to update or revise any forward-looking statements after the date of this release.

Cision

View original content to download multimedia:https://www.prnewswire.com/news-releases/enova-announces-increase-to-share-repurchase-program-301670769.html

SOURCE Enova International, Inc.",artificial intelligence,yahoo entertainment
48,"Artificial Intelligence Platform Market Growth USD 5122.36 Million by 2027 | Business Opportunities, Growth Factors, Top Countries, Latest Technology | Development, Sales, Price, Revenue, Gross Margin | Key Players, Types, Application",https://media.zenfs.com/en/globenewswire.com/25f60b27605da28caf94b2a878a09f22,09/11/2022,"Pune, Nov. 09, 2022 (GLOBE NEWSWIRE) -- Artificial Intelligence Platform market report shares valuable information about global development status...",https://finance.yahoo.com/news/artificial-intelligence-platform-market-growth-112300314.html,"Absolute Reports Pvt Ltd

Pune, Nov. 09, 2022 (GLOBE NEWSWIRE) -- Artificial Intelligence Platform market report shares valuable information about global development status, opportunities, and challenges in near future, as past data analyzed by industry experts which is helpful for you to take needful discussions. Artificial Intelligence Platform market study offers information about the sales and revenue during the historic and estimated period of 2017 to 2028. Understanding the benefits of the segment in identifying the significance of different factors that help the industry progress.

Artificial Intelligence Platform market report also covers all the regions and countries of the world, which shows the regional development status, with market size, volume, and value, as well as price data, key players, and regional analysis. Moreover, the report similarly covers segment data, with type segment, application segment, channel segment, etc.

Get a Sample Copy of the Report at - https://www.absolutereports.com/enquiry/request-sample/21534239

Artificial intelligence (AI) platforms provide users a tool kit to build intelligent applications. These platforms combine intelligent, decision-making algorithms with data, which enables developers to create a business solution. The global Artificial Intelligence Platform market size was valued at USD 2208.77 million in 2021 and is expected to expand at a CAGR of 15.05% during the forecast period, reaching USD 5122.36 million by 2027.



Segmentation by Types: -

Cloud

On-premises

Segmentation by Applications: -

Home automation

Remote sensing

Medical diagnosis

Automated weapons

Speech Recognition

Text Recognition

Others

Inquire or Share Your Questions If Any Before Purchasing This Report – https://www.absolutereports.com/enquiry/pre-order-enquiry/21534239

Geographic Segmentation: -

North America

Europe

Asia-Pacific

South America

The Middle East and Africa

Major players in the global market include: -

Samsung

Wit.ai

IBM

Meya.ai

Arterys

iCarbonX

Microsoft Corporation

Ayasdi

Rainbird

Cisco

Wipro HOLMES

Infosys Nia

Dialogflow

Vital AI

Story continues

Get a Sample Copy of the Report at – https://www.absolutereports.com/enquiry/request-sample/21534239

Key Reasons to Purchase: -

To gain an understanding examines of the market and have a complete acceptance of the global market and its commercial landscape.

Evaluate the production processes, major issues, and solutions to mitigate the development risk.

To understand the most affecting driving and restraining forces in the market and their impact on the global market.

Learn about the market strategies that are being adopted by leading respective organizations.

To understand the future outlook and prospects for the market.

Besides the standard structure reports, we also provide custom research according to specific requirements.

TOC of Artificial Intelligence Platform Market Research Report: -

1 Artificial Intelligence Platform Market Overview

2 Industry Outlook

3 Global Artificial Intelligence Platform Market Landscape by Player

4 Global Artificial Intelligence Platform Sales Volume and Revenue Region Wise (2017-2022)

5 Global Artificial Intelligence Platform Sales Volume, Revenue, Price Trend by Type

6 Global Artificial Intelligence Platform Market Analysis by Application

7 Global Artificial Intelligence Platform Market Forecast (2022-2027)

8 Artificial Intelligence Platform Market Upstream and Downstream Analysis

9 Players Profiles

10 Research Findings and Conclusion

11 Appendix

Purchase this Report (Price 3250 USD for a Single-User License) – https://www.absolutereports.com/checkout/21534239

About Absolute Reports: -

Absolute Reports is an upscale platform to help key personnel in the business world in strategizing and taking visionary decisions based on facts and figures derived from in-depth market research. We are one of the top report resellers in the market, dedicated to bringing you an ingenious concoction of data parameters.

CONTACT: Absolute Reports Phone: US +1 424 253 0807 UK +44 203 239 8187 Email: sales@absolutereports.com Web: https://www.absolutereports.com



",artificial intelligence,yahoo entertainment
49,Net Asset Value(s),https://s.yimg.com/cv/apiv2/social/images/yahoo_default_logo-1200x1200.png,07/11/2022,WisdomTree Issuer plc – Daily Fund Prices 04-November-22 WisdomTree Artificial Intelligence UCITS ETF - USD Acc04/11...,https://finance.yahoo.com/news/net-asset-value-104600626.html,"TipRanks

It’s on to the rubbish heap for flashy tech stocks, and time to place bets on the old-timers. That at least seems to be Jim Cramer’s latest piece of advice for investors. The well-known host of CNBC’s ‘Mad Money’ program says investors need to accept the “new reality” in which tech names are shunned aside in favor of the stock market’s more vintage collection. “It’s the revenge of the old guard right now, right here,” Cramer said. “All sorts of boring, conventional companies are taking back the",artificial intelligence,yahoo entertainment
50,DoubleRainbow Biosciences Announces Strategic AI Collaboration with Galixir,https://s.yimg.com/ny/api/res/1.2/k4IM8YlFQJsQJdqsvC8_fg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD05Nw--/https://media.zenfs.com/en/globenewswire.com/8930a3d87908367cc6b1cc1e23322337,07/11/2022,"Sustainable biotech company uses advanced artificial intelligence to further the drug discovery processLEXINGTON, MASS., Nov. 07, 2022 (GLOBE NEWSWIRE...",https://finance.yahoo.com/news/doublerainbow-biosciences-announces-strategic-ai-131000597.html,"Sustainable biotech company uses advanced artificial intelligence to further the drug discovery process

LEXINGTON, MASS., Nov. 07, 2022 (GLOBE NEWSWIRE) -- Double Rainbow, a sustainable health care company harnessing the power of natural evolution through bioengineering to improve the quality of human health, today announced its partnership with Galixir, a biotech company that drives drug discovery through artificial intelligence.

With this agreement, Double Rainbow and Galixir will combine their respective expertise and technologies to pioneer new capabilities for natural product pathway elucidation and enzyme function prediction. Galixir is the ideal artificial intelligence partner for Double Rainbow, as the team has recently demonstrated the utility of their deep-learning-driven natural product biosynthetic pathway prediction algorithm, called BioNavi-NP,i and their drug-protein binding structure prediction tool TankBind, developed based on trigonometry-aware neural networks.ii Double Rainbow harbors high volumes of real-world data for enzyme reactivities and specialized metabolic pathways across all kingdoms of life. Combined, the organizations will leverage their complementary expertise to develop new computational tools and workflows to discover and evolve new catalysts and elevate biosynthetic production capabilities for valuable natural products.

“Our goal is to provide ethical, cost-effective access to rare or endangered natural products that support human health and wellbeing. By working with partners like Galixir, we will pair data from our revolutionary HARMONY and PRISM platforms, with their team’s proprietary AI system to further our ambition to harness the natural world to advance human health,” said Jing-Ke Weng, Ph.D., Co-founder of Double Rainbow. ​“As a biotech company, Double Rainbow strives to elevate the medicinal potential of nature through the latest advances in the areas of genomics, metabolomics, and synthetic biology, and this partnership is a key step in that journey.”

“As an AI-driven company, data is the key to the success of models. By collaborating with Double Rainbow and leveraging their advanced platforms HARMONY and PRISM, our unique models will be fueled with unique data. We will further integrate experiences from computational chemistry and structural biology, and push the limit of computation-driven discovery in this field, making rare or endangered natural products more accessible.” said Chengtao Li, Ph.D., Founder and CEO of Galixir. “Galixir is dedicated to bringing unique value into chemistry and pharmaceutical science. I believe this partnership will certainly make contribution to launch a new paradigm for the whole industry.”

Galixir is a global leader integrating drug discovery and AI with the mission to build a healthier world and make innovative medicines available. The company has 20+ papers in top journals and conference proceedings, covering subjects including molecular generation, property prediction, virtual screening and retrosynthesis prediction.

Double Rainbow has significant experience and expertise in the discovery and development of nature-inspired new medicines leveraging transformative technologies, novel biosynthetic strategies, and deep knowledge base of metabolic systems. Through its proprietary platforms, Double Rainbow is pioneering the future of sustainable natural product manufacturing and novel glyco-drug conjugate technology to promote the health of people and the planet.

About Double Rainbow

Double Rainbow is a sustainable biotech company harnessing the power of natural evolution through bioengineering to improve the quality of human health and ensure the sustainability of our planet. By leveraging advances in the areas of genomics, metabolomics, and synthetic biology, we are accessing the richness and efficacy of natural chemistry like never before to bring therapeutics and bioceuticals to the world at scale without harming the environment. Learn more at www.doublerainbowbio.com.

About Galixir

Galixir is an AI-driven biotech company integrating computational platforms Pyxir® and M1 and experience of computational chemistry, medicinal chemistry and biology, to bring unique values into pharmaceutical industry. Pyxir® leverages cutting-edge AI algorithms to solve problems in the preclinical development of small molecule drugs and to find candidate molecules with high potency and novel structures. M1, the AI-driven intelligent computing platform, combines AI with classical physics principle and makes breakthroughs in classical molecular modeling by accurately describing interactions between molecules and proteins. Learn more at https://www.galixir.com/en.

i Zheng, S., Zeng, T., Li, C. et al. Deep learning driven biosynthetic pathways navigation for natural products with BioNavi-NP. Nat Commun 13, 3342 (2022). https://doi.org/10.1038/s41467-022-30970-9

ii Lu, W., Wu, Q., Zhang, J., Rao, J., Li, C., & Zheng, S. (2022). TANKBind: Trigonometry-Aware Neural NetworKs for Drug-Protein Binding Structure Prediction. bioRxiv. https://doi.org/10.1101/2022.06.06.495043

CONTACT: Zoe Tobin / APCO APCO 508 6156770 ztobin@apcoworldwide.com



",artificial intelligence,yahoo entertainment
51,Artificial Intelligence in Drug Discovery Market Size Worth USD 8.9 Billion by 2030 at 24.9% CAGR – Report by Market Research Future (MRFR),https://media.zenfs.com/en/globenewswire.com/c9cb9749bf29d1cd3a050e36b39c153f,09/11/2022,"Artificial Intelligence in Drug Discovery Market Trends and Insights By Product Type (Software, Services), Molecule Type (Large Molecule, Small Molecule...",https://finance.yahoo.com/news/artificial-intelligence-drug-discovery-market-153000144.html,"Market Research Future

Artificial Intelligence in Drug Discovery Market Trends and Insights By Product Type (Software, Services), Molecule Type (Large Molecule, Small Molecule), Technology (Machine Learning, Deep Learning and others), Indication (Immune-Oncology, Neurodegenerative Diseases, Cardiovascular Diseases, Metabolic Diseases and others), Application (Target Identification, Candidate Screening, De novo Drug Designing, Drug Optimization and Repurposing and Preclinical Testing) - Forecast till 2030

New York, USA, Nov. 09, 2022 (GLOBE NEWSWIRE) -- Artificial Intelligence in Drug Discovery Market Overview:

According to a Comprehensive Research Report by Market Research Future (MRFR), “ Artificial Intelligence in Drug Discovery Market Information By Product Type, Molecule Type, Technology, Indication, Application - Forecast till 2030”, the market is expected to hold a value of about USD 8.9 Billion by 2030, and it is projected to register a CAGR of 24.9% from 2022 to 2030.

Market Scope:

Artificial intelligence refers to the replication of the human intelligence processes using machines, particularly computer systems. Certain applications of AI are natural language processing, expert systems, machine vision, and speech recognition.

Several companies and significant research hospitals have been working on developing these systems for clinical application over the past couple of years, capturing the enthusiasm and attention of medical industry specialists. Artificial intelligence (also known as deep learning, machine learning, or artificial neural networks) is currently seeing its first commercial applications in the medical field. A potential paradigm change in clinician workflow, these devices have the potential to enhance efficiency while also enhancing care and patient throughput.

In general, AI works by ingesting huge volumes of labeled training data, assessing the data for patterns and correlations, and utilizing these patterns to predict future states. Like this, a chatbot being fed a series of text chats is able to learn to generate lifelike exchanges with consumers. Similarly, an image recognition tool is able to learn to detect and describe different objects in images by assessing multiple examples.

Story continues

Get Free Sample PDF Brochure @ https://www.marketresearchfuture.com/sample_request/9393

Report Scope:

Report Attribute Details Market Size in 2030 USD 8.9 Billion CAGR 24.9% Base Year 2021 Forecast Period 2022-2030 Historical Data 2020 Forecast Units Value (USD Billion) Report Coverage Revenue Forecast, Competitive Landscape, Growth Factors, and Trends Segments Covered By Product Type, Molecule Type, Technology, Indication, Application and End User Geographies Covered North America, Europe, Asia-Pacific, and Rest of the World (RoW) Key Market Drivers An increasing number of startups operating in the AI spectrum for healthcare including drug discovery Increased use of AI technology by major pharma companies for drug discovery

Artificial Intelligence in Drug Discovery Market Competitive Outlook:

Key Players of the market are

Microsoft Corporation

IBM Corporation

Google (A Subsidiary of Alphabet Inc.)

Atomwise, Inc.

Deep Genomics

Cloud Pharmaceuticals, Inc.

Insilico Medicine

BenevolentAI

Exscientia

Cyclica

Bioage

Numerate

Numedii, Inc.

Envisagenics

Twoxar, Incorporated

Owkin, Inc.

Xtalpi, Inc.

Verge Genomics

Berg LLC

Artificial Intelligence in Drug Discovery Market Dynamics:



Market Drivers

Healthcare applications of artificial intelligence are thriving thanks to the numerous potential presented by this cutting-edge technology. Consequently, many large corporations are investing heavily in this sector. Tech giants like IBM's Watson, Alphabet (Google's parent company), and Philips are all betting big on AI in healthcare. In addition, several pharmaceutical firms and a growing number of startups across the globe are actively pursuing and investing in the creation of AI & machine learning tools to enhance drug discovery and boost the success rate of drug development.

The use of AI in healthcare is still in its infancy, and its incorporation into the field is still at a nascent stage. Given the vast opportunities that AI presents in healthcare, an increasing number of businesses are investing in research and development of AI-based solutions in this area.

Market Restraints

Over the forecast time period, the market is likely to be hampered by the high cost of integrating AI and the lack of suitable infrastructure in low economic countries.

Browse In-depth Market Research Report (140 Pages) on Artificial Intelligence in Drug Discovery: https://www.marketresearchfuture.com/reports/ai-drug-discovery-market-9393

COVID-19 Analysis:

Drug companies have been quick to incorporate AI-powered solutions in clinical trial research and increase medicinal development in response to the ongoing Covid-19 pandemic, which has placed a strain on existing healthcare systems and increased the demand for novel drug remedies. Artificial intelligence (AI) and associated technologies are seen as a key driver of expansion in the healthcare sector. Companies from around the world are pooling resources to unleash AI's full potential in medication discovery and the research of the effects and course of diseases like COVID and others.

Artificial Intelligence in Drug Discovery Market Segmentation:

By Product Type

The software subsector dominates the Artificial intelligence in drug discovery industry. Microsoft Azure and Google Cloud AI are two of the most popular AI cloud platforms available. Smaller firms are also building AI platforms, which is driving the rapid expansion of the AI market for drug discovery.

Buy Now: https://www.marketresearchfuture.com/checkout?currency=one_user-USD&report_id=9393

By Molecule Type

Biologic medications are examples of drug prospects in the large molecule category because of their complicated molecular structure. Biologic medication development and complex molecular structure analysis are two areas where artificial intelligence (AI) technology is being increasingly put to use to meet the rising need for life-saving pharmaceuticals.

Machine learning techniques offer a toolkit for better decision making when dealing with large amounts of high-quality data and narrowly defined problems. Using ML to make decisions can increase the efficiency of the process and decrease the number of unsuccessful trials, both of which can hasten the creation of new medicines. The proportion of this group is expected to grow.

By Indication

Market share for AI in drug discovery is predicted to be highest in the immuno-oncology subsegment. Positive results from using AI to distinguish between similar genetic variants are encouraging for the future of precision medicine.

By Application

At least for the duration of the forecast, the preclinical testing subsegment of the artificial intelligence in drug discovery market is expected to account for a sizable portion of the overall market.

Share your Queries @ https://www.marketresearchfuture.com/enquiry/9393

Artificial Intelligence in Drug Discovery Market Regional Analysis

The presence of numerous large AI platform developers in the region is a key factor in the expansion of the AI in drug discovery industry in North America. The expansion of the ai in drug discovery market is being fueled in part by the rising interest in using AI in the pharmaceutical industry from major players like AbbVie, Genentech, Amgen, and Eli Lilly & Company. Also contributing to the expansion of the Americas is the rising need for novel pharmaceuticals in Latin America.

When it comes to artificial intelligence (AI) in drug development, Europe is the second largest market in the world, behind only the Americas. The regional ai in drug discovery market is predicted to increase as a result of a number of reasons, including rising R&D spending in the pharmaceutical industry and strong demand for AI solutions from Big Pharma businesses. In order to include AI technology into the drug discovery process, leading pharmaceutical corporations have formed collaborations with the AI service providers.

The rising need for efficient drug discovery solutions is fueling the expansion of the Asia-Pacific Artificial intelligence in drug discovery market. Several companies have begun focusing on using AI in the pharmaceutical research and development process.

The lack of a sophisticated healthcare system, the tiny number of companies actively engaged in medication discovery and development, and low per capita disposable incomes in some parts of Africa have combined to make the Middle East and Africa the smallest market for artificial intelligence in this field.

Discover more research Reports on Healthcare Industry , by Market Research Future:

Drug Discovery Services Market Research Report: By Drug Type (Small Molecule Drug, Biologics), by Type (DMPK, Pharmaceutical Services, Others), by Therapeutic Area (Oncology, Others), by Process, by Technology, and by End-User – Global Forecast Till 2030

Healthcare Artificial Intelligence (AI) Market Research Report: Information By Component (Hardware, Software, Services), Application (Robot-Assisted Surgery, Virtual Nursing Assistant, Dosage Error Reduction, Clinical Trial, Preliminary Diagnosis, Automated Image Diagnosis), Technology (Machine Learning, Querying Method, Natural Language Processing), End User (Hospital & Diagnostic Centers, Pharmaceutical & Biotechnology Companies Academic & Research Laboratories) - Global Forecast till 2030

Internet of Things in Healthcare Market : By Component (Medical Devices- Wearable External Medical Devices, Implanted Medical Devices, Stationary Medical Devices, Systems; Software- Remote Device Management, Network Bandwidth Management, Data Analytics, Application Security, Network Security; and Services- Support & Maintenance Services, Consulting & System Integration), Application (Inpatient Monitoring, Medication Management, Telemedicine, Clinical Operations &Workflow Management, and Connected Imaging), Connective Technology (Wi-Fi, Bluetooth Low Energy, Zigbee, Near Field Communication, Cellular, and Satellite), End Use (Clinical Research Organizations, Hospitals & Clinics, Research, and Diagnostic Laboratories), Region (North America, Europe, Asia-Pacific, and Rest of the World)- Forecast to 2027

About Market Research Future:

Market Research Future (MRFR) is a global market research company that takes pride in its services, offering a complete and accurate analysis with regard to diverse markets and consumers worldwide. Market Research Future has the distinguished objective of providing the optimal quality research and granular research to clients. Our market research studies by products, services, technologies, applications, end users, and market players for global, regional, and country level market segments, enable our clients to see more, know more, and do more, which help answer your most important questions.

Follow Us: LinkedIn | Twitter

CONTACT: Market Research Future (Part of Wantstats Research and Media Private Limited) 99 Hudson Street, 5Th Floor New York, NY 10013 United States of America +1 628 258 0071 (US) +44 2035 002 764 (UK) Email: sales@marketresearchfuture.com Website: https://www.marketresearchfuture.com



",artificial intelligence,yahoo entertainment
52,NLP Logix Joins Beeline Partner Ecosystem,https://media.zenfs.com/en/prnewswire.com/1ed557d3549b771f444b0876419b5a7e,07/11/2022,"NLP Logix, an artificial intelligence and machine learning solutions company, today announced it's partnership and inclusion into the Beeline ecosystem...",https://finance.yahoo.com/news/nlp-logix-joins-beeline-partner-070000151.html,"NLP Logix will offer artificial intelligence and machine learning automation solutions to increase productivity of the contingent workforce

JACKSONVILLE, Fla., Nov. 7, 2022 /PRNewswire/ -- NLP Logix, an artificial intelligence and machine learning solutions company, today announced it's partnership and inclusion into the Beeline ecosystem. Beeline customers will be able to leverage NLP Logix's task automation solutions to drive even greater efficiencies. Beeline is the leading technology solution provider for managing the global extended workforce.

Beeline is using artificial intelligence to optimize the contingent workforce of the future.

""NLP Logix's AI tools can eliminate repetitive tasks, allowing the contingent workforce to offer even more value.""

""Beeline's mission is to optimize the contingent workforce in every way and partnering with NLP Logix will add another layer to this optimization,"" said Doug Leeby, Beeline CEO. ""NLP Logix's AI tools can analyze workflow and eliminate repetitive tasks, allowing the contingent workforce to offer even more value.""

Matt Berseth, Chief Information Officer, NLP Logix, said, ""There are so many ways our automation sourced through Beeline can help companies. For instance, an insurance company may request a large number of professional adjusters to respond to a natural disaster, like a hurricane. NLP Logix would automate many of the tasks that it takes to estimate the claim. Additional examples include financial services companies that need data entry personnel to identify and remove credit card information from a document image, or an aerospace firm needing to optimize its contingent maintenance operations. These type of AI applications save time and efficiencies, boosting productivity for the workers and the companies.""

For the past 10 years, NLP Logix has demonstrated the ability to reduce repetitive tasks through the application of AI, often by factors of ten. The company uses machine learning technologies such as robotic process automation (RPA) to automate repetitive data entry tasks, computer vision to automate visual inspection of imagery including documents, and natural language processing (NLP) to automate the reading and interpretation of large amounts of written and audio information.

Story continues

About NLP Logix

NLP Logix is an artificial intelligence/machine learning systems and automation solutions provider, which has evolved over the past ten years to one of the fastest growing team of machine learning practitioners. NLP Logix delivers automation and machine learning solutions to customers across a wide swath of industries, including financial services, transportation, healthcare, government, human resources and many more. More information at www.nlplogix.com.

About Beeline

Beeline powers the future of work with the world's first extended workforce platform. Our intelligence-driven, cloud-based platform manages more than 30 million contingent, shift-based, project-based, and independent workers and enables total talent visibility into the entire workforce.

As the pioneer of vendor management systems (VMS), Beeline understands the future of work is fueled by technology that enables the limitless potential of every business and every individual. Our AI-powered software delivers insights and tools needed to manage the modern world of work.

With the most seasoned team of contingent workforce solution professionals around the world, we help businesses across more than 120 countries meet their most critical talent needs. To learn more, visit beeline.com

Media Contact: Samantha Epstein, Samantha.epstein@nlplogix.com

NLP Logix, LLC

Cision

View original content to download multimedia:https://www.prnewswire.com/news-releases/nlp-logix-joins-beeline-partner-ecosystem-301669200.html

SOURCE NLP Logix, LLC",artificial intelligence,yahoo entertainment
53,What Happens When Everything Becomes TikTok,,07/11/2022,Even the most advanced automated systems can’t catch every bit of extreme content.,https://www.theatlantic.com/technology/archive/2022/11/tiktok-instagram-video-feeds-ai-algorithm/672002/?utm_source=feed,"Updated at 12:18 p.m. ET on November 7, 2022

There’s been a lot of chatter, in recent days, about the fate of a certain platform that deals mostly in text posts no longer than 280 characters. With a chaos agent now at the helm of Twitter, many people are understandably fretting about whether it could possibly control a rising tide of abuse, hate speech, pornography, spam, and other junk. But in a sense, these worries miss the point: In 2022, Twitter is small fry.

A far grander and more terrifying saga is unfolding on the endless video feeds that have become the dominant mode of social media today, drawing not millions but billions of monthly users on TikTok, Instagram, Facebook, and YouTube. The Era of Video has definitively and irreversibly arrived.

Doubters might look to a recent clash between social-media royalty and Instagram leadership. Back in July, two Kardashians and a Jenner shared an Instagram image from the creator Tati Bruening calling on the platform to “stop trying to be tiktok.” In the history of social media, this was a bit like the 21st-century equivalent of nailing a pamphlet to a cathedral door. The protest referred in no uncertain terms to the company’s turn toward video, and away from its origins as a vehicle for still images. TikTok, of course, is almost entirely video—a relentlessly addictive scroll of auto-playing content, much of which comes from accounts you do not follow.

But not even some of the biggest influencers of all time could turn the tides. The day after their posts went up, Instagram’s CEO, Adam Mosseri, doubled down. “I need to be honest,” he said (in a video). “I do believe that more and more of Instagram is going to become video over time.”

No matter where you swipe or tap, video is there—a torrent of pixels, fury, and sound that is, if not literally infinite, effectively endless. The quality of our online lives now hinges on how these feeds are ordered and mediated, powers that are largely automated. In line with its push to embrace video, Meta has said that by the end of 2023, it will more than double the proportion of material on Instagram and Facebook users’ feeds that is “recommended by our AI.” The likelihood that we’ll find ourselves hurtling down one of those black holes of content—where time seems to dilate and lose all meaning—will depend less on whom we follow and more on what the machine decides to serve us next.

The shape of our politics, our ideology, and even our fundamental grasp of how the world works is, in some substantial way, up to the algorithms. According to a recent survey from the Pew Research Center, a quarter of people under 30 in the U.S. regularly get their news from TikTok clips. That number is growing. People are even turning to social-media video as a replacement for Google search.

Whether the results of such swipes and searches lead us to enlightenment or drag our worldviews further down toward their least reconciliatory, most conspiratorial depths depend in part on AI. In an experiment from September, the fact-checking company NewsGuard found that the top results on TikTok for a range of terms often included misleading, hateful, and in some cases extremely dangerous videos. Thirteen of the top 20 results for does mugwort induce abortion, for example, advocated unproven herbal abortifacients such as papaya seeds. In the same experiment, a search for hydroxychloroquine yielded a tutorial on how to fabricate the malaria drug—and bogus COVID cure—at home using grapefruit. Needless to say, this is not how to make hydroxychloroquine.

All of this should lead social-media companies to redouble their efforts to keep the muck—violence, illegal pornographic material, disinformation—off their platforms. As it is, only about 40 percent of the videos that TikTok pulls down are culled with automated systems, leaving millions of videos to be reviewed each month by workers who will have to spend the rest of their lives under the pall of what they’ve seen.

Even the most cutting-edge AI is not always as smart or all-seeing as it’s chalked up to be. These shortcomings could become more painfully evident in the years ahead. And if there were a way for AI to execute moderation tasks faithfully and accurately on the endless feed, it could come at a heavy price, drawn directly from our scant remaining balance of privacy and autonomy.

How does a machine even “understand” a video in the first place? Thanks to advances in computer vision over recent years, it’s become routine for AI to examine still images and, for example, connect the attributes of a face to someone’s identity, or to conclude that a gun is indeed a gun—or that a grapefruit is indeed a grapefruit.

Every minute of video is really just thousands of static pictures arranged in succession. And AI-based computer vision can certainly find still frames containing signals of problematic content with impressive tenacity. But that’s only going to get you so far. YouTube arguably has the most extensive experience with automated video moderation, but violative videos are viewed millions of times every day.

Part of the issue is that video contains a lot of data. In sequence, the thousands of still frames that make up a video create narrative. The accompanying audio adds further layers of meaning. This morass can be difficult to sort through—the density of data in any given video is a “two-sided coin,” as Dhanaraj Thakur, a research director at the Washington, D.C.–based Center for Democracy and Technology, told me. You can’t have the system analyze just one layer, because it would pick up a bycatch of content that, at a glance, would appear to break terms of service, despite being innocuous—while still letting other illicit material through the gaps.

For example, a system that flags any video with a gun would flag a clip from Pawn Stars with two people discussing the value of an antique rifle. Meanwhile, it would miss a clip of a person being shot with a firearm that’s out of frame. Visually and even perhaps auditorily, a clip of someone attempting to make hydroxychloroquine might be hard to discern from that of someone making grapefruit juice, especially if that person takes care not to say anything about COVID.

Read: Of God and machines

Social-media firms couldn’t abide such overzealous AI-based policing, because it would get in the way of the kind of content that’s often best for engagement and ad impressions—the shocking, the outrageous, and, of course, the risqué. AI-based skin detection, which continues to be the basis for nudity filtering, might block any clip of swimwear-clad beachgoers, spelling doom for an entire industry of fitness influencers. This has pushed the research community toward some unorthodox solutions over the years. Researchers have, for example, sought to improve the accuracy of these kinds of classifiers with AI that recognizes porn’s unique patterns of motion, as well as its singular soundtrack—in the words of one team: “moans, deep breathing, panting, groans, screams, and whimpers,” as well as “bed creaking, sheets rustling.” But although such tools may work fine in the lab, they can struggle in the infinitude of the real world. A similar effort from 2006 that detected porn on the basis of the audio’s “periodicity”—that is, its repetitiveness—ended up catching lots of footage of tennis matches.

Ultimately, a video’s true meaning may be gleaned only at the “confluence” of its various layers of data, as Becca Ricks, a senior researcher at the Mozilla Foundation, put it to me.

Footage of a desolate landscape with a tumbleweed blowing across it would raise no red flags for either a human or a machine, nor would an audio clip of someone saying, “Look how many people love you.” But if you combine the two and send the result to someone you’re cyberbullying—No one loves you!—the computer would be none the wiser.

Much hate speech, it turns out, fits snugly in this gap of computer comprehension. A “Hateful Meme Challenge” organized by Facebook in 2020 created a set of more “subtle” combinations of images and text that AI struggles to understand; an image of a tumbleweed with the exact phrasing contained above, for example, or a picture of an alligator with the text “Your wrinkle cream is working great.” Different AI models had varying levels of success, but none of them came close to human accuracy. Effective moderation can require “real-life context and common sense,” researchers wrote—in other words, a human’s sensibilities. Achieving better results in a single TikTok, which the researcher Abbie Richards describes as a “three dimensional meme composed of video, audio, and text,” could take a quantum leap in technology.

AI also doesn’t do well on things that it hasn’t encountered before—“edge cases,” in the poetics of the academy. This lends those posting harmful content a perpetual upper hand. “Humans are good at adaptation,” Hany Farid, a professor at UC Berkeley who was one of the creators of PhotoDNA, a widely used system for detecting child porn, told me. “AI is slower.”

YouTube has said that prior to 2020, its AI had gotten reasonably good at detecting “the few main narratives” that dominated “the misinformation landscape online,” (“9/11 truthers, moon landing conspiracy theorists, and flat earthers”). But when a wave of new pandemic mis- and disinformation began to flood the web, it took time for the company to retrain its algorithms and catch up.

Maybe someday AI will reliably grasp the difference between an exercise video and a porno, or between banter and hate speech. But an AI that can preempt the next trick up the misinformation community’s sleeve? That could be beyond science fiction.

Even if AI could filter out illicit video with superhuman acuity, there is still the task of ordering the endless feed. With extreme political content on the rise across the internet, the manner in which the algorithm chooses what to surface and recommend is a fraught technological question with very high stakes. Here, too, video is different.

When you engage with a video online, you generate far more data than you give up by just staring at a photo, according to Spandana Singh, a former policy analyst at New America's Open Technology Institute. Companies can track things like how many times you rewatched a video or how far through you made it before skipping to something else. “All that interaction data, I have to assume, goes into determining how videos are ranked,” Ricks told me. (TikTok and Instagram did not respond to a request for comment about how they use interaction data to serve content; both have information pages explaining that they use interactions to sort through and serve content.)

The AI that churns these data has proved astonishingly adept at keeping us on our screens as long as possible—sometimes with perilous results.

An internal Facebook document from 2020, which was released as part of the Facebook Papers and recently analyzed by a team at Amnesty International, describes how a video of the leader of the anti-Rohingya extremist group 969 circulated on Facebook two full years after the company faced widespread condemnation for its role in the Rohingya genocide. As it turned out, the clip’s numbers had not been driven by some coordinated campaign. Seventy percent of the video’s views had come through Facebook’s algorithmically fueled “Up Next” feature. The same team also noted that algorithmically recommended content already accounted for no less than half of the total time that Burmese users spent on the platform.

The issue is that an AI optimized for engagement can’t tell the difference between a clip that you enjoyed watching and one that you hate-watched, or watched passively. If you watched a clip multiple times, the AI won’t be able to discern whether it was because it gave you joy or because it boiled your blood. (Even if it could, a company might end up promoting infuriating content anyway because it’s so compelling—Facebook supposedly did exactly that after introducing emoji-based reactions a few years ago.) As Singh put it, “How do you train a recommender system to optimize for happiness? Like, what does that mean?”

Read: Artificial intelligence is misreading human emotion

Some people are trying to find out. Jochen Hartmann, an assistant professor at the University of Groningen, in the Netherlands, is part of an enthusiastic technical community building AI that hunts for the “unstructured” data within social-media video. Last year, Hartmann and three other researchers built a tool that analyzed video for a wide range of different qualities, including whether any given face in the clip expresses anger, happiness, disgust, surprise, or neutrality. If such a system could, say, rank videos by how happy they are, it might help elevate more positive content and subdue the darker stuff: less vitriol, more virtue. Researchers are also exploring using such techniques for detecting hate speech more effectively.

Of course, there’s a caveat. “All of this information,” Hartmann told me, “can be used to recommend new products.” It might be used, in connection with your personal data, for marketing.

And another: “Emotion recognition” is widely seen to be based on physiognomic theories that were revealed, decades ago, to be both thoroughly unscientific and startlingly racist.

Every expert I spoke with said that it’s hard to measure what we know to be true of AI in general against what’s actually going on inside the locked labs and servers of Silicon Valley. The algorithms behind products like Facebook and TikTok are “frustratingly and impossibly opaque,” as the Microsoft researcher Tarleton Gillespie has written.

Technology is also evolving rapidly. The forces governing video feeds today may not have much in common with whatever users will be subjected to a few years from now. “Here’s the one thing I’ve learned in my 30-year career,” Farid told me. “Don’t make predictions about the future when it comes to technology.”

If there is just one certainty in all of this, it is that video holds an embarrassment of data—and although these data might prove to be a stubborn obstacle for AI moderation and an impish enabler for recommendation engines, Farid is sure of this much: “Companies will figure out how to mine this massive amount of data to monetize it.”

In particular, video could be unimaginably useful for building the next generation of artificial intelligence. In 2016, the internet was briefly gripped by the Mannequin Challenge, in which people held poses as a camera moved around the scene. Two years later, Google revealed that it had used 2,000 mannequin-challenge videos to develop an AI capable of depth perception, a skill that will be essential for the kind of embodied robots that Silicon Valley hopes to bring to market in the coming years.

Other, similar experiments are surely in the works. Both Meta and Google recently unveiled prototype AI systems capable of turning any text prompt into video. It’s like DALL-E, but for the moving image—a cataclysmic prospect for keeping disinformation off the internet, according to Farid and Thakur, the Center for Democracy and Technology research director.

Maybe elsewhere in Silicon Valley, a team of engineers is using one of the mostly very boring videos I post about food to train up another AI. What for? Who knows.

I asked Farid if he thought those as-yet-shrouded future AIs will be built from the ground up with an eye to ethics. On this, he was also willing to break his rule against predictions. “No,” he said. “I’m not that naive.”",artificial intelligence,the atlantic
54,Weekly Review,https://harpers.org/wp-content/uploads/2020/03/5-Weekly-Review-FINAL.jpg,08/11/2022,"It was revealed that scientists increasingly don’t understand how artificial intelligence works.
The post Weekly Review first appeared on Harper's Magazine.",https://harpers.org/2022/11/weekly-review-jair-bolsonaro-lula-netanyahu-midterms-trump-biden-herschel-walker/,"Two days after losing an election, Brazilian president Jair Bolsonaro, who said that a congresswoman was too ugly to rape, led what Médecins Sans Frontières described as the worst COVID-19 response in the world, and claimed that he would “eat an Indian, no problem at all,” authorized the transfer of power to his opponent, Luiz Inácio Lula da Silva, without conceding defeat.1 2 3 4 Israeli prime minister Yair Lapid conceded defeat to former prime minister Benjamin Netanyahu after the nation’s fifth election in less than four years.5 Netanyahu, who is currently on trial for bribery and fraud, and under whose leadership Israel began to construct at least 19,000 settler homes in illegally occupied territory, won as part of a coalition with the Religious Zionism party, whose leader was convicted in 2007 of racist incitement against Arabs and who campaigned on the slogan “Who’s the landlord here?”6 7 8 9 Days before the U.S. midterm elections, for which billionaires have made over 7 percent of all donations, a federal judge ruled that an “election-monitoring” group may not take photos of voters, post information about voters online, or openly carry firearms near ballot boxes.10 11 “Some of us have horrible children,” said former president Donald Trump.12 It was revealed that 44 percent of voters believe that the government is controlled by a secret cabal.13 A Texan House candidate was reported to have written a novel in which Anne Frank embraces Christianity while imprisoned in a concentration camp, and Georgia Senate candidate Herschel Walker said that he has a solution to America’s major problems but won’t share it because Democrats would copy it.14 15 “They are good at lying to you,” he said. In a speech, President Joe Biden mislabeled the war in Ukraine as the war in Iraq and incorrectly stated that his son had died in the Middle Eastern nation.16 Research on mice showed that nose-picking might be linked to Alzheimer’s.17

Elon Musk fired nearly half of Twitter’s staff, including the entire accessibility and human rights teams, and, in a tweet, threatened to “thermonuclear name and shame” companies that had stopped advertising on the platform.18 19 20 North Korea test-fired more than 30 missiles, including an ICBM, and the United States responded by flying two supersonic bombers nearby.21 The Air Force denied that a refuel plane intentionally drew a penis in the sky near a Russian base.22 An Alaska Airlines flight was delayed for over two hours after the pilots could not get along, and a disabled woman in Australia crawled off a plane after staff tried to charge her to use a wheelchair.23 24 A nurse in Wisconsin was charged with abuse for cutting off a man’s foot without permission, and firefighters in Denver were suspended for having a living woman declared dead.25 26 A Ugandan woman was arrested on suspicion of drugging men by putting sedatives on her nipples.27 The chief of police in Willacoochee, Georgia, was arrested for burglary, and the mayor of Rufus, Oregon, was arrested for firing a gun at a moving car.28 29 A study found that most school shooters don’t have severe mental illness, and a teen who said that he was “tired of being stereotyped as a school shooter” was arrested for threatening to shoot up his school.30 31 “Zealous representation of a confessed murderer does not mean flipping the bird when you think the cameras aren’t on you,” said the father of a Parkland shooting victim to the killer’s defense team.32 In India, a child bit to death a cobra that had wrapped around his hand, and the Australian government determined that more research is needed before any attempt to use herpes to control the carp population.33 34

It was reported that a man pretending to be a Stanford student had been kicked out of the dorms after 10 months.35 Harvard argued for its affirmative action policies at the Supreme Court, and a judge ruled that the university would have to pay millions more for its defense because it forgot to notify its insurance company.36 The Powerball jackpot hit a record $1.9 billion, and a Chinese man who won over $30 million in a lottery accepted his check while wearing a mascot costume in order to hide the news from his wife and child.37 38 Amazon closed at less than $1 trillion in market value for the first time since the early days of the pandemic, and Jeff Bezos was sued by a former housekeeper who said his staff got UTIs from a lack of bathroom access.39 40 Google announced the creation of robots that can write their own code, and it was revealed that scientists increasingly don’t understand how artificial intelligence works.41 42 Engineers in Switzerland were reported to have built a drone with wings made of rice cakes, and Italian researchers announced techniques that can extend the shelf life of fresh pasta by a month.43 44 Bavarian police found crystal meth in a doughnut, and the mayor of Badiraguato, Mexico, defended spending over $700,000 on a museum of drug trafficking.45 46 On Halloween, Peruvian police executed a narcotics raid while dressed up as superheroes, and in Roachdale, Indiana, officers pursued a man who was recklessly driving a lawnmower while dressed as Pikachu.47 48 “No other Pokémon characters were involved in this incident,” the police department wrote. “However, we are not opposed to catching them all.” —Jon Edelman",artificial intelligence,harpers.org
55,Why Figma is selling to Adobe for $20 billion,https://cdn.vox-cdn.com/thumbor/ST_bggERPD8aS4WpWoUG8uFcJBI=/0x0:2040x1360/1200x628/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24176707/226396_Decoder_Dylan_Field_Figma_WJoel.jpg,08/11/2022,We also talked about AI and VR — but we know why you’re here: the upstart design platform sold to its biggest competitor. CEO Dylan Field explains why.,https://www.theverge.com/2022/11/8/23445821/figma-adobe-acquisition-design-vr-ai-meta,"Dylan Field is the co-founder and CEO of Figma, which makes a very popular design tool that allows designers and their collaborators to all work together right in a web browser. You know how multiple people can edit together in Google Docs? Figma is that for design work. We just redesigned The Verge; we used Figma extensively throughout that process.

So for years, people have been waiting on the inevitable Figma vs. Adobe standoff since Figma was such a clear upstart competitor to Photoshop and Illustrator and the rest. Well, buckle up because in September, Adobe announced that it was buying Figma for $20 billion. Figma is going to remain independent inside Adobe, but you know, it’s a little weird.

So I wanted to talk to Dylan about the deal, why he’s doing it, how he made the decision to sell, and what things he can do as part of Adobe that he couldn’t do as an independent company.

Dylan’s also a pretty expansive thinker, so after we talked about his company getting the “fuck you” money from Adobe, we talked about making VR Figma for the metaverse and AGI, which is artificial general intelligence, or the kind of AI that can fully think for itself. This episode takes a turn. I think you’re going to like it.

Okay, Dylan Field, CEO of Figma. Here we go.

Dylan Field is the co-founder and CEO of Figma. Welcome to Decoder.

Thank you. I’m excited to be on Decoder. Let’s make it happen.

Yeah! So you and I had dinner a while ago. It was before you were going to sell the company to Adobe and before we launched our redesign.

We may or may not have already been in talks with Adobe at that point. You were telling me about the redesign, and it hadn’t yet lit up the entire internet. I was very intrigued to see it at that point and saw it a little bit afterwards. You were telling me about the process of it. That was really cool to hear about.

Yeah, I was dangling. This is inside baseball of how we get people to come on the show. I was like, “I’ll show you the redesign, if you come on Decoder.” Then you announced your Adobe deal and went quiet, we launched the redesign, and now here we are — it finally happened. I’m very excited to talk to you. There’s a lot of Decoder stuff to talk about. Figma itself is a fascinating product with a lot of fascinating elements to how it works, what it runs on, all of that.

Let’s start at the very beginning. Tell people what Figma is in a way that they can explain to their friends who haven’t heard about it.

Listen to Decoder, a show hosted by The Verge’s Nilay Patel about big ideas — and other problems. Subscribe here!

Figma is a platform for visual communication design. We start off with FigJam, which is our brainstorming, whiteboarding, ideation tool. It’s a great place to help run meetings with your entire team and also to facilitate them, make them more fun and engaging, and bring more ideas forth. From there we have Figma Design, which is a great platform to be able to really work with your design team across the company and to express visual design, interface design, and more. Finally, we go into the design and production side. There is not a lot to talk about there today, but I think over the next year there will be a lot there to speak about.

When you say the design and production side, and how there will be a lot to speak about, do you mean actually generating the code that makes a website?

One thing people don’t realize is that about a third of the people that use Figma on a weekly basis are developers. I just think we could do a much better job of serving their needs. Right now we are so focused on designers and people that work very close to designers in that co-creation process. How do we make it so that there’s a better way to go from design to production, to do that handoff and to make it so that you’re able to align really well with your developer counterpart? I think there is a lot we could do there, so that is something we’re thinking a lot about right now.

So just to unpack that for people, let’s say you’re going to launch a new product or something on the internet. In FigJam, your client, your product manager, your designers, and other stakeholders all get together and have a meeting.

You might be in HR, sales, or really anywhere in the org. Anywhere that wants to design a better meeting, that’s FigJam. We’re seeing it all across the org now, which is pretty cool.

Okay. So from there, you go to Figma, where the actual designers design a product. Then from there, you have to go write some code to ship the product that’s been designed through this process.

Exactly, idea to design to production.

You’re saying you want to go into that last stage, but you’re not there yet.

Exactly.

So Figma is the main tool. It’s the thing that designers use and the reason the company is famous. I imagine it is the reason that Adobe wants to buy the company right now, because it’s the product that is taking market share away from them. It all seems very obvious right now, in the way that every successful company seems obvious at the end of one path. When you started this 10 years ago, people thought this was a bad idea. Talk about that journey, where you knew, “We want to bring design to the web in the way that Figma works on the web.” What was the moment that you knew it was going to work?

Totally. There’s a lot there. Before I get into it, I’ll also add that I think I probably had as much conversation and heard as much excitement from Adobe about FigJam as I have about Figma Design at this point. We’ll get back to that later.

Ten years ago, when I was an intern at LinkedIn, I heard its cofounder and then-CEO Reid Hoffman say, “Most good companies have a good why-now.” It’s interesting to think about the different why-nows that exist in software. For a long time, I couldn’t figure out Twitter’s why-now. I realized at some point that you had SMS, so people were used to short-form content exchange, and you also had this cultural change, which was AIM away messages. Remember away messages? You could update your away message — it was basically like Twitter before Twitter.

Yes, in a less democracy-altering way. I was a master of the away message.

Seriously, people were trained into this behavior, so it wasn’t new behavior when Twitter launched. It was something that enough people already had a critical mass around and knew how to do.

It can be social like that, or it can be a moment in time. “This thing was regulated; now it’s not regulated.” Or it could be a new technology. In our case, we were set on new technologies. We were looking at WebGL and drones. My co-founder was very convincing, saying that we shouldn’t do drones, so we went to WebGL instead and explored there.

It was like, “Okay, WebGL lets you use the GPU, your computer, and the browser. What can we do with that?” So we started proving it out. He had made a bunch of tech demos already, and we started to look at it in the context of professional-grade tools and eventually interface design.

The more we built with WebGL, the more confident we were that this could be a technology we could use to go build a professional-grade interface design tool. But like you said, no one believed us. I kept trying to recruit people, and I found that if I didn’t show up and immediately open my laptop to show them the tool working, they just wouldn’t believe me. I couldn’t even get them to wait around in a meeting. They would do it, because they were polite, but people form their first impression quite quickly. If I waited until the end of the meeting to show the candidates the tool versus showing them the tool in the first two minutes, it was a way different conversion probability of whether they were interested in the next step. If you’re sitting there with me for an hour, you’re just like, “This guy is full of it,” versus, “Wow, this is maybe legit.” It was a very different proposition.

So people didn’t believe that you could run desktop-class design in a browser using WebGL.

Not at all, no. I think there had been too many examples of prior art, and not just in creative tools, but also in folks trying to build really good web applications. Outside of things like Google Docs and G Suite, there weren’t a lot of good examples yet. Some people in the know were seeing that things like Onshape were starting to come out. I think Aviary was a predecessor to Figma in some ways. It did good work, but in Flash, so it was kind of the wrong technology at the wrong time. It’s amazing how just a few years can make that difference.

I actually want to get into the web and WebGL and what that means for Figma as a company.

Heck yes.

I think it’s really important but under-recognized. Figma is a web standards company in a very important way. But let’s come back to that. Let’s do the Decoder questions first. I think of these as the basic questions. How many people are at Figma right now after 10 years?

We’re nearing 1,000.

Have you scaled at a linear rate? Have you added 100 people a year for 10 years, or have there been peaks and valleys?

I would say we have roughly doubled year over year, most years.

Where do you double? How is Figma structured?

This last year we probably doubled across the org, with perhaps a bit more growth in sales.

In sales?

Yes, in sales and go-to-market in general. We see the customer demand there, and we’re trying to scale to reach it. Most years we have doubled pretty much across the board, though there are little variations here and there.

What does sales look like at Figma? Do you have people cold-calling giant companies and being like, “Have you thought about designing on the web?” Or is it inbound, where you are answering questions and designing licenses? What does the sales process actually look like?

It is mostly inbound and outbound. The go-to-market is very influenced by bottoms-up. I think in general, enterprise companies are not rocket science. You have to find customers somehow. Maybe it’s through marketing, maybe it’s through sales development representatives that are, like you said, cold-calling or cold-emailing, or maybe it’s through your product qualified leads.

A lot of it is product qualified for us. People that are using Figma say, “Okay, wait a second. My needs are evolving. I’m trying to get more of my company on Figma.” They are raising their hands, saying, “How can I do that?” We are trying to help, so we try to make it very consultative, to make it so that people are able to have us as a trusted partner. Then we’re able to work with them to figure out the right way to expand that Figma usage.

Just to be clear, the bottoms-up sale is when people at a company just start using a tool without telling anyone, which is how I do everything. That’s the bottoms-up. You get the users because they are using a good tool, and the company is sort of forced to buy the tool for everybody. The other way around is to sell the product directly to the Chief Information Officer (CIO).

Well, you work with the company.

Right, you work with the company.

Usually there is some combination of people saying, “Hey, this is interesting,” and us trying to get the conversation going early enough so no one feels weird about it. We build that relationship and try to make it so people understand what Figma is. Why could it be valuable? How could it work uniquely with your company? So you work together with a design leader, core product leader, or IT — the champions in the organization who want to see this become the standard — and together you bring it into the organization.

I think Datadog has a really cool history of serving developers. It has some similarities, not entirely one-to-one, but somewhat similar to designers. They have a very heavy motion of expansion. Over time the account grows, and they have managed to figure out how to add more value through new products. How we build new products and new services for our customers is something that we care about too.

As CEO you have a lot of people reporting to you. Where are most of the people reporting from? Is it on the product side? Is it the sales side? Do you just have a lot of accountants?

Engineering product development and sales are probably the biggest areas.

Is that where all the recruiting focus is?

It’s across the board. You want to make sure that people have a great experience coming to Figma regardless. What I tell people is that it’s every manager’s responsibility to recruit. You can’t really depend on dedicated recruiters. Though hopefully, a recruiter will make it a lot easier and will make sure the experience is really good. Then it is HR’s responsibility to make sure once people are in the building, they have a really great experience of being a Figmate — that they are learning and developing, have great career options and good mentorship, and if they need feedback, they’re getting it.

The cumulative sum of all that is that our culture is the best it’s ever been, because we have invested and focused so much on that over the past few years. We’ve had days where our culture was not as good, mostly in the early days. So I have a comparator point there and feel really good about how Figma works. Hearing feedback from newer hires that Figma matches what they were sold has been great to hear. But there are always ways to improve too.

Actually, let me ask you about those early days a little bit. You have been very open in other interviews and talks that you’ve done that you had to learn how to be a leader on the job at Figma. You received some pretty hard feedback along the way. As you mentioned, your only other job before this was as an intern. So here is the Decoder question. You are 10 years on this journey and you just made a gigantic decision to sell this company. How do you make decisions?

Depends on the decision, always. I think if it comes to product engineering, design, and roadmap, there is always a tension in wanting to give people some guidance on how to be top-down in terms of the strategy. Where is the company going in broad strokes? What are the top three things we are doing that everyone needs to know? But it also needs to be empowering. You need to make sure at all times that people across the organization are able to understand, be on the ground, talking with users, and be really deep in the details and technical specifics of what is possible or what is changing locally for their product area.

You want to meet somewhere in the middle of, “Here is the local feedback and the ideas that we have,” and the top-down, “Here is a point of view on strategy and where we should take the company.” Somehow those have to meet, and you need to be able to resolve tensions and work through any conflicts that arise. Education and context-building are areas that can really help with these things.

When it comes to making decisions in general, especially when you don’t have enough data, it’s not like there is one framework that is the magic framework. People talk about regret minimization, where you imagine yourself in the future and ask yourself which path you would regret less. That’s a really good framework, but it turns out it’s not the only one. You can come up with all sorts of frameworks for any decision you are trying to make.

An example is when we were deciding, “Okay, do we sell the company or not?” First of all, I was very lucky to have people around me, like my board, and once we eventually got to a certain point in the process, I was able to be more open to my exec team and talk with them as well. But ultimately, at the end of the day, it is my decision. I own the decision. I tried a multitude of frameworks, and each one led me to say, “This is a good call.” I won’t go into the details of all those frameworks.

What were the top two frameworks?

I won’t go into the details on all of them right now.

I didn’t ask for all them, I asked for two. What were the top two?

But I think what’s interesting is…

No, wait. What were the top two?

“Obviously monetary is a framework, right?”

Well, I mean obviously monetary is a framework, right? But it’s not the only one.

I knew it was the first one.

Impact. Impact is a framework. Will this lead to us having less impact? I think regret minimization is one that you could certainly think about. Anyway, I can list off 10 more, but again, I don’t want to go into the details there. Making sure that we were able to continue building a really important culture was definitely a consideration, so was attracting the type of people that we had been attracting. I think it would’ve been spooky to me if we didn’t think that was the case. I built a lot of conviction that it was. Thinking through all these different frameworks, not only did it highlight where the gaps were in my thinking and what things I had to figure out, it also highlighted important conversations I needed to have with the Adobe team.

The more I went into those conversations and brought up my concerns, the more I gained conviction that this was a really good decision for not just the company, but for our users and our community. It also built our trust and our relationship with the team. There was never a moment where I was like, “Oh, I have this framework that I’m trying,” that led me to a decision of, “We shouldn’t do this.” That was a sign. I think if you do get to a point where you have different frameworks that lead to different answers, you have to find some meta frameworks or a way to sort through all of them, which is maybe a little tougher.

All right. Let me give you a framework where it doesn’t work out so well. It’s shocking to me that you are out doing media in the middle of this acquisition. Here is a framework that the government is going to use: The Federal Trade Commission or European regulators are going to say Adobe is a gigantic corporation with dominant market share amongst designers in the world. Figma represented real and meaningful competition to Adobe, and was taking share away from Adobe in a variety of contexts. Adobe buying Figma reduces competition in the market. I have heard this from people who do not care about antitrust law, “Crap, this thing that was competing with Adobe that I was excited about is going to get swallowed by the board.” I have heard this from regulators who care a lot about competition from the market, and I have heard it from your local podcast hosts who think that tech companies need a lot more competition, especially big tech companies.

That is the framework that I think comes out as a “no,” right? You just listed off a lot of people you obviously care about, who are on your team and in control of the destiny of this company. You are going to cede some of their control over the future of Figma to a very large company with its own needs and aspirations, and might snuff out the thing that makes Figma such a good competitor. Whether or not you think that is the right policy choice, the right financial choice, or whatever, the thing that is exciting about tech is that there is always a disruptive challenger that shows up and knocks these giants off their pedestals. Figma is that thing. Isn’t that the framework that says, “No, you shouldn’t do this. You should see if you can actually knock Adobe off the map?”

I think for the user community, that was a critical component of the decision. That was probably the first audience that I thought of as we were thinking through it. As I thought through that decision and what we could do for the community, it actually led me to becoming more convinced that we should do this versus less so. Part of that is because there are a lot of things we don’t do in Figma today that are needed in the product development process.

If you think about product development, it’s not just pixels on the screen. You have a range of media types you are going to bring into the product development process in today’s world. Think about the Verge redesign for example. It’s not like you just use static imagery; you use video, and in the future you might use 3D content.

But those tools exist. We can pay for those tools too. Why does Figma need to be a part of those tools? It’s not like JPEGs and MP4s are difficult to move around.

I think that there are really good advantages that you can have as someone using a set of tools if the tools actually connect really well in one process. It’s like what we were talking about before. Figma is going from idea to design to production, and we are really trying to make the product development process as good as possible. What else can we do if we are able to bring more mediums into that? I think there are a lot of things that become possible there.

Name a thing. Name a specific thing. Adobe is a vast company. I think most people listening to this do not know that Adobe has a gigantic ads business. Many, many things can plug into whatever Figma is doing. Give me a concrete example of why being owned by Adobe is better than a partnership with Adobe.

Photo editing is a great example of something that I think we could do a much better job of in the product design process. There are a lot of times where you are using Figma plus other tools for photo editing, many of which might be owned by Adobe right now.

Why does the ownership of the tools matter?

It is extremely helpful to be able to go seamlessly into your workflow with a new modality, versus bringing assets and doing a complex import-export process into another tool. At the end of the day, our vision for Figma is to make design accessible to all, to make it so you are able to get things out of your head and onto the canvas faster. How do you do that while making it so that you are able to transition across these modalities quicker?

So you’re saying you’re opening Figma? I am just trying to be very concrete about this. You are opening Figma, you have designed some interface, you have a photo element in it, you click on it, and you get the full set of Photoshop tools right there in front of you, instead of having to open Photoshop and create a file.

I think there is a huge opportunity to bring these capabilities from Adobe Creative Suite and Creative Cloud into Figma and utilize them more, and to make it so that you are able to go and somehow transition across these different creative modalities to have a more seamless way of working.

By the way, we aren’t just talking about product design at the end of the day. I think that there is an opportunity to scale the impact of Figma much more broadly. We can start to make it so that you take the web-based tech, the different methods of collaboration, and the platform we have developed, and apply that to many other creative areas as well.

Finally, there is a huge opportunity to think about how creativity and productivity come together here. Like I mentioned at the start of our conversation, FigJam is not just a tool for designers. Isn’t this being used across the entire organization? It turns out that visual canvases are actually really helpful for tons of people to use. It’s a way for teams to come together, and it’s a way for people to run meetings.

A lot of people are trying to get into the creative productivity game. It’s heating up in competition a lot.

We are in a world where a lot of people are trying to get into the creative productivity game. It’s an area that is heating up in competition a lot. For example, Microsoft Designer just came out.

I mean, I’m rolling my eyes because another thing that just happened is that Adobe announced it was going to be purchasing Figma, and that it was going to sunset Adobe XD, which is the competitor to Figma.

I don’t think they announced that.

You can add and you can subtract from the market, and it is net zero that Microsoft is going to bundle some more stuff into the Office Suite. At the end of the day, Adobe’s competitor to Figma is going to go away because the company is going to own Figma. I hear you, in that there are ways to make things more seamless, but I’m still not clear on why Adobe has to own Figma to make these things happen.

I’m trying to highlight that there are a lot of things we can do here to make the customer experience of using Figma way better as a result of this. It’s really good for our community, really good for our user base, and really good for the designers in the Verge team.

We did our redesign on Figma. It was fun to use.

There is stuff in this structure that is really interesting to me. Everyone has been very clear that Figma will be an independent division inside of Adobe when this is all said and done — not a subsidiary, but a division of Adobe into itself. You’re going to report to an Adobe executive. Who are you going to report to?

David Wadhwani.

What is his role at Adobe?

He’s the chief business officer of Creative Cloud and Digital Media.

This is just a really small question. Did you get to pick? I have never been acquired. Did you look at a sheet with your kitchen cabinet of people and say, “All right, I’m going to report to this person,” or did they tell you?

I mean, look, I have had a great relationship with Scott [Belsky, Adobe’s chief product officer] since the start of Figma.

I think he reports to the same person, right?

Yes. I actually tried to convince Scott to be an investor early on. Turns out he was getting acquired, so I didn’t get him as an investor. We have continued to be friends and build that relationship over the last decade. In this case, it was David who was really bringing Figma in, and so I just assumed that was the structure the entire way.

So there was never a conversation. You never said, “I actually want to report to the CEO of Adobe”?

Nope.

How much do you stand to personally make from this deal?

Depends on the stock price on any given day. Look, that has not been my focus.

You’ve done the math. What’s the low and what’s the high?

I don’t have the spreadsheets in front of me. It becomes very complex.

Are you going to be rich when it’s done? Like private jet rich?

I feel very well-off already. I have nothing to complain about, and I feel super blessed and lucky. I couldn’t be more thankful to be where I am at 30, regardless of this deal.

How much will your employees get?

A lot.

I assure you, every one of your employees who has equity in this company has done the math. Is it significant? Are you going to mint a bunch of millionaires?

I hope that we’re able to make it so the team is able to do whatever they want to do, and to move on if they want to. Hopefully they will stay at Figma a long time, but they can also go make a great impact in whatever community they’re in. I think we have an incredible, super creative group of people at Figma. I’m really excited to see them be even more empowered.

The reason I ask all those questions in that way is because I think you are going to stay at Figma. My feeling is that you are very committed to this thing you started when you were a very young man. But when people get the “fuck you” money, they might leave. They don’t have to stay after the deal closes. You have to retain great talent that is going to enter the Adobe ecosystem, be able to leave, and even just do things inside of Adobe. It has to come into a much larger corporate structure that is going to have all the attendant Byzantine problems that come with it, as well as the resources. I don’t want to say there are no pros to that, but there are some cons.

The reason people join startups like Figma is the promise of this exit payday, which you will not be able to offer folks anymore. Have you thought about that life cycle? “Okay, I’m going to graduate out a bunch of people who are going to get the money — they’re going to get the bag and walk. Then my recruiting pipeline is going to dramatically change because the pot of gold at the end of the rainbow will be gone.”

This is wild, you don’t have to believe me if you don’t want to, but the number of people that started to apply to Figma after we announced this went up tremendously. Which is counterintuitive, because a lot of people have that mental model you just described. That is just the fact. I don’t know exactly what the percentage lift was and how sustained it was. I mean, it probably went down after the acquisition announcement a bit, but we have been getting people that are really excited about doing this at the combined company.

Well, the deal hasn’t closed yet, right? If you get a job at Figma today, you still get Figma equity that might get paid out.

It’s pinned to Adobe equity.

Okay.

If it ends up going through, then it becomes Adobe equity. If not, it’s Figma equity. I think that the chance of going and building this context is something that people are actually really excited about. Just looking at our team, we very deliberately tried to hire people that are super missionary throughout the company’s life.

We haven’t always been the highest-paying company. And you can always find a way to stretch a band and not be fair in your compensation, but we have been very deliberate about making sure that our compensation bands are fair and equitable. Through that, I think we have a lot of people who really believe in what we’re doing, not just people who are trying to make the most money. It turns out that this has become a good outcome and people are going to do really well in aggregate, which I’m super happy about. Our employees are in it because they really love creativity, design, and building things, and they love doing it for other designers and creatives. I think they’re stoked.

I think you probably know this, but Tony Fadell is a friend of the show and a friend of The Verge, and he was on Decoder recently. He has a book out called Build. It’s uplifting in many ways, except for the chapters about the Nest acquisition at Google, of which Tony has nothing but unreserved scorn. Nest was a company that had its own culture. He was building it, Google bought it, they dumped a bunch of money into this company, they turbocharged investment, Google culture seeped into the company, and things went totally sideways. I don’t know how familiar you are with that story, but it is a pretty common story. You do the acquisitions so you can turbocharge growth with other people’s cash.

Oh, there are really positive stories too. GitHub and LinkedIn are some examples. Pixar is a really good example.

Pixar is a different direction. Pixar ate Walt Disney Animation Studios.

Totally.

The culture of Pixar took over Walt Disney. Here’s my question for you. What are the safeguards against the negative outcome? The negative outcome is well-known. The positive outcome is well-known. Do you have a commitment in writing that Figma will be independent? How does that work? What is that conversation like?

There has been a conversation with all levels of Adobe and everyone related to the deal about the autonomy of Figma, our goals, and how we’re going to execute against them. Honestly, the open-mindedness of the Adobe team to think about this in a very unique way was part of what got us comfortable. They were amazing with it. The proof is in the pudding.

Do you have a contract that says Figma will be independent?

We have an operating model doc where we talk about autonomy within Adobe. That is not legally binding, but it is a plan.

Not in those words. We have an operating model doc where we talk about autonomy. That is not legally binding, but it is a plan. It’s important to think together about how we will make this combined company really amazing in the long term. Adobe is really wanting to set this up for success. Not just the management of Adobe, but having just been to Adobe Max last week, it’s the greater Adobe team as well.

I was really heartened by that reaction. Getting to meet them and spend time with them, we felt very welcomed. I’m really excited to spend that time with their team to learn and figure out how we go from here. How do we keep building and do the best thing for the customer and for that vision of making design accessible to all? And not just interface design, but more globally, all types of design, creativity, and productivity. There’s a lot to do there.

I have to ask you about the tweet, then I promise we’re going to move off of this and talk about WebGL. You know what tweet I’m going to ask you about. In January 2021, somebody said, “Give it 15 years and Figma will replace Adobe.” You replied, “The goal is to be Figma and not Adobe.” I have to point out to you that you’re about to become Adobe.

“I still stand by that tweet. I don’t take it back.”

Again, we are operating autonomously. We are going to have our own offices and our own culture. We are definitely going to have a lot of people that are coming from Adobe into Figma. We are going to interview people, so it’s not like an automatic rubber-stamp “yes.” We are also going to be interviewing people from outside of Adobe and Figma to come in. We are going to continue to have our values.

It turns out our values are actually very similar to Adobe. That is one thing I learned through this process. Our mission is very similar to Adobe. Literally, you put the values side by side and it’s like, “Wow.” Turns out, design-oriented creative people are attracted to these companies. Having met people at Adobe Max, a lot of them feel like Figmates already. There is probably a lot I didn’t know about Adobe at that point in terms of how close they felt to us in demographic employee makeup and psychological makeup. At the same time, we definitely want to preserve the best of Figma. I still stand by that tweet. I don’t take it back.

It’s a pretty bad market right now, if you look at the economy. This is not the market for companies to go public in. This is not the market to go raise money in. In all of your decision-making frameworks, did that factor into it? “Hey, it’s going to be really hard to get more money. We’re kicking the ass of our competitor Adobe a little bit. They’re ready to give us a bunch of money to accelerate this.” Was that one of the decisions here?

We were on a path to continue to be independent as well. We’re cash flow positive, and we’re doubling revenue year over year. We were in as good of a state as possible. It was really about the merits of a combined entity, what we could do together, how we could be useful, and how we could make this product better for our audience. That was really the thing that was weighed the most heavily.

Figma is a web product built on WebGL. You mentioned at the top of the show that WebGL’s technology lets you do 3D rendering on the web. The web is kind of under attack. On top of everything else, this primary surface that you distribute your product on, has maybe been perpetually under attack. First Microsoft tried to kill it, now maybe Apple’s trying to kill it, and who knows what Google’s trying to do with it, but it always feels a little unsteady. I know a bunch of designers who use Figma on Chromebooks. They don’t have Macs or Windows PCs, they just have nicer Chromebooks. You can use Figma on Chromebooks. The web is fundamentally Google’s revenue platform. Very few other companies make money on the web writ large. You make money selling seat licenses and enterprise software. You distribute on the web, but you don’t make money on the web. Google is one of the few companies that makes money on the web.

That means the Apples and the Microsofts of the world are constantly trying to push back against this and capture more value on their platforms directly. When I say a perceived threat, specifically what I mean is that Apple continues to encroach on the web on iOS. The Safari browser is a big deal, and there is a standards battle between Apple and Google in particular that gets pretty heated quite often. You need to build on those standards. Do you watch that from afar? Do you just hope that the web persists, grows, and innovates in a way that lets you build new features? Or are you like, “Screw it, we better have some native apps in the background”?

What are examples of the standards battles that you’re referring to?

WebGL itself. It needs to continue innovating, and it needs new standards-level capabilities that leverage new hardware capabilities and different computers over time. Apple in particular probably does not want to open up the entire graphics pipeline of the M Series chip to the web. They want to save that for their own native apps because a lot of designers run Macs. How do you get through that as a company?

Well, it turns out that you can make our software really efficient, even on WebGL, by mapping to low-end chips from phones that were from five years ago. Can we make it even faster with even more access to the hardware and even better standards? Absolutely. At the same time, if you’re efficient about your code and about the way you write your shaders and manage memory, it turns out it’s pretty incredible what you can do.

It’s a story that persists across computing for a long time. Look at what people were doing in the demo scene in the ‘90s. It was amazing. One thing that seems to happen with the way that programs and software evolve over time, is that you start to become less disciplined about the way you build software. There are more abstraction layers that exist over time.

As more abstraction layers exist in the software you’re building, each one incrementally slows down a little bit year over year — especially as they become a sort of black box that’s not actually introspected into and people rely on them in almost faith-based way. “Of course that abstraction level is good. We don’t touch it anymore. The person who worked on it is no longer here. Don’t go there. The code is really messy.” Then of course it degrades a little bit year over year.

At Figma, we try to be very disciplined about how we structure the code base, making sure that we continue to refactor our code year over year, that we clean up our tech debt, and that we take out old systems that are no longer needed. By doing so, we have been able to keep things really fast and efficient.

At the same time, maybe every month or two, something happens. I see some uptick on reports from our support channels or through Twitter, or I’m talking to someone and I realize, “Oh shit. With some chipset or model of computer somewhere, or after some recent update was launched, we introduced some regression. Figma slowed down in some way, and someone is unhappy.” Our team has a really good culture of identifying these issues, diving into them and talking with users, and figuring out what’s going on and fixing it.

We also do a lot of good performance testing to make sure that we are able to continually monitor and understand if we are still on-track or if we are off-track somehow. Did we ship something that’s bad? By having that really high standard from the start and maintaining it over time, that hasn’t been an issue for us. Of course, we are always looking for the web to be better, but I think the fact that we have our render based in WebGL gives us a lot of control over what we actually write to the canvas. That means that we are sort of on this weird, independent path that is a little bit different than having to run every single thing in web standards.

Now, that said, browsers do occasionally ship something where they’re trying to fix something over here or in a different spot, and there is some kind of inefficiency that’s added or an issue that accumulates. We have worked really hard since the start of the company to maintain and build relationships with browsers so that if that happens, we’re seeing in a canary or beta build that there is an issue. We are then able to flag it to a browser vendor way ahead of time, tell them that issue has occurred, show them the reproducible steps, and help them patch the issue. Doing that over time, having those relationships, and hiring people that worked on browsers in the past, who have a deep understanding of the browser stack, has also helped.

Do you think that you need to ship native apps on Mac, Windows, iOS, and Android? I mean there are native apps there, but again, the primary canvas here for you is the web.

There’s definitely an opportunity to do more natively in the future for Figma. For example, there’s pen and touch input. Even if web standards improve a ton, there is probably some better feeling of lower latency if you do more of the handling of those gestures natively than on the web. Then of course, there is always that next thing of, “Well, maybe we could do this thing natively instead of on the web.”

It turns out that “on the web” is good enough most of the time. However, I think we are constantly trying to figure out, “Okay, what’s the next thing that we can start to do natively? What’s the progression of that over time?” I do think that eventually a tablet version of Figma will be really useful.

One thing we’re excited to announce very soon — and I’ll give you a little sneak peek — is our mobile comments that are coming out. Making sure we could add that in a performant way was really important to us. If you think about it, there is a lot that we can do with comments on mobile that is unique to the mobile form factor over time. We’re super stoked about that.

We also have a bunch we’re doing with FigJam on tablets, and we’re adding more functionality. For example, we’re making it so you can play music while you’re in FigJam now. We’re making it so that you can do better integrations with Teams, GoMeet, and Zoom, as well as add sections, tables, and better text formatting. People have asked for these things for a long time. We are able to add this stuff even though we’re not having a ton of native surface area with FigJam, but we are trying to improve that native surface area over time.

It’s hard to go get this stat, but my instinct is that Figma is one of the biggest and most lucrative WebGL clients out there. There aren’t a lot of others, so it seems like a safe bet. Figma is a big and lucrative company. The product is excellent, a lot of people use it, and there’s just not a lot else. You are built on this thing that you depend on, maybe in a way that the other users of WebGL don’t depend on — they’re mostly games, from what I can tell.

I think there’s going to be a lot more people that use WebGL over time. I’m excited to see so many people betting on the browser as a platform. I get emails every day of people that are building Figma for X (you fill in the blank). People are doing it and they’re betting on the web.

If that was the only thing that we looked back on in 10 years and we said, “Wow, because of Figma existing there are more people on the web,” that would be something that would make me feel really proud. I think and hope there will be a lot more too. It’s really cool to see so many people betting on the web now, whereas before it was something that people just didn’t believe in.

I mean, I’m a huge proponent of the web. I think more people should bet on the web every day. That comes and goes in waves. Five years ago, if you weren’t shipping a native phone app, you were basically not in the conversation to get funding. Why do you think the web is back in vogue?

I think that the power of the URL is one where you’re able to easily share content. I can pass content from me to you so easily with a URL. Having that URL as this global address that people can find information off of forces choices for a medium.

So for example, if you don’t have multiplayer editing on the web, it just feels wrong. That doesn’t mean you have to be on the web to have multiplayer editing. You can do it natively too. But they go together really well. It also goes together really well when you have a URL on top and can share it with people. There’s this cluster of features and functionality I think that starts to merge, where it just feels better to be able to navigate from links that you’re encountering on email or Slack onto a website, where you’re able to have this rich content experience and then in the browser, work.

The web really captures the ethos of my generation... transparency, access, and collaboration.

It really captures the ethos of my generation at least. I can’t speak for my generation…

Be the voice of a generation, Dylan, you can do it. You have the name for it. Do it.

Some of the things that I feel are really important, and I think a lot of my peers feel are important, are transparency, access, collaboration, and working together. I think the web really embodies that ethos. A lot of desktop software didn’t traditionally embody that ethos, it was more siloed. It’s not like there is one thing that makes the web so powerful, but being able to have that cluster of functionality of values ends up really having an amazing effect.

Do you make strategic decisions at Figma around the market shares of different browser engines on desktop? Chromium is really dominant. Microsoft was forced to effectively concede and move Edge to Chromium on mobile Safari. If you don’t address mobile Safari, you don’t get a whole bunch of people, because there are no other browser engines on the iPhone. Is that something that you have to think about as you make technical and business decisions?

Not really. If that conversation is happening, it’s not rising to me. Like I said before, when there are issues, we have to pay attention to them. We have to be in communication with browser vendors. It’s probably the case that there are small bugs or issues that exist, and depending on market share, that impacts the priority at which we attack those and push browser renders to try to fix those things. That’s probably the extent of it.

Does anything on that level come up to you? Do you ever get a phone call that’s like, “I need you to call Sundar Pichai and get him to fix Chrome”? Does that happen to you?

I’m laughing at the Sundar thing, because I literally have an email thread from a long time ago — I forget exactly what it was about at the time, but this was like 2015 — where I was trying to get some issue fixed with Chrome, and I got an intro to Sundar who was not yet CEO of Google. It went all the way to Sundar, then it went through this chain of product managers, and eventually it ended up with my friend, who already knew about it because I hung out with her all the time. She was like, “Oh, hi Dylan.” I felt like a total fool for escalating that one.

How often do you escalate things? Does it happen, or is that mostly on the technical side of the company?

It hasn’t happened much recently, because we now have such good relationships with browsers and they have been so helpful. In the earlier days, we just didn’t have the attention of these teams, partially because we weren’t at scale yet. If you have more people that are being impacted by an issue, that impacts the time in which that issue is dealt with, which makes sense, right?

Yeah. You mentioned bottoms-up. The reason I’m asking is because I wonder, does it get easier when half the company is using your tool and they are running into problems?

Totally. Oh, absolutely yes.

I have to imagine that that is the case at Microsoft, Google, Apple, and all the rest.

For sure. When Google adopted Figma, I feel like they definitely cared a lot more about Figma running well, which also makes sense.

I just spotted my review unit of the Meta Quest Pro, it’s just sitting right over there, so I need to ask you about VR. Meta thinks that we’re all going to be hanging out in the metaverse, winking at each other and connecting emotionally because we can see each other’s faces. They have a little bit of a whiteboarding tool. It’s very early. Is that something that you see being competitive with you? Is that something that you want to participate in? Is that just a distraction?

I think it would be great participating in that one day. Right now, we are still early in terms of how many people are using VR, but it seems like an exponential graph, which is really exciting as a new platform. But we’re at the early stages, so I think we’ll probably spend more calories thinking about that when that exponential curve goes up more.

You’ll believe it when you see it is basically what you just said.

No, no. I mean, I like VR. I was on paternity leave early this year, and I spent a lot of time in VR. It’s really good. I’m excited to try the new Quest 2, by the way. I think as a gaming platform, it’s excellent; I think as a productivity platform, it’s emerging. There is still stuff that has to be solved around how much time you can spend in VR without getting a headache, motion sickness, or fatigue. I personally don’t get motion sickness or a headache, but I know people that do. I still feel some fatigue after half an hour to an hour in VR.

Now I haven’t tried the new headsets yet, so it’s possible that it has been fixed already. When I tried VR in 2016 or 2015, it was for like five minutes. After that I felt like I had a crazy night out drinking. Now it’s such an improved experience, and I feel like it is going to keep improving, just like there are going to be more people adopting it. It might be exponential. As it gets to that point where you can spend a few hours in VR and take the headset off and say, “I feel fine,” I think the possibilities unlock a lot more. I’m actually quite bullish on VR, and I’m really impressed with Meta’s dedication to the platform. I think it’s quite visionary and bold. It’s a great example of someone trying to will a new technology into existence.

How many engineers are you paying to build VR Figma right now?

Zero.

Right. I love my Quest 2. I use it every day, but I use it as a fitness platform to work out. If I try to use it for collaboration, I would tell you that being on a Zoom meeting with FigJam open on a tablet, just so I can draw at people, is immediately more evocative to me than all of us being cartoons in the metaverse. I’m just wondering where you are calibrated on that spectrum.

When you take these paradigms and you try to retrofit them into a new space, it’s not always right. It’s a good starting point, but I think that the real opportunity is probably that task of having a meeting, of brainstorming, of ideating, of trying to collaborate in a space. Those are the things people are trying to do in FigJam. What does it mean to do that in VR? I think that’s a much more interesting question than, “How do you take this 2D primitive and put it on a plane in a 3D space in VR?” When we get to the point where we see the traction of the platform and, like I said, the ergonomics are a little better, I think it’s going to be really exciting to explore this.

By the way, we are just now building tablet for FigJam and for Figma, and tablets have been around for a long time. It’s not like this is a new thing. It takes a lot to remove people from the surface that they’re already used to and put them on a new one. You have to demonstrate some benefit. That said, as a product person and as someone who cares for design, I love the challenge of being able to work in a new medium, and to think about the ways to solve that product challenge in that new medium. That’s really exciting.

By the way, a lot of what you’re saying around VR, “Oh yeah, I use it for fitness.” I’m like, “I use it for gaming.” It reminds me of crypto in some ways.

Oh God. This is another hour. You have another hour for this metaphor?

I have time. Do you have time?

Let’s do it.

With crypto, for a long time it was like, “Yeah, people are just gambling on this thing. What’s it good for?” It was like, “Well, maybe there’s a store of value.” Then it was, “Well, maybe there’s this DeFi thing.” Now it’s like, “How about NFTs?” Perhaps next there’s gaming.

I’m not saying that the crypto industry is without sin. There are a lot of things that are pretty fucked up in crypto. But I’m also saying that what you see when you have a new technology or platform emerge is that people discover the use cases of it one by one. At first it seems like it’s nascent, that it’s actually worthless, et cetera. Then over time you realize, “Holy crap, there is a lot going on here, and there’s so much that we can do on this new platform,” like machine learning.

I remember when we were starting Figma, and Chris Olah was in my Thiel Fellowship class. He later went on to work on Google Brain, and was responsible for all sorts of interesting research into how neural nets actually work. Then he was at OpenAI, and now Anthropic. He was showing me these very hacked-together demos in his terminal, where he was shoving into AWS, running on GPUs, very basic neural nets. He’s like, “This is amazing.” I was like, “Yeah, it’s cool. You can classify some numbers. I’ve seen the same demo before.”

What I was missing was the exponential curve of that technology, and the fact that it was actually a paradigm shift from more structured machine learning models and people trying to use hardcore math to make AI into this new representation and new way to actually solve problems. Then you get something like transformers on top of that, and suddenly so many more applications become possible. We are at this phase now, and not just with Generative Adversarial Networks (GANs) and diffusion models, where people are actually taking some real, interesting tech and applying it to entirely new industries and new areas. The use cases are proliferating.

Let me push back on this just a little bit, because this is fascinating. AI, machine learning, and now generative image models are all a very cool party trick, right? I know some newsletter authors who are like, “I’m going to illustrate my newsletter with DALL-E.” That’s cool, it’s very neat. There’s some stuff that might get built on top of it, and there are some machine learning applications that are indeed very useful to large industries all over the place. They are capabilities that were layered into things people are already doing, or capabilities that were layered in to make something cheaper. Image generation is actually just going to make something much, much cheaper for people.

In VR and crypto, they are applications in search of a market. I don’t think DeFi is an actual application yet. It’s a conceptual market that might exist if crypto works the way we want it to. I mean, I have the VR headset; I use it for games and fitness. It’s searching for its big consumer application, and they keep firing things at the wall. I think that’s a real difference. I could come to you and say, “Okay, in five years I’m going to type ‘music player app’ into Figma, and Figma is going to call up DALL-E and fire out a sketch of a music player app that I can then further manipulate.” I can see that sitting from here, whereas I couldn’t tell you what NFT capability you should add to Figma today.

First of all, it’s pretty amazing. A year or two ago, I think, if we were having the same conversation about AI/ML, you could very easily have said, “Hey, this is research in search of a problem. This is just a bunch of people who are doing cool math, and it’s not clear that there’s actually something here yet. What are these models actually good for? You got GPT-3 sure, but what recent advancements have we seen? In GPT-3, large language models have kind of been tapped out. What are people building on it?”

It turns out, even on GPT-3, let alone the new improvements we’re seeing to large language models, we’re actually seeing incredible things being built on those now, and they’re impacting a lot of different industries. The timing of the question ends up mattering.

There is something to having scarce digital goods. Do I think it was overhyped and there’s a bubble? Absolutely, I do. I think that’s the curve that most technology is on. In fact, I think that we’re probably going to see an even bigger bubble around a lot of things that are called AI as a collection of things. If I’m seeing the VC investment patterns that are going on, AI feels a lot like crypto right now.

Fair enough.

From before the crash, just to be clear. Every technology has a hype cycle, and with VR, at the end of the day it’s like, “Okay, what are the behaviors that are new that you’re doing?” Did you increase your fitness spend when you got an Oculus Quest?

Yeah, I really did. It’s a real thing that happened. You should listen our episode with Chris Milk from Supernatural. We talked about the whole thing.

I will. I’m sorry I missed it.

It’s the thing that drives VR adoption. It’s a completely under-reported phenomenon that the thing that drives VR adoption is fitness. I think it’s fascinating. Here is this thing that’s supposed to disembody you into the internet, and it makes people consider their bodies in a much different way. It’s great. I totally buy it.

It is fascinating. It’s also interesting that the GDP has gone up too. There has actually been a net value creation there. Crypto is interesting because it’s a little bit different when it comes to value. There are a lot of things in the crypto ecosystem that I wouldn’t call Ponzi, but they have these Ponzi characteristics. The more money that flows in the system, the more the asset price goes up; the more money comes out of the system, the more the asset price goes down. It’s wrong to say that collectibles markets or art markets don’t have value. At the same time, there’s something about that characteristic that people realize feels a little weird. Then AI could be very deflationary, by the way.

How so?

“All technology is deflationary, but depending on how much more efficient AI makes things, it could cut into the time that people are being paid for.”

Well, all technology is deflationary, but depending on how much more efficient AI makes things, it could cut into the time that people are being paid for.

I see what you mean. So let me ask you this directly. I mean, this is your business, right? You make people more productive and you make designers more collaborative. Do you foresee a world in which Figma has generative tools in it, so that I really can type in “new Verge website” and Figma pops out a mock for me to then iterate on?

I think that there are a lot of ways to do that. What I’m excited about is how you make it so designers are able to explore more of an option space, and then bring in their expertise as well. It’s like getting inspiration from a model, just like they get inspiration from looking at other designer’s work on Dribbble, Behance, or in Figma’s community. A generative model is your operating lead in the space. It’s kind of the same thing in some ways. People may not like me saying that, but I think inspiration can be drawn from lots of places. How do you work with an AI agent versus an AI agent replacing a designer? I think across all creative work, that is going to be a really important thing to figure out.

Let’s just take the bear case, which is that the tech we have today is the tech we get. There’s no evolution. Never mind that every day on Twitter I’m seeing two new papers that are mind-blowing. Let’s just say that stops tomorrow. So the bear case is what we have now in AI. If we can take that and just apply it to new areas of the economy, that is already going to be very disruptive. We would continue to see the base case for some time, then it asymptotes. At some point, we don’t see much more around AI for a while. The capabilities kind of max out across a few domains. Again, it’s even more disruptive. In a bull case where there’s AGI [artificial general intelligence], I don’t even know how to think about that. I think that the world could get really weird, really fast.

Then we’re all out of work. That’s the most deflationary.

No, work might just change in a very fundamental way.

If there’s AGI? Yeah, we’ll all be working for the robot.

I made a tweet recently. I’ll read it to you.

Oh my God.

I did a poll. I said, “AGI has arrived. Everyone is saying it’s way smarter than humans and well-known experts claim it’s ‘human aligned.’ Recently political leaders asked the AGI to propose an ‘optimal system of government,’ (and resulting constitutional amendments). Would you consider the proposal?” The options were yes, yes if still democracy, no, and see results; 21.5 percent said see results. The remainder: 35.3 percent said yes, 25.5 percent said yes if still democracy, and 17.7 percent said no.

I thought that was really interesting. First of all, I was surprised that so many people were open to nondemocratic systems of government, which is not something I would have expected going into that question. Also, I thought the no answers would be higher, because if you think about it for a second, if AGI existed, it would be able to basically market to you whatever idea it had in a way that would presumably sway your opinion. The fact that less than 20% of people said no, it’s like, okay, people are open to the idea of an AGI-proposed utopia.

Now how do you know if it’s actually human aligned? There are a lot of alignment issues that come up with that too, that I think are just not even on people’s radar yet. Again, AGI is too complex. I don’t know. It breaks my brain a little bit.

Yeah. I think you and I are going to be lucky enough to not have to experience it. I worry about our kids. All right, we have to get out of here. I can’t believe we got all the way to AGI in this interview. Dylan, you’ve given us so much time. I really appreciate it. I think I know what’s next for Figma, but what should people be on the lookout for?

So much. There’s going to be a ton that we do around Figma Design over the next year, and I’m excited for people to see that. We’re just at the start for design systems, and FigJam is in collaboration with that. Like I said, we are launching a bunch around collaboration today. There will be new areas where you’re able to add nouns to the FigJam canvas, like tables, music, voting integrations, mobile comments, and notifications. There’s so much more coming for FigJam. We’re trying to make it so that you’re able to have A-sync/B-sync, and make it so that your means are able to run better, whether you’re in the file at the same time or not. There will be lots more over the next year about that.

Going back to the start of the conversation, how do you navigate that process and product development, from idea to design and production, and make it a really great process? To do that handoff, whether it’s a design system or your design file, with engineering more effectively and make it a great experience for developers in Figma, that is another area that we really care about.

All right. This was great, man. Thank you for getting into it. I loved it. You have to come back soon. We’ve never had anybody in the middle of an acquisition, so now we have to follow up after and see how it went. So come back soon, Dylan. It was great talking to you.

I look forward to it. It was great to see you, and thanks for having me.",artificial intelligence,the verge
56,More cartoon characters brought to life with AI (25 Photos),https://thechive.com/wp-content/uploads/2022/11/ThumbnailTemplateNEW-8.jpg?attachment_cache_bust=4240979&quality=85&strip=info,06/11/2022,See the full gallery on thechive.com,https://thechive.com/2022/11/05/more-cartoon-characters-brought-to-life-with-ai-25-photos/,"1

Hidreley Diao is a digital artist that uses artificial intelligence to bring cartoon characters to life and show their proper human form. Which one do you think nailed it and which one needs some recalibration?",artificial intelligence,thechive.com
57,"Artificial Intelligence Based Medical Device Market will Turn over in 2022 to 2025 Research by Business Opportunities, Top Companies report covers (Google,Apple,Microsoft,IBM,NVIDIA Corporation,Medtronic,)",https://media.zenfs.com/en/globenewswire.com/934835f9b53bfc35497459b8b018252e,06/11/2022,"PUNE, Nov. 06, 2022 (GLOBE NEWSWIRE) -- ""Artificial Intelligence Based Medical Device Market"" research report focus on overall information that can help to...",https://finance.yahoo.com/news/artificial-intelligence-based-medical-device-050900701.html,"Proficient Market Insights

PUNE, Nov. 06, 2022 (GLOBE NEWSWIRE) -- ""Artificial Intelligence Based Medical Device Market"" research report focus on overall information that can help to take decisions on current market situation. Artificial Intelligence Based Medical Device market using different methodologies and analyzes to provide accurate and in-depth information about the market. For a clearer understanding, it is divided into several parts to cover different aspects of the market. Each area is then elaborated to help the reader comprehend the growth potential of each region and its contribution to the global market. The researchers have used primary and secondary methodologies to collate the information in the report. They have also used the same data to generate the current market scenario. This report is aimed at guiding people towards an apprehensive, better, and clearer knowledge of the market.

Artificial Intelligence Based Medical Device Market Report Contains: -

Complete overview of the global Artificial Intelligence Based Medical Device Market

Top Country data and analysis for United States, Canada, Mexico, Germany, France, United Kingdom, Russia, Italy, China, Japan, Korea, India, Southeast Asia, Australia, Brazil and Saudi Arabia, etc. It also throws light on the progress of key regional Artificial Intelligence Based Medical Device markets such as North America, Europe, Asia-Pacific, South America and Middle East and Africa

Description and analysis of Artificial Intelligence Based Medical Device market potential by type, Deep Dive, disruption, application capacity, end use industry

impact evaluation of most important drivers and restraints, and dynamics of the global Artificial Intelligence Based Medical Device market and current trends in the enterprise

Get a Sample Copy of the Report at - https://proficientmarketinsights.com/enquiry/request-sample/18698370

Artificial Intelligence Based Medical Device Market Segmentation: -

researcher’s latest report provides a deep insight into the global Artificial Intelligence Based Medical Device market covering all its essential aspects. This ranges from a macro overview of the market to micro details of the market size, competitive landscape, development trend, niche market, key market drivers and challenges, SWOT analysis, Porter’s five forces analysis, value chain analysis, etc.

Story continues

The global Artificial Intelligence Based Medical Device market size is projected to reach US$ XX million by 2027, from US$ XX million in 2020, at a CAGR of XX% during 2021-2027.

Inquire or Share Your Questions If Any Before the Purchasing This Report – https://proficientmarketinsights.com/enquiry/pre-order-enquiry/18698370

Global Artificial Intelligence Based Medical Device Scope and Segment

The global Artificial Intelligence Based Medical Device market is segmented by company, region (country), by Type, and by Application. Players, stakeholders, and other participants in the global Artificial Intelligence Based Medical Device market will be able to gain the upper hand as they use the report as a powerful resource. The segmental analysis focuses on revenue and forecast by region (country), by Type, and by Application for the period 2016-2027.

Artificial Intelligence Based Medical Device Market segments help decision-makers direct the product, sales, and marketing strategies, and can power your product development cycles by informing how you make product offerings for different segments.

Segment by Type

Machine learning

Deep learning

NLP

Computer Vision

Predictive Analytics

Others

Segment by Application

Predictive Maintenance/Self Diagnostics

Virtual Assistance

Network Operations & Monitoring Management

Others

Market segment by Region/Country including: -

North America (United States, Canada, and Mexico)

Europe (Germany, UK, France, Italy, Russia and Spain, etc.)

Asia-Pacific (China, Japan, Korea, India, Australia, Southeast Asia, etc.)

South America (Brazil, Argentina, Colombia, etc.)

Middle East & Africa (South Africa, UAE, Saudi Arabia, etc.)

Key Players in the Artificial Intelligence Based Medical Device Market: -

Google

Apple

Microsoft

IBM

NVIDIA Corporation

Medtronic

GE Healthcare

PathAI

Aidoc

Get a Sample Copy of the Report at - https://proficientmarketinsights.com/enquiry/request-sample/18698370

Key Benefits of Artificial Intelligence Based Medical Device Market Research Report:

Types, applications, regions, and key players covered in the study

Industry drivers, restraints, and opportunities covered in the study

Recent industry trends and developments

Competitive landscape & strategies of key players

Historical, current, and projected market size, in terms of value

In-depth analysis of the Artificial Intelligence AI Chips Market

Sales, price, revenue, market share, and growth rate are covered in the report sales channels, distributors, traders, dealers, etc. are covered in the report

Detailed TOC of Global Artificial Intelligence Based Medical Device Market Report, History and Forecast 2016-2027, Breakdown Data by Companies, Key Regions, Types and Application

1 Market Overview of Artificial Intelligence Based Medical Device

1.1 Artificial Intelligence Based Medical Device Market Overview

1.1.1 Artificial Intelligence Based Medical Device Product Scope

1.1.2 Artificial Intelligence Based Medical Device Market Status and Outlook

1.2 Global Artificial Intelligence Based Medical Device Market Size Overview by Region 2016 VS 2021VS 2027

1.3 Global Artificial Intelligence Based Medical Device Market Size by Region (2016-2027)

1.4 Global Artificial Intelligence Based Medical Device Historic Market Size by Region (2016-2021)

1.5 Global Artificial Intelligence Based Medical Device Market Size Forecast by Region (2022-2027)

1.6 Key Regions, Artificial Intelligence Based Medical Device Market Size (2016-2027)

1.6.1 North America Artificial Intelligence Based Medical Device Market Size (2016-2027)

1.6.2 Europe Artificial Intelligence Based Medical Device Market Size (2016-2027)

1.6.3 Asia-Pacific Artificial Intelligence Based Medical Device Market Size (2016-2027)

1.6.4 Latin America Artificial Intelligence Based Medical Device Market Size (2016-2027)

1.6.5 Middle East & Africa Artificial Intelligence Based Medical Device Market Size (2016-2027)

2 Artificial Intelligence Based Medical Device Market Overview by Type

2.1 Global Artificial Intelligence Based Medical Device Market Size by Type: 2016 VS 2021 VS 2027

2.2 Global Artificial Intelligence Based Medical Device Historic Market Size by Type (2016-2021)

2.3 Global Artificial Intelligence Based Medical Device Forecasted Market Size by Type (2022-2027)

2.4 Machine learning

2.5 Deep learning

2.6 NLP

2.7 Computer Vision

2.8 Predictive Analytics

2.9 Others

3 Artificial Intelligence Based Medical Device Market Overview by Application

3.1 Global Artificial Intelligence Based Medical Device Market Size by Application: 2016 VS 2021 VS 2027

3.2 Global Artificial Intelligence Based Medical Device Historic Market Size by Application (2016-2021)

3.3 Global Artificial Intelligence Based Medical Device Forecasted Market Size by Application (2022-2027)

3.4 Predictive Maintenance/Self Diagnostics

3.5 Virtual Assistance

3.6 Network Operations & Monitoring Management

3.7 Others

4 Artificial Intelligence Based Medical Device Competition Analysis by Players

4.1 Global Artificial Intelligence Based Medical Device Market Size by Players (2016-2021)

4.2 Global Top Players by Company Type (Tier 1, Tier 2 and Tier 3) & (based on the Revenue in Artificial Intelligence Based Medical Device as of 2020)

4.3 Date of Key Players Enter into Artificial Intelligence Based Medical Device Market

4.4 Global Top Players Artificial Intelligence Based Medical Device Headquarters and Area Served

4.5 Key Players Artificial Intelligence Based Medical Device Product Solution and Service

4.6 Competitive Status

4.6.1 Artificial Intelligence Based Medical Device Market Concentration Rate

4.6.2 Mergers & Acquisitions, Expansion Plans

And more…

Explore Full Report With Detailed TOC Here: https://proficientmarketinsights.com/TOC/18698370#TOC

1.To study and analyze the global Artificial Intelligence Based Medical Device consumption (value) by key regions/countries, product type and application

2.To understand the structure of Artificial Intelligence Based Medical Device market by identifying its various sub segments.

3.Focuses on the key global Artificial Intelligence Based Medical Device manufacturers, to define, describe and analyze the value, market share, market competition landscape, Porter's five forces analysis, SWOT analysis and development plans in next few years.

4.To analyze the Artificial Intelligence Based Medical Device with respect to individual growth trends, future prospects, and their contribution to the total market.

5.To share detailed information about the key factors influencing the growth of the market (growth potential, opportunities, drivers, industry-specific challenges and risks).

6.To project the consumption of Artificial Intelligence Based Medical Device submarkets, with respect to key regions (along with their respective key countries).

7.To analyze competitive developments such as expansions, agreements, new product launches, and acquisitions in the market.

8.To strategically profile the key players and comprehensively analyze their growth strategies.

Key Reasons to Purchase

To gain insightful analyses of the market and have comprehensive understanding of the global Artificial Intelligence Based Medical Device market and its commercial landscape.

Assess the production processes, major issues, and solutions to mitigate the development risk.

To understand the most affecting driving and restraining forces in the Artificial Intelligence Based Medical Device market and its impact in the global market.

Learn about the Artificial Intelligence Based Medical Device market strategies that are being adopted by leading respective organizations.

To understand the future outlook and prospects for the Artificial Intelligence Based Medical Device market.

Besides the standard structure reports, we also provide custom research according to specific requirements

Purchase this Report (Price 3350 USD for a Single-User License) – https://proficientmarketinsights.com/purchase/18698370

About Proficient market insights:

Proficient market insights is an upscale platform to help key personnel in the business world in strategizing and taking visionary decisions based on facts and figures derived from in-depth market research. We are one of the top report resellers in the market, dedicated to bringing you an ingenious concoction of data parameters.

CONTACT: Proficient market insights Phone : +1 424 253 0807 Phone : +44 203 239 8187 Email : sales@proficientmarketinsights.com Web: https://proficientmarketinsights.com/



",artificial intelligence,yahoo entertainment
58,Artificial Intelligence (AI) In Retail Market is Projected to Reach US$ 49.09 Billion in 2028,https://media.zenfs.com/en/globenewswire.com/07ee875c965bd771c3af25d9aae2d2f8,10/11/2022,"Artificial Intelligence In Retail Market is expected to reach US$ 49.09 Billion in 2028, growing at a CAGR of 38.05% during 2022-2028, reports Stratview...",https://finance.yahoo.com/news/artificial-intelligence-ai-retail-market-073700219.html,"Stratview Research

Artificial Intelligence In Retail Market is expected to reach US$ 49.09 Billion in 2028, growing at a CAGR of 38.05% during 2022-2028, reports Stratview Research.

Raipur, Nov. 10, 2022 (GLOBE NEWSWIRE) -- Stratview Research, a leading market research firm has launched a report on the Artificial Intelligence In Retail Market which provides an in-depth analysis of the market dynamics, current and emerging trends, industry forecast, and competitive landscape.

Click here to get the free sample pdf:

https://www.stratviewresearch.com/Request-Sample/2740/artificial-intelligence-in-retail-market.html#form

How is the Report Helpful?

The report has a very high utility for the key decision-makers and strategists in terms of accurate market insights, future growth opportunities, and key success factors.

Most importantly, the report analyses the possible impact of COVID-19 on the market dynamics which offers cushioning against the uncertain business environment and helps in streamlining the resources and investment decisions in a fruitful manner.

What are the Top Market Drivers?

According to the report, the artificial intelligence In retail market is driven by a host of factors, some of which are noted below:

Significantly increasing internet users & smart devices, favorable government initiatives towards digitization, and growing awareness regarding AI and big data & analytics.

Moreover, the rising adoption of multichannel or omnichannel retailing strategy, growing enterprise’s demands for streamlining business process, untapped opportunities to improve sales efficiency, and increasing need to enhance end-user experience further bolster the industry growth.

The report also includes growth rate estimates based upon the intensity of drivers and constraints and provides the users with several graphical illustrations of the key insights.

Artificial Intelligence (AI) in Retail Market Segmentation:

Stratview Research has segmented the market in the following ways which fulfil the market data needs of multiple stakeholders across the industry value chain.

Story continues

By Deployment (Cloud, On-Premise),

By Application (Supply Chain and Logistics, Product Optimization, In-Store Navigation, Payment and Pricing Analytics, Inventory Management, Customer Relationship Management (CRM)),

By Technology (Machine Learning, Natural Language Processing, Chatbots, Image and Video Analytics, Swarm Intelligence),

By Region (North America, Europe, Asia-Pacific, and Rest of the World).





Artificial Intelligence (AI) in Retail Market Insights

Market Trends by Application Type

The AI in retail market has been classified into supply chain and logistics, product optimization, in-store navigation, payment and pricing analytics, inventory management, and Customer Relationship Management (CRM). Under these, the product optimization segment held a significant market share in 2021.

Market Trends by Technology Type

The AI in retail market has been classified into Machine Learning, Natural Language Processing, Chatbots, Image and Video Analytics, Swarm Intelligence. Under these, Natural language processing segment is expected to grow at a rapid pace whereas, Machine Learning segment is likely to dominate the market during the forecast period.

Which region offers the best opportunity and growth?

The North American market held the highest market share in 2021 and is projected to grow at a fastest CAGR in the coming years. This is ascribed to large presence of major players, early adoption of new and emerging technologies such as Big Data and AI, surging need for intelligent business processes, and increasing adoption of digital technologies, which bolsters the regional market growth during the review period.

COVID-19 Impact on the artificial intelligence in retail market

COVID-19 has put an instant halt to many industries across the globe. Lockdown norms in several countries have swiftly affected the global economy by affecting the supply chain, production, and demand in the market. Both direct, as well as indirect impacts of the pandemic, have been incorporated in this report.

To know more about the covid-19 impact, get a free sample report, here:

https://www.stratviewresearch.com/2740/artificial-intelligence-in-retail-market.html

Who are the Top Market Players?

After a thorough analysis of the market, the experts have listed a few key players and discussed company profiles of the below-given players -

IBM Corporation (US)

Microsoft Corporation (US)

Google LLC (US)

Amazon Web Services Inc. (US)

Oracle Corporation (US)

Salesforce.com Inc. (US)

SAP SE (Germany)

ViSenze Pte Ltd (Singapore)

BloomReach, Inc. (US)

Symphony RetailAI (US).

Market Dynamics

What deliverables will you get in this report?

In-depth analysis of the artificial intelligence in retail market

Detailed market segmentation.

Competitive-landscape analysis.

Historical, present, and future market size analysis.

Industry trends, technologies, and advancements.

Growth and operation strategies adopted by key players.

Potential segments/regions offering promising growth.

Geographical presence of the key players.

Related reports which might be useful:

About us –

Stratview Research is a global market research firm that offers reliable market reports, market entry strategies, strategic growth consulting, and more. The market experts compile high-quality market information to help users obtain granular level clarity on current business trends and expected future developments. Stratview Research also offers customisation of the reports. Reach out to the analysts to customize the given report according to your priority/requirement.

Stratview Research has also launched 'Composights', an online portal that offers free thought leadership reports, whitepapers, market report synopsis, and much more for Composites and allied industries, worth US$ 20,000 every year.

Click here to sign up (No costs involved):

https://www.stratviewresearch.com/composights/sign-in

CONTACT: Stratview Research E-mail: sales@stratviewresearch.com Direct: +1-313-307-4176



",artificial intelligence,yahoo entertainment
59,Artificial Intelligence as a Service Market is Projected to Reach US$ 59.11 Billion in 2028,https://media.zenfs.com/en/globenewswire.com/07ee875c965bd771c3af25d9aae2d2f8,10/11/2022,"Artificial Intelligence as a Service Market is expected to reach US$ 59.11 Billion in 2028, growing at a CAGR of 48.19% during 2022-2028, reports Stratview...",https://finance.yahoo.com/news/artificial-intelligence-market-projected-reach-084700768.html,"Stratview Research

Artificial Intelligence as a Service Market is expected to reach US$ 59.11 Billion in 2028, growing at a CAGR of 48.19% during 2022-2028, reports Stratview Research.

Raipur, Nov. 10, 2022 (GLOBE NEWSWIRE) -- Stratview Research, a leading market research firm has launched a report on the Artificial Intelligence as a Service Market which provides an in-depth analysis of the market dynamics, current and emerging trends, industry forecast, and competitive landscape.

Click here to get the free sample pdf:

https://www.stratviewresearch.com/Request-Sample/2741/artificial-intelligence-as-a-service-market.html#form

How is the Report Helpful?

The report has a very high utility for the key decision-makers and strategists in terms of accurate market insights, future growth opportunities, and key success factors.

Most importantly, the report analyses the possible impact of COVID-19 on the market dynamics which offers cushioning against the uncertain business environment and helps in streamlining the resources and investment decisions in a fruitful manner.

What are the Top Market Drivers?

According to the report, the artificial intelligence as a service market is driven by a host of factors, some of which are noted below:

Increasing implementation of cloud-based solutions and growing requirement for artificial intelligence & cognitive computing market.

Lack of trained staff is likely to hamper the industry growth.

The report also includes growth rate estimates based upon the intensity of drivers and constraints and provides the users with several graphical illustrations of the key insights.





Artificial Intelligence as a Service Market Segmentation:

Stratview Research has segmented the market in the following ways which fulfill the market data needs of multiple stakeholders across the industry value chain.

By Deployment (Public, Private, Hybrid),

By Organization Size (Small and Medium Enterprise, Large Enterprise),

By End Use (BFSI, Retail, Healthcare, IT and Telecom, Manufacturing, Energy, Others),

By Region (North America, Europe, Asia-Pacific, and Rest of the World)

Story continues

Artificial Intelligence as a Service Market Insights

Market Trends by Organization Size Type

The market has been classified into small & medium enterprise and large enterprise. The large enterprise segment secured the highest market share in 2021 and it is anticipated to grow at the highest CAGR during the forecast period.

Market Trends by End-use Type

The artificial intelligence as a service market has been classified into BFSI, retail, healthcare, IT and telecom, manufacturing, energy, others. Under these, the BFSI segment held a significant market share in 2021. In BFSI, AI is primarily used as algorithmic trading, chatbots, fraud detection, and customer recommendation. Banks, such as RBS, are adopting chatbots, expected to compel other financial institutions to invest in similar technologies, which boosts the segment growth.

Which region offers the best opportunity and growth?

The North American market held the highest market share in 2021 and is projected to grow at a fastest CAGR in the coming years. This is ascribed to large presence of major players, technological developments in BFSI and IT sectors, surging need for intelligent business processes, and increasing adoption of digital technologies, which bolsters the regional market growth during the review period.

COVID-19 Impact on the artificial intelligence as a service market

COVID-19 has put an instant halt to many industries across the globe. Lockdown norms in several countries have swiftly affected the global economy by affecting the supply chain, production, and demand in the market. Both direct, as well as indirect impacts of the pandemic, have been incorporated in this report.

To know more about the covid-19 impact, get a free sample report, here:

https://www.stratviewresearch.com/Request-Sample/2741/artificial-intelligence-as-a-service-market.html#form

Who are the Top Market Players?

After a thorough analysis of the market, the experts have listed a few key players and discussed company profiles of the below-given players -

IBM Corporation (US)

Microsoft Corporation (US)

Google LLC (US)

Amazon Web Services Inc. (US)

Oracle Corporation (US)

Salesforce.com Inc. (US)

SAS Institute Inc. (US)

BigML Inc (US)

DATAIKU SAS (US)

H2O.Ai Inc (US).

What deliverables will you get in this report?

In-depth analysis of the artificial intelligence as a service market

Detailed market segmentation.

Competitive-landscape analysis.

Historical, present, and future market size analysis.

Industry trends, technologies, and advancements.

Growth and operation strategies adopted by key players.

Potential segments/regions offering promising growth.

Geographical presence of the key players.

Related reports which might be useful:

About us –

Stratview Research is a global market research firm that offers reliable market reports, market entry strategies, strategic growth consulting, and more. The market experts compile high-quality market information to help users obtain granular level clarity on current business trends and expected future developments. Stratview Research also offers customisation of the reports. Reach out to the analysts to customize the given report according to your priority/requirement.

Stratview Research has also launched 'Composights', an online portal that offers free thought leadership reports, whitepapers, market report synopsis, and much more for Composites and allied industries, worth US$ 20,000 every year.

Click here to sign up (No costs involved):

https://www.stratviewresearch.com/composights/sign-in

CONTACT: Stratview Research E-mail: sales@stratviewresearch.com Direct: +1-313-307-4176



",artificial intelligence,yahoo entertainment
60,Artificial Intelligence (AI) in Medical Diagnostics Market Size to Reach $5.5 billion by 2027 - Exclusive Report by MarketsandMarkets™,https://media.zenfs.com/en/globenewswire.com/d4c3eb630bf83da5a3947696840b275d,08/11/2022,"Chicago, Nov. 08, 2022 (GLOBE NEWSWIRE) -- According to the new market research report ""Artificial Intelligence (AI) in Medical Diagnostics Market by...",https://finance.yahoo.com/news/artificial-intelligence-ai-medical-diagnostics-123000026.html,"MarketsandMarkets Research Pvt. Ltd.

Chicago, Nov. 08, 2022 (GLOBE NEWSWIRE) -- According to the new market research report "" Artificial Intelligence (AI) in Medical Diagnostics Market by Component (Software, Service), Application (In Vivo, Radiology, Neurology, CT, MRI, X - ray, IVD), End User (Hospital, Diagnostic Imaging Center, Diagnostic Laboratory) - Global Forecast to 2027"", the global Artificial Intelligence (AI) in Medical Diagnostics Market is projected to reach USD 5.5 billion by 2027 from USD 1.0 billion in 2022, at a CAGR of 39.9% during the forecast period.

Browse in-depth TOC on ""AI in Medical Diagnostics Market""

128 - Tables

37 - Figures

178 - Pages

Download PDF Brochure: https://www.marketsandmarkets.com/pdfdownloadNew.asp?id=22519734

Scope of the Report:

Report Coverage Details Market Size USD 5.5 billion by 2027 CAGR 39.9% Historical Data 2020-2027 Base Year 2021 Forecast Period 2022-2027 Forecast Units Value (USD Billion) Report Coverage Revenue Forecast, Competitive Landscape, Growth Factors, and Trends Segments Covered By Component, By application, By end user, By region Geographies Covered North America (US, and Canada), Europe (Germany, France, UK, Italy and the RoE), Asia Pacific (Japan, China, India, and RoAPAC), RoW Key Companies Profiled/Vendors Microsoft (US), NVIDIA (US), IBM (US), Intel Corporation (US), Google, Inc.(Subsidiary of Alphabet, Inc) (US), Siemens Healthineers (Germany), GE Healthcare (US), Digital Diagnostics, Inc (US), Xilinx (US), InformAI LLC (US), HeartFlow, Inc (US), Enlitic, Inc (US), Day Zero Diagnostics, Inc(US), Aidence (Netherlands), Butterfly Network, Inc. (US), Prognos Health (US), Nanox AI (Israel), Viz.ai, Inc (US), Quibin (Spain), Qure.ai (India), Therapixel (France), Aidoc (Israel), Koninklijke Philips N.V. (Netherlands), Lunit. Inc (South Korea), EchoNous Inc. (US) Key Market Opportunities Increasing focus on developing human-aware AI systems Key Market Drivers Influx of big data

The application of AI in medical diagnostics is growing at a highest rate owing to factors such as rise in government initiatives to drive the adoption of AI-based technologies, high usage of AI solutions by radiologists to reduce workload, the generation of big data, available funding for AI-based start-ups, and the growing number of cross-industry partnerships & collaborations.

Story continues

However, the lack of trained AI workforce, ambiguity in regulations, and the reluctance among medical practitioners to adopt these solutions are factors expected to restrain the market growth.

On the basis components, AI in medical diagnostics market is segmented into software and services. The services segment dominated the market in 2021, while the software segment is estimated to grow at a higher CAGR during the forecast period. Software solutions provide medical practitioners a chance to gain a competitive edge despite the challenges of being short-staffed and facing increasing imaging scan volumes.

Download PDF Brochure: https://www.marketsandmarkets.com/pdfdownloadNew.asp?id=22519734

Based on application, AI in the medical diagnostics market is segmented into in vivo and in vitro diagnostics. The in vivo diagnostics segment commanded the largest share of this market in 2021. The large share of this segment can be attributed to the increase in use of AI solutions by practitioners, as these solutions help reduce human errors and improve treatment efficacy.



Based on end users, the AI in the medical diagnostics market is segmented into hospitals, diagnostic imaging centers, diagnostic laboratories, and other end users. The hospitals segment commanded the largest share of this market in 2021. The large share of this segment can be attributed to the rising number of diagnostic imaging treatments in hospitals, the inclination of hospitals toward the automation and digitization of radiology treatment workflow, adoption of minimally invasive procedures in hospitals to improve the quality of patient care, and the growth in use of advanced imaging modalities to improve workflow efficiency.

Speak to Analyst: https://www.marketsandmarkets.com/speaktoanalystNew.asp?id=22519734

Geographical Growth Scenario:

The AI in medical diagnostics market has been segmented into four main regional segments: North America, Europe, the Asia Pacific, and the Rest of the World. In 2021, North America accounted for the largest market share of this market. However, the Asia Pacific market is projected to register the highest CAGR of 42.6% during the forecast period. The high growth rate of the Asia Pacific market can primarily be attributed to the growth strategies adopted by key players in emerging markets, better medical diagnostics infrastructure, rising geriatric population, increasing prevalence of cancer, and the implementation of favourable government initiatives to adopt the AI technology.

Key Players:

Prominent players in this market are Microsoft (US), NVIDIA (US), IBM (US), Intel Corporation (US), Google, Inc.(Subsidiary of Alphabet, Inc) (US), Siemens Healthineers (Germany), GE Healthcare (US), Digital Diagnostics, Inc (US), Xilinx (US), InformAI LLC (US), HeartFlow, Inc (US), Enlitic, Inc (US), Day Zero Diagnostics, Inc(US), Aidence (Netherlands), Butterfly Network, Inc. (US), Prognos Health (US), Nanox AI (Israel), Viz.ai, Inc (US), Quibin (Spain), Qure.ai (India), Therapixel (France), Aidoc (Israel), Koninklijke Philips N.V. (Netherlands), Lunit. Inc (South Korea), EchoNous Inc. (US)

Browse Adjacent Markets: Healthcare IT Market Research Reports & Consulting

Browse Related Reports:

Healthcare Cloud Computing Market

AI in Drug Discovery Market

Molecular Diagnostics Market

Healthcare IT Market

Diagnostic Imaging Market

CONTACT: About MarketsandMarkets™ MarketsandMarkets™ provides quantified B2B research on 30,000 high growth niche opportunities/threats which will impact 70% to 80% of worldwide companies’ revenues. Currently servicing 7500 customers worldwide including 80% of global Fortune 1000 companies as clients. Almost 75,000 top officers across eight industries worldwide approach MarketsandMarkets™ for their painpoints around revenues decisions. Our 850 fulltime analyst and SMEs at MarketsandMarkets™ are tracking global high growth markets following the ""Growth Engagement Model – GEM"". The GEM aims at proactive collaboration with the clients to identify new opportunities, identify most important customers, write ""Attack, avoid and defend"" strategies, identify sources of incremental revenues for both the company and its competitors. MarketsandMarkets™ now coming up with 1,500 MicroQuadrants (Positioning top players across leaders, emerging companies, innovators, strategic players) annually in high growth emerging segments. MarketsandMarkets™ is determined to benefit more than 10,000 companies this year for their revenue planning and help them take their innovations/disruptions early to the market by providing them research ahead of the curve. MarketsandMarkets’s flagship competitive intelligence and market research platform, ""Knowledge Store"" connects over 200,000 markets and entire value chains for deeper understanding of the unmet insights along with market sizing and forecasts of niche markets. Contact: Mr. Aashish Mehra MarketsandMarkets™ INC. 630 Dundee Road Suite 430 Northbrook, IL 60062 USA: +1-888-600-6441 Email: sales@marketsandmarkets.com



",artificial intelligence,yahoo entertainment
61,Crowdworks Registers U.S. Patent for 'method for selecting worker according to feature of project based on crowd sourcing',https://media.zenfs.com/en/prnewswire.com/b1150981fe442363397dade52eff0525,08/11/2022,"Crowdworks (CEO Park Min-woo), an Artificial Intelligence (AI) training data platform company, announced on the 28th of October that it has completed the...",https://finance.yahoo.com/news/crowdworks-registers-u-patent-method-070000815.html,"SEOUL, South Korea, Nov. 8, 2022 /PRNewswire/ -- Crowdworks (CEO Park Min-woo), an Artificial Intelligence (AI) training data platform company, announced on the 28th of October that it has completed the registration of a US patent for 'method for selecting worker according to feature of project based on crowd sourcing'.

When operating a crowdsourcing-based AI data project, this technology checks the functional elements included in the project to be opened and selects workers (data labelers) who are proficient in the task in consideration of the worker's work performance for the functional element. For each data labeling project, it automatically creates and provides real-time worker pools of optimal workers.

In case of using patented technology, it is possible to reduce time and cost by selecting optimal workers according to the characteristics of the project. Furthermore, it allows to maximize their data project efficiency.

Crowdworks is the largest patent holder in the AI data labeling technology field in Korea, applying for over 180 Korean and international technology patents essential to the advancement of AI data labeling technology and securing market competitiveness.

Crowdworks' Machine Learning (ML) and AI-based technologies, which are protected by more than 180 patents, improve the productivity and efficiency of AI training data construction tasks, and manage the quality of the result data. The AI training data constructed in this way has been provided to customers and society to help the development of various AI fields.

Crowdworks' has been steadily securing US patents since its first US patent registration in March of this year. Crowdworks is continuously developing the North American and Europe markets by securing global patents and participating in Epicenter Accelerate – K-Startup Program in Sweden. The company is also planning its CES 2023 exhibit.

Park Min-woo, CEO of Crowdworks, said, ""As data-centric AI is now a global topic, securing technological competitiveness for high-quality data is essential."" And he continued ""We are aiming to lead the global AI training data market by actively securing intellectual property rights.""

Story continues

About Crowdworks

Crowdworks is one of the leading AI training data annotation solution provider in Korea since 2017. Crowdworks' AI training data annotation platform 'Workstage' delivers qualified AI training data collection and annotation to accelerate AI development for corporations from a wide range of industries including automotive, healthcare, and manufacturing.

www.crowdworks.kr / www.workstage.com Follow us on LinkedIn.

Cision

View original content to download multimedia:https://www.prnewswire.com/news-releases/crowdworks-registers-us-patent-for-method-for-selecting-worker-according-to-feature-of-project-based-on-crowd-sourcing-301669569.html

SOURCE Crowdworks Inc",artificial intelligence,yahoo entertainment
62,New method enables global internal solitary wave propagation forecast in global oceans,https://scx2.b-cdn.net/gfx/news/2022/novel-method-enables-g.jpg,08/11/2022,"Internal solitary waves (ISWs) are widely distributed in global oceans, and their propagation is affected by complicated environmental factors.",https://phys.org/news/2022-11-method-enables-global-internal-solitary.html,"ISW forecast in different ocean areas. Credit: IOCAS

Internal solitary waves (ISWs) are widely distributed in global oceans, and their propagation is affected by complicated environmental factors.

Satellite remote sensing images are the main data source for ISW study due to their large coverage and frequent revisiting time. However, the number of satellite images containing ISW signatures is still far from being able to cover the globe.

Recently, a research team led by Prof. Li Xiaofeng from the Institute of Oceanology of the Chinese Academy of Sciences (IOCAS) has proposed a novel method that couples physical mechanisms and artificial intelligence algorithms for ISW propagation forecast in global oceans.

Their study was published in Remote Sensing of Environment on Oct. 27.

The researchers collected a global dataset covering 13 ISW hotspots. Analysis of the built dataset revealed the relationship between ISW propagation speed and tidal information on a global scale for the first time. ISW propagation speed variations showed good correlation with the spring and neap tides.

They adopted the clustering algorithm to solve the ISW sample geographical imbalance problem, and incorporated the ISW physical mechanism into the model-building process.

""The proposed ISW speed model can be applied to study long-term ISW speed characteristics and it showed superior performance at different water depth ranges,"" said Dr. Zhang Xudong, first author of the study.

The continuous density stratification in the ocean was considered in the model in contrast to the traditional two-layer ocean stratification assumption. ""It can also reveal ISW propagation characteristics and how the changing ocean stratification will influence the ISW propagation,"" said Prof. Li.

More information: Xudong Zhang et al, Satellite data-driven and knowledge-informed machine learning model for estimating global internal solitary wave speed, Remote Sensing of Environment (2022). DOI: 10.1016/j.rse.2022.113328",artificial intelligence,phys.org
63,Axiomtek launches the newest medical grade artificial intelligence computing system - mBOX100,https://media.zenfs.com/en/prnewswire.com/50043205c25306b0af8c3b2ec72beefe,09/11/2022,"Axiomtek – a world-renowned leader relentlessly devoted to the research, development, and manufacturing of innovative and reliable industrial computer...",https://finance.yahoo.com/news/axiomtek-launches-newest-medical-grade-092100779.html,"TAIPEI, Nov. 9, 2022 /PRNewswire/ -- Axiomtek – a world-renowned leader relentlessly devoted to the research, development, and manufacturing of innovative and reliable industrial computer products of high efficiency – is pleased to announce the release of the mBOX100, a medical-grade edge AI computing system with dual 4K displays. This slim-type medical system complies with the IEC-60601 medical safety standard for use in a variety of hospital applications and healthcare environments.

Axiomtek's mBOX100 is powered by the Intel® Core™ i7/i5 processor (code name: Whiskey Lake-U) and equipped with two DDR4-2400 non-ECC SO-DIMM slots with a total capacity of up to 64GB. Aligning with excellent performance, the mBOX100 offers Intel® UHD Graphics 620 and 15W TDPs for high-end image processing and provides HDMI and DisplayPort for applications requiring the displays of medical images. This medical AI computing system delivers greater storage with lower latency by a swappable 2.5"" SATA III tray with a security lock for SSD and an M.2 Key M 2280 slot for NVMe. In terms of sufficient I/O, it has two isolated RS-232/422/485, two isolated 10/100/1000 Mbps Ethernet, four USB 3.1, one HDMI 1.4, DisplayPort 1.2, two audio jacks, and two SMA-type antenna connectors, expansion interface with one full-size PCIe Mini Card slot (USB+PCIe signal) for wireless module to ensure outstanding using experience.

Worth mentioning, Axiomtek's mBOX100 has a rugged design with fanless operation for noise-sensitive environments, and antimicrobial coating (optional) as well as white, streamlined design for ideal hospital applications. Even in a small form factor, 250 x 220 x 60mm, the mBOX100 has an excellent thermal design enabling a wide operating temperature from 0°C to 40°C. The system offers 10% to 90% non-condensing humidity tolerance and 3G vibration endurance to secure reliable performance across system. Furthermore, it supports Trusted Platform Module 2.0 (TPM) to provide hardware-based data protection, along with OS support for Windows® 10 IoT and Linux operating systems.

""The mBOX100 truly empowers fast and precise smart computer-aided diagnosis (CADx) by superior AI computing performance, dual 4K display connection, and trust build-quality that can apply smart healthcare applications properly,"" said Jenny Yu, the product manager of the intelligent medical solution team at Axiomtek. ""What is more, we have the capability to assist with any customer's industrial integration requirements and fulfill fast time to market.""

The mBOX100 is available for purchase now. For further product information or customization services, please visit our global website at www.axiomtek.com or contact sales representatives at info@axiomtek.com.tw.

Advanced Features of mBOX100:

8th generation Intel® Core™ i7/i5 processor (Whiskey Lake-U), TDP 15W

2 DDR4-2400 SO-DIMM for up to 64GB memory

1 HDMI and 1 DisplayPort with 4K UHD supported

2 isolated COM and 2 GbE LAN with isolation supported

Swappable 2.5"" SATAIII SSD tray with security lock

Ultra-compact design and fanless

Antimicrobial coating chassis (optional)

About Axiomtek Co., Ltd

Axiomtek has experienced extraordinary growth in the past 30 years because of our people, our years of learning which resulted in our tremendous industry experience, and our desire to deliver well-rounded, easy-to-integrate solutions to our customers. These factors have influenced us to invest in a growing team of engineers including software, hardware, firmware, and application engineers. For the next few decades, our success will be determined by our ability to lead with unique technologies for AIoT and serve our key markets with innovatively-designed solution packages of hardware and software – coupled with unmatched engineering and value-added services that will help lessen the challenges faced by our systems integrator, OEM and ODM customers and prospects alike. We will continue to enlist more technology partners and increase collaborations with our growing ecosystem who are leaders in their fields. With such alliances, we will create synergy and better deliver solutions, value, and the expertise our customers need.

As an associate member of the Intel® Internet of Things Solutions Alliance, Axiomtek continuously develops and delivers cutting edge solutions based on the latest Intel® platforms.

Cision

View original content to download multimedia:https://www.prnewswire.com/news-releases/axiomtek-launches-the-newest-medical-grade-artificial-intelligence-computing-system--mbox100-301672724.html

SOURCE Axiomtek",artificial intelligence,yahoo entertainment
64,Ten student design projects from Centro de Diseño y Comunicación,https://static.dezeen.com/uploads/2022/11/Centro-de-Diseño-y-Comunicación_dezeen_2364_ss_0-1024x1024.jpg,07/11/2022,"Dezeen School Shows: an installation that ""acts and thinks"" and an ornate fashion collection made from featherwork, foiling and embroidery are included in Dezeen's latest school show by students at Centro de Diseño y Comunicación. Also included is a series of…",https://www.dezeen.com/2022/11/07/ten-student-design-projects-from-centro-de-diseno-y-comunicacion/,"Dezeen School Shows: an installation that ""acts and thinks"" and an ornate fashion collection made from featherwork, foiling and embroidery are included in Dezeen's latest school show by students at Centro de Diseño y Comunicación.

Also included is a series of ceramics that take cues from the female form and a smart training suit designed to enhance physical performance.

Centro de Diseño y Comunicación

Institution: Centro de Diseño y Comunicación

School: Centro de diseño, cine y televisión

Courses: BA Architecture, BA Film and Television, BA Industrial Design, BA Interior Architecture, BA Marketing and Strategic Design, BA Creative Computing, BA Textile and Fashion Design and BA Visual Communication

Tutors: Miquel Adrià, Roberto Cabezas, Guillermo Huerta, Uzyel Karp, Cecilia León de la Barra, Beata Nowicka, Cristina Piña and Miguel Torres

School statement:

""Centro is an urban model for higher education in design, architecture, digital media and film in Mexico City.

""Since its founding in 2004, it has become Mexico's main institution for higher learning in the field of creativity, providing its 2,500 students with the unique opportunity to transform their passion and talent into successful, cutting-edge professional careers.

""Centro focuses on the critical role of creativity in analysing and resolving problems of varied complexity in diverse contexts, using a human-centred and system-oriented approach.

""Centro creates creative experts with a socially conscious, sustainable and entrepreneurial perspectives through a specialised and personalised educational model.

""It offers undergraduate and graduate degree programs to future generations of creative leaders in Mexico and beyond.

""We are focused on creativity because we believe it is the key element to thrive in today's complex world and its intricate dynamic systems.""

Capas: A thesis on the rehabilitation of forgotten architecture by Regina Lauxterman Munguía

""Capas is a mixed-use scheme that explores the ways in which pre-existing fragments of architecture can coexist with contemporary design interventions.

""The project focuses on the joins between old and new, and giving continuity to existing buildings by integrating new materials and architectural elements that will make the space habitable again without damaging or modifying the layers of its history.

""The space resignifies and reactivates life inside a forgotten structure.""

Student: Regina Lauxterman Munguía

Email: rlauxterman[at]centro.edu.mx

Course: BA Interior Architecture

Tutors: Alexander Cziharz, Aldo Juarez Meave and Eduardo Duarte Muñoz

Machina Vitae by Constantino Brito Grek

""Machina Vitae is an installation that acts and thinks – it imitates biological mechanisms through gears and pulleys and can feel, react and communicate through sensors and circuits.

""Each synthetic organism has all the necessary components to operate independently – it can move and perceive the environment on its own.

""However, its true potential unfolds when this module is iterated as these organisms are capable of communicating with each other through touch, light and colour.

""With a few of these pieces interacting, a collective intelligence is formed, they are no longer individual modules, they are a coordinated superorganism.

""The superorganism is composed of machines that are not inanimate objects nor are they alive – they are a thinking collective composed of agents that in an individual scale perform simple actions, but these iterated actions form a complex system.""

Student: Constantino Brito Grek

Email: cbrito[at]centro.edu.mx

Course: BA Creative Computing

Tutors: Ana Rosa Gómez Mutio, Fernanda del Monte, Diego Trujillo Pisanty, Beto Olsi, Rolando González and Roberto Cabezas

Shortfilm: Las plantas también mueren by Andrea León

""Inside a room full of plants, a woman finds shelter from the outside world. Submerged in delirium, Alba experiences her withering.

""This short film uses the stop-motion technique in which the illusion of bringing an inanimate object to life is created through a series of photographs.

""The uniqueness of the frame-by-frame animated output; the imperfections that reveal the presence of the human hand is its greatest charm. This technique references childhood games.

""Las plantas también mueren is a tribute to Mother Nature and the cyclical and essential processes of life – the inevitable transformation over time, growth, death and rebirth.""

Student: Andrea León

Email: aleong[at]centro.edu.mx

Course: BA Film and Television

Tutors: Ángeles Sánchez, Jorge Gardoni, Cristina Piña and Ricardo Cortés

V02-MAX a smart training suit by David Schoenfeld

""VO2-MAX is a smart training suit that allows to control physiological responses with the aim of improving performance and endurance, alerting and evaluating the strengths and weaknesses of the athlete.

""Constant monitoring, such as performance control tests that diagnose the precise information of training in terms of techniques and physical qualities using wearable technology, allow the athlete's status to be controlled.

""This monitoring prevents alterations in the wearer's stimuli, such as injuries, overheating, poor hydration, recovery control and other adverse effects related to the exchange of ambient temperature with the thermoregulatory system.

""E-Textile makes it work – VO2-MAX is a completely wearable suit that can be washed without damaging the capacities and alterations of all electronic components.

Student: David Schoenfeld

Email: dschoenfeld[at]centro.edu.mx

Course: BA Industrial Design

Tutors: Diego Trujillo Pisanty, Andrea Izquierdo Ruiz and Eduardo Duarte Munoz

Ifuckinglovetheinternet by Jero Rosas

""Ifuckinglovetheinternet explores the question of what fame means in the digital age.

""Using digital tools such as programming and collaboration with artificial intelligence, the collection poses a new idea of what streetwear means for internet users.

""Pulling from references such as sports cars, status symbols and the absurdity of flex-culture, the collection reinterprets luxury and exclusivity through irony.

""The concept of memes, ego and social networks become pillars to generate a collection driven by details that revolve around the user, taking their experience to a new level.

""The virtual realm has been responsible for transforming the concept of fame into something that seems accessible for everyone at the reach of a click.""

Student: Jero Rosas

Email: jrosas[at]centro.edu.mx

Course: BA Textile and Fashion Design

Tutors: Judith Almazán, María Ponce, Andrea Bores, Fernando Madrid, Luciana Renner and Guillermo Huerta

Emerge by Daniela Levy Esses

""Emerge is a project of research and practice that asks questions about how computational systems contribute to the artistic process of simulation, to explore form and movement within digital space.

""The experimental animation has aesthetic aims and derives from the appropriation of a computational system known as Boids.

""Experiments emerge through the parameterization of variables declaring the possibility of form and movement in digital space, and parting from a logic perceived in the natural world, which is then translated into computational science.""

Student: Daniela Levy Esses

Email: dalevye[at]centro.edu.mx

Course: BA Creative Computing

Tutors: Ana Rosa Gómez Mutio, Fernanda del Monte, Diego Trujillo Pisanty, Rolando González, Aaron Martínez and Roberto Cabezas

Architecture/Atmosphere + Videogames (AV) by Regina Rios Gurría

""My work aims to explore the limits of interior architecture from the perspective of a video game.

""This research seeks to analyse the interior architectural atmospheres of the video game Monument Valley created by UsTwo Games.

""The aim is to understand the set of elements that make up a moving and exciting atmosphere by identifying key visual constants: colour, shape, movement, lighting, landscape, background and thematic setting etc.

""The notion of space is analysed through the lenses of virtual reality, interior design, illustration and games.

""As a result of the joint application of these four perspectives, a more comprehensive understanding of the nature of interior design emerged – one increasingly less tethered to the physical world and more firmly planted in the new possibilities of the digital realm.""

Student: Regina Rios Gurría

Course: BA Interior Architecture

Tutor: Alexander Cziharz

The Primadonna Manifesto by Guillermo de Jesús

""The Primadonna Manifesto is a collection that is inspired by a new subculture of people that I call 'Primadonnas'. They seem to live in a performance in which they imitate a classic, eccentric and glamorous archetype of a woman, commonly referred to in Mexican culture as a 'lady'.

""The Mexican telenovela and cinema divas, interior decoration and the Marianist aesthetic were keys to discover the characteristics that the Primadonnas and are reflected in their personality.

""The obsession for ornate, ostentatious and antique features are some of the points that I used to create the manifesto, which guided me to build the aesthetic universe of the Primadonna.

""Artisanal techniques such as featherwork and textile methods such as embroidery, foiling and dyeing were used throughout the garment creation process.""

Student: Guillermo de Jesús

Email: gsolis[at]centro.edu.mx

Course: BA Textile and Fashion Design

Tutors: Judith Almazán, María Ponce, Andrea Bores, Fernando Madrid, Luciana Renner and Guillermo Huerta

Habitemos: Conversación, amor y juego como herramientas de transformación social by Daniela Zorrilla Valdés

""Habitemos is a board game in which there are no winners or losers – participants have a common goal that can only be achieved through collaboration.

""Through the different cards and dynamics, it seeks to generate spaces that encourage ideological diversity.

""The design of the game comes from the analysis of the dynamics of conversations that are violent normalised.

""For example, those in which the goal is to be right and change the opinion of others, or the dynamics of power and hierarchies, interruptions and poor listening skills, to name a few.

""These conversations, besieged by the values of patriarchal capitalism, generate a cycle of communication that does not allow us to discuss alternative ways of life therefore hindering our development as a society.

""The ultimate goal of Habitemos is to gradually transform the way we converse in order to make change in this harmful cycle of communication, and transform it into a cycle that embraces differences and confronts conflict without getting into intolerant dynamics.

""Let's learn to converse from love and have fun while we do it.""

Student: Daniela Zorrilla Valdés

Email: dzorrillav[at]centro.edu.mx

Course: BA Visual Communication

Tutors: Regina Olivares Alberti, Carlos Nicolés Pradilla Molina and Cristina Cruz Hernández

Cuerpa by Adelaida Cortés

""Have you ever asked yourself about which parts of your thoughts, behaviours and emotions come from the collective intellectual unconscious to which we are exposed every day?

""Do you like your body when you look in the mirror? Spanish is a language that has grammatical gender – it means that inanimate objects have a pronoun or article.

""We are used to assuming that every noun that ends in the letter 'O' is a male gender, even when talking about nouns that can be neutral or both.

""When we mention 'Cuerpo' it means the human body, and we think about a masculine subject. I made 'Cuerpa' to materialise and give power and identity to the stories of the Mexican women's bodies.""

Student: Adelaida Cortés

Email: adelaidacortesb[at]gmail.com

Course: BA Industrial Design

Tutor: Eduardo Duarte

Partnership content

This school show is a partnership between Dezeen and Centro de Diseño y Comunicación. Find out more about Dezeen partnership content here.",artificial intelligence,dezeen
65,Tech bubble? Our Progress Towards Value to Users Has Slowed… - Walter Bradley Center for Natural and Artificial Intelligence,https://mindmatters.ai/wp-content/uploads/sites/2/2022/11/hipster-breakfast-at-home-stockpack-adobe-stock-scaled.jpg,07/11/2022,What makes me pessimistic just now is that few participants in today’s tech bubble are even having this conversation about actual gains vs. hype.,https://mindmatters.ai/2022/11/tech-bubble-our-progress-towards-value-to-users-has-slowed/,"Today’s new technologies, from virtual reality to nuclear fusion have recently received record investments from venture capitalists, but their revenues are not growing as fast as technologies of past decades. Startup losses are unprecedented — far larger than in past decades. Share prices and private valuations have also been collapsing in 2022.

Optimists mostly focus on the good news and ignore these facts. They believe that the heavy funding for these new technologies is a good measure of potential and thus any criticism is unjustified. Here is their typical argument:

Paul Krugman and other “experts” criticized the Internet, personal computers, and other technologies in their early years. But these technologies succeeded. Therefore, criticisms of the new technologies are unfounded — or so goes the argument for optimists.

My response is simple: just because some people were wrong about some new technologies in the past, doesn’t mean that every new technology will succeed. In fact, many, if not all, might fail.

What determines whether a technology succeeds or fails?

Any optimistic argument about a new technology should first detail the benefits for a specific set of early users, the more specific, the better. Unfortunately, proponents of today’s new technologies often focus on the benefits to suppliers and not to customers, because most people think in terms of value capture and not value creation. But value creation is the more important of the two because suppliers must create more value than they capture, with one part of this created value offered to the customer in the form of a value proposition. Some examples will, I hope, demonstrate my points:

Within a few years of the first offer of desktop computers in 1975, their software enabled users to edit documents and do calculations in spreadsheets. The value of these applications was easily appreciated because most people understood the limitations of typewriters and pocket calculators — the latter were themselves a recent replacement for adding machines.

The first users of Amazon quickly recognized the benefits of buying books (and music) on the Internet because they had wasted much time searching through bookstores. By ordering from Amazon, readers could avoid driving to different bookstores just to be told that the book wasn’t available. Books were the perfect killer app because of their huge variety.

Today’s technologies should offer equally large benefits. If they can’t be described, then the new technology probably won’t have many sales over the next few years, and we should be suspicious of optimistic forecasts.

A second issue is whether there is progress towards providing or extending the type of benefits described above. I have written extensively in academic journals on topics such as rapidly improving new technologies prior to commercialization, either by themselves or in new combinations such as the smart phone.

For instance, personal computers benefitted from Moore’s Law, because dramatic increases in processing power enabled computers to process more complex and feature-filled software for word processing and spreadsheets. These rapid improvements also contributed to a booming market for enterprise software that helped manage factories, procurement, engineering, and sales by the early 1990s, a result that purportedly enabled the largest productivity increases of the last 50 years in the early 1990s.

Improvements in Internet speeds also made this software better. They also enabled more products to be sold online as sellers used these improvements to include an increasing number of pictures, videos, and Java files on their websites. For instance, fashion and cosmetic suppliers were initially resistant to offering their products online because the poor aesthetics of webpages, mostly text or slow loading pictures, degraded their product.

It’s different today. Several of today’s new technologies are experiencing slow improvements in performance and cost. Thus their revenue growth is slow and their suppliers experience big losses. Here are some examples:

What’s holding virtual and augmented reality back? A physics law

The two biggest problems of VR today are the large physical sizes of files and, for some users, the nausea that comes from using them. Progress in solving these two problems is slow. Sizes are not getting smaller and one outcome is that the Department of Defense cancelled Microsoft’s contract of AR for soldiers because of nausea. Worse, many neuroscientists believe that AR-induced nausea cannot be eliminated.

Reducing size is hard due to a physics theory known as the law of etendue: There is a tradeoff between size and field of view: We can either have small size or large field of view (FoV), but not both. Google Glass has a horizontal FoV of only 12.5°. The FoV is 43° for the larger Hololens goggles from Microsoft. But without progress towards smaller sizes, VR and AR will likely never experience rapid growth.

What’s the future for delivery drones?

Little progress has been made in handing a package to a tenth story resident through a window, a common challenge in high density areas where the economics of home delivery are the most promising. In less denser areas, there are often above-ground power and telephone lines that can cause accidents. Progress in making drones that can maneuver these lines is also slow. Perhaps it is faster than the progress towards making handoffs through a tenth-story window, but slow nonetheless.

This is the delivery drone’s environment.

And self-driving vehicles?

Safety is understandably important. It took decades of improvements in vehicles and roads for the safety of human-driven vehicles to reach the low levels of mishap that we experience today. For self-driving vehicles to accomplish the same level of safety, they face the ”devilish problem of edge cases,” the thousands of situations that humans learn to handle through years of “becoming an adult.” Progress in teaching machines all these edge cases is “devilishly” slow.

An even bigger problem is the negative impact that ride hailing vehicles, and thus robo-taxis, have on congestion. Ride hailing suppliers such as Uber and Lyft have made no progress along this metric, because drivers spend a significant amount of their time searching for customers. Robo-taxis face the same problem and no amount of training an AI system will solve it.

What about satellite internet?

These services provide value to a slowly growing number of subscribers, but the question is whether their progress is sufficient to enable them (now 500,000) to obtain the current number of global subscribers for cellular phone services (8.6 billion), or even the 12 million that cellular had obtained by 1990.

Large numbers of satellites are needed to provide reliable service because the low-altitude satellites move quickly across the sky and are often hidden behind buildings, trees, and mountains. The number of satellites is growing and hopefully will continue to grow despite NASA’s reservations about potential collisions. The problem is that speeds are slowing due to congestion from the growth in subscribers, even though the number of subscribers is still very small. Speeds should be rising not falling. Even America’s Federal Communications Commission rejected Starlink’s proposal to provide rural services because, in the FCC’s view, the speeds are too slow. If Starlink cannot handle today’s 500,000 subscribers, how can it handle millions of subscribers much less billions to have a big impact?

And artificial intelligence?

AI is the most successful of today’s new technologies because value is being created. But most of this value has come through augmentation of — rather than replacement of — workers. Will this change? It all has to do with progress.

The cost of training an AI system for a specific accuracy is dropping, mostly from using better computers. But when trying to increase the accuracy from say 90% to 99% or to 99.9% there are exponential increases in computing resources, costs, and green-house gas emissions. For instance, GPT-3, the world’s largest language model, still requires human inputs, even with 175 billion parameters and trained on 45 Terabytes of text data.

Summary

Tech bubbles are worse when engineers and entrepreneurs don’t understand what value is, what it means to create value, and whether progress is being made towards offering that value to customers.

When I taught my course on the economics of new technology at the National University of Singapore from the late 2000s through the mid-2010s, I talked about these issues for many technologies including nuclear fusion, superconductors, displays, bio-electronics, neuromorphic computing, and other new technologies. I always saw my course as the start of a conversation about a new technology, not the end. But unfortunately, for many participants in today’s bubble, few have even started having this conversation. And that makes me very pessimistic.",artificial intelligence,mindmatters.ai
66,"Online abuse and death threats awful, says MP Anna McMorrin",https://media.zenfs.com/en/bbc_us_articles_995/6cf44796ae08739e988d7357b22d89dc,09/11/2022,"""I have to be very security conscious now and that is a worry,"" says Cardiff North MP Anna McMorrin.",https://finance.yahoo.com/news/online-abuse-death-threats-awful-111331782.html,"Anna McMorrin: ""The most serious ones, particularly if they're death threats, I do report them to the police""

""I have to be very security conscious now and that is a worry,"" says Cardiff North Labour MP Anna McMorrin.

More than 3,000 offensive tweets are sent to UK Members of Parliament every day, a BBC investigation into the extent of online abuse has found.

Ms McMorrin told BBC Radio Wales Breakfast that comments could be ""really aggressive, veering on sexually abusive, sometimes death threats"".

Twitter was unavailable for comment.

Analysis of three million tweets aimed at politicians over a six-week period found more than 130,000, about one in 20, could be classed as toxic.

""It's pretty awful... the most serious ones, particularly if they're death threats, I do report them to the police,"" said Ms McMorrin.

""I'm in touch with the police and they're in touch with me about my movements.""

Ynys Môn Conservative MP Virginia Crosbie received a death threat last year

Ynys Môn Conservative MP Virginia Crosbie spoke about a death threat she received to her constituency office in Holyhead, Anglesey, last year.

Former Plaid Cymru leader Leanne Wood also highlighted ""vile"" online abuse she received on social media in 2016.

And, last year, Kirsty Williams, the ex-Liberal Democrat politician and Welsh education minister, said it abuse was getting ""worse and worse"".

The BBC investigation found female MPs were more likely to be called ""thick"" and ""ignorant"" and be subject to sexualised language while their male counterparts were more likely to be called ""liars"".

Former Welsh politicians Leanne Wood and Kirsty Williams have previously spoken about online abuse

""It shouldn't be that a woman in politics should have to deal with this,"" said Ms McMorrin.

""You only need one lone wolf to do something crazy.

""I've got to think about my family because this job does impact that, but you can't let that consume you.""

The BBC's Shared Data Unit used Perspective, a tool that uses artificial intelligence to spot toxic comments online.

Developed by Jigsaw, a research unit within Google, it defines a toxic comment as one which is ""rude, disrespectful or unreasonable"" and ""likely to make someone leave a conversation"".

Story continues

The team analysed all tweets mentioning MPs from March to mid-April.

The BBC had contacted Twitter for a response, but the firm was unable to reply.

Twitter has previously said it is committed to combatting abuse as outlined in its Hateful Conduct Policy.",artificial intelligence,yahoo entertainment
67,Photo Editing App That Removes Backgrounds Tops 40M Downloads,https://petapixel.com/assets/uploads/2022/11/photoroom2.jpg,08/11/2022,"A photo editing app that automatically removes the background from pictures with just one click has soared to over 40 million downloads.
[Read More]",https://petapixel.com/2022/11/08/photo-editing-app-that-removes-backgrounds-tops-40m-downloads/,,artificial intelligence,petapixel
68,Introducing the Features of Web 3.0 Sites,,07/11/2022,"By Jessica Day


Web 3.0 offers many new developments and exciting possibilities. This next big step in Web design incorporates some truly revolutionary technologies. Just as Web 2.0 represented a quantum leap forward from Web 1.0, the changes that Web 3.0 is…",https://www.uxmatters.com/mt/archives/2022/11/introducing-the-features-of-web-30-sites.php,"2. Artificial Intelligence–Driven Design

AI will make Web sites easier to use and more engaging to the user.

As artificial intelligence has more and more impact on Web-site design, Artificial Design Intelligence (ADI) will have significant impact on the user experience. AI will make Web sites easier to use and more engaging to the user. As we’ll see next, this trend will exploit people’s preference for pictures over pure text in the form of great 3D graphic design.

3. 3D Graphics in Web Design

Advances in graphics technology have delivered enormous strides forward in terms of what’s possible pictorially. This design style will continue to develop in Web 3.0, especially in the realm of 3D graphic design. This will inform everything from image choices to the color schemes of Web sites.

Users of Web 3.0 are going to have to get their heads around some new concepts such as the aforementioned blockchain technology. Plus, it’s usually the case that pictures do the explaining better than words do. Consider the illustration in Figure 2, which shows very quickly and directly how much people tend to prefer Web sites with images. The potential that 3D graphic design offers will cater to this preference.

Figure 2 —Engaging users through images



Image source: business2community.com

However, where sites must use text, they should put an emphasis on language that immediately resonates well with their brand. Just as with a business vanity number, in which a telephone number incorporates something that is key to the brand, this use of language works by being both eye-catching and memorable.

Of course, as Web 3.0 takes root, it won’t be so imperative to teach people about new ideas such as the importance of adopting blockchain. Most people will already have learned about them.

4. Content Accessibility on Any Device

For sites to be as open to access by a smartwatch as by a desktop PC, we much optimize their user interfaces and site performance to perfection.

The ubiquity of access that the IoT delivers has some consequences for Web site–design choices. Many of the devices that people use to connect to the net will have relatively little processing power. This is likely to be the case for some time to come, so for sites to be as open to access by a smartwatch as by a desktop PC, we much optimize their user interfaces and site performance to perfection.

5. User-Driven Blockchain Design

Blockchain seems to be everywhere right now. Without getting too technical, blockchain provides a way of decentralizing the Web by providing community-driven means of authenticating processes. The idea is to take power from the megacorps and distribute it among the users. Any design work on Web sites or applications—or decentralized applications, or dApps, on blockchain—should build on these principles.

6. Intensive Semantic Web Experiences from AI Chatbots

The overwhelming majority of searches will be via voice rather than keyboard. Why is this happening? Because of the rise of AI and the Internet of Things. Plus, as Figure 3 shows, the growth of personal assistants in our everyday lives has been phenomenal.

Figure 3 —Adoption of voice assistants



Image source: t4.ai

What Siri, Alexa, and other voice assistants have in common is a sophisticated verbal interface that learns as it goes. This trend will accelerate with Web 3.0.

We’ll need to design Web sites with voice searches in mind. One characteristic of voice searching is that people tend to use proper sentences, as though they’re talking to another person.

What this means for Web 3.0 is that we’ll need to design Web sites with voice searches in mind. One characteristic of voice searching is that people tend to use proper sentences, as though they’re talking to another person. Sites that people can find using conversational queries will benefit. There will be an increase in the use of self-service AI, too, with assistive chatbots becoming both more common and more sophisticated.

Web 3.0 will be much more about the context of a search and the user’s intention. Until now, people have found sites based purely on keyword density. This will change by using AI insights. Searches can build on users’ past behaviors and previous searches to form a complex picture of the user. Structured data will bring about this capability by labeling the vital parts of content on Web sites for easier identification.

7. Futuristic Experience Through AR and VR Augmentation

Artificial reality (AR) and virtual reality (VR) are hugely exciting. The ways in which companies will be able to repurpose content and make it completely compelling will be phenomenal. The commercial and creative possibilities of AR and VR are off the scale. Being able to see a product within the context of your life—whether your home, your car, your office, your garden, or your wherever—before you buy it will be a game changer for many. This is what AR/VR can deliver. Figure 4 shows a VR headset.

Figure 4 —VR technology



Image source: Unsplash

Internet users will benefit from having a better foundation for making decisions about whether to buy certain products. Will that sofa fit my lounge decor? Let’s have a look. And businesses will benefit from being able to demonstrate what products can bring to a given environment. Using such techniques can only result in scaling up your business.

8. Data Decentralization

As I mentioned earlier, the use of blockchain will disperse the power that currently resides with small numbers of huge corporate entities among large numbers of smaller entities and individuals. This power will primarily take the shape of data, which, as it becomes more widely available to people, will be a great leveler in terms of ownership of the Web.

Top 3 Web 3.0 Design Builders

What are the top three applications for building Web 3.0 applications?

1. Sketch

A bit like a Web designer’s Photoshop, Sketch is available only for use on Mac OS. This robust and hugely popular application has all the tools a designer could need, whether for Web site or mobile app design, vector graphics work. or prototyping.

2. Lunacy

This free, Windows-driven package has gained a firm foothold in the design world, not least because it can handle Sketch files. It’s a community-driven platform, so users vote on features and design directions.

3. Figma

This is another popular package that is free to use, powerful, and built for browser use, but there is a desktop app, too.

Designing Web 3.0 Sites Now

The world is not slowing down, nor is Web development. Web 3.0 is already here, so Web-site design needs to factor in its arrival. If you’re not yet designing Web sites with Web 3.0 in mind, you’ve already fallen behind. But you’ll have plenty of opportunities to catch up if you start now.

Conclusion

Several key factors are driving Web 3.0 design, chiefly comprehensibility, means of access, community-based efforts, and search sophistication. If you’ve got a great idea along these lines and are just itching to get it in front of a buyer, using this software proposal contract template will make your task a lot easier.

Through the use of AI and other advanced technologies, Web-site design can stay on top of these factors, as well as address some new ones that are as yet impossible to predict. One of the tricky things about any new world is that you never quite know what it’ll look like until you’re in it. Unless you’re using VR, of course.",artificial intelligence,uxmatters.com
69,Why LivePerson Stock Was Up on Tuesday,https://g.foolcdn.com/editorial/images/708426/smiling-woman-tablet.jpg,08/11/2022,Sales trends were better than expected through September.,https://www.fool.com/investing/2022/11/08/why-liveperson-stock-was-up-on-tuesday/,"What happened

LivePerson (LPSN -7.56%) investors had a great morning on Tuesday. The cloud software specialist's stock had jumped 17% by 12:30 p.m. ET, compared to a 1.2% spike in the S&P 500. That surge just erased a small portion of recent losses for the stock, though, which remains down by over 60% so far in 2022.

It was powered by a well-received earnings report.

So what

LivePerson said sales of its artificial intelligence (AI) communications platform rose 10% in the selling period that ended in late September, easily beating management's early August forecast. The software-as-a-service specialist made progress at building up its client base, expanding the size of its renewed contracts, and adding value to the platform. Average annual contract size rose 18% to $675,000.

LivePerson remains unprofitable, and in fact operating loss more than doubled year over year to $49 million. Yet the company said its restructuring process is moving it toward positive free cash flow by next year. ""We're making durable changes to our operating model,"" CFO John Collins said in a press release.

Now what

The short-term outlook is brightening, too. LivePerson is now expecting sales to grow by between 10% and 11% in 2022, up from the prior forecast of between 8% and 10%. Yes, investors had been enjoying much faster sales gains as recently as the first quarter. But it is still good news that LivePerson isn't seeing a further deterioration in demand as IT budgets become more stressed.

Management's focus now is on adding value to the conversational AI platform so that more large enterprises consider it a necessary cost-saving expense rather than a discretionary purchase.

Progress here, combined with a push toward more high-value contracts, could allow LivePerson to achieve positive cash flow soon, with sustainable earnings growth likely after that. In the meantime, look for continued volatility in this small-cap stock.",artificial intelligence,motley fool
70,"Manipal Hospitals partners with Google Cloud to improve patient care, network efficiency",https://images.moneycontrol.com/static-mcnews/2021/01/Manipal-Hospitals-770x433.jpg,09/11/2022,"Manipal Hospitals will also use Google Cloudâs conversational artificial intelligence (AI) tools to improve customer interactions, offering patients 24/7 care.",https://www.moneycontrol.com/news/technology/manipal-hospitals-partners-with-google-cloud-to-improve-patient-care-network-efficiency-9475571.html,"(PC-Facebook)

Manipal Hospitals, the second-largest healthcare service provider in India, and Google Cloud have announced a partnership towards better patient care, clinician experience, and network efficiency.

According to a press release, Manipal Hospitals will leverage Google Cloud’s technology to enable virtual care services across its chain of hospitals in the country and create a new e-pharmacy platform that allows patients to order medicines directly from the hospital, and to build remote patient monitoring to improve overall care.

“I believe that the partnership will help promote penetration of Manipal’s clinical healthcare services in Tier II and III markets while making it convenient for both clinicians and patients. The partnership is critical to further clinical excellence of our healthcare system in markets with inequitable access to quality healthcare. Today, even the remotest areas of our country have access to the internet and smartphones. This, along with the penetration of Google Cloud in our country provides us the opportunity to deliver high-quality care in markets that we are not present in,” Karthik Rajagopal, COO, Manipal Hospitals, said.

Manipal Hospitals will also use Google Cloud’s conversational artificial intelligence (AI) tools to improve customer interactions, offering patients 24-by-7 care.

“Data-driven innovation is growing exponentially in healthcare, and this collaboration will help Manipal Hospitals use data, AI, and machine learning (ML) to improve patient experiences and outcomes,” said Bikram Singh Bedi, Managing Director at Google Cloud India.

“With Google Cloud’s technology and Manipal’s healthcare expertise, we have a unique opportunity to help the hospital network develop features that can dramatically improve the lives of people across the country,” he added.

Working with Google Cloud, Manipal Hospitals will transform the way it advances virtual care with AI-enabled digital diagnostics. The hospital chain will leverage Google’s tech to build multichannel conversational AI experiences across its appointment booking, searching for doctors, and other important patient tasks.

As a pioneer in healthcare, Manipal Hospitals is among the top healthcare providers in India serving over 4 million patients annually.

Google Cloud accelerates every organization’s ability to digitally transform its business. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry.",artificial intelligence,moneycontrol
71,SKEMA Business School launches 'SKEMA Law School for Business' - PR Newswire,https://mma.prnewswire.com/media/1938556/SKEMA_Law_School_For_Business.jpg?p=facebook,07/11/2022,"/PRNewswire/ -- SKEMA Business School inaugurated its law school ""SKEMA Law School for Business"" in Belo Horizonte, Brazil, on 28 October 2022. The creation of...",https://www.prnewswire.com/news-releases/skema-business-school-launches-skema-law-school-for-business-301669620.html,"PARIS, Nov. 7, 2022 /PRNewswire/ -- SKEMA Business School inaugurated its law school ""SKEMA Law School for Business"" in Belo Horizonte, Brazil, on 28 October 2022.

The creation of SKEMA Law School for Business is part of the school's SKY25 strategic plan, which aims to develop a 'comprehensive' institution to go beyond management disciplines and respond to trans-disciplinary issues. This is being done through the creation of three new schools in law, artificial intelligence and, in the coming months, geopolitics.

Left: Inauguration of SKEMA Law for Business on 28 October 2002 in Belo Horizonte, with Alice Guilhon, Dean and Executive President of SKEMA Business School, Judge José Arthur de Carvalho Pereira, President of the Court of Justice of the State of Minas Gerais, intellectual property lawyer Gabriel di Blasi, Geneviève Poulingue, Dean of SKEMA Brazil and Edgar Jacobs, Coordinator of the law courses at SKEMA Law School for Business. On the right: SKEMA's City Campus, in the heart of Belo Horizonte.

The objective of the law school in Belo Horizonte is to train aspiring professionals in the next 20 years with a global, multidisciplinary, and technological approach, capable of acting in an international environment with a multicultural prism.

SKEMA Law School for Business is structured around several programmes and online courses:

A state-approved five-year Bachelor's in Business Administration programme that prepares students for judicial law, technology law and business law.

Four master of science (MSc) programmes with several specialisations: digital law, judicial law and technology, start-up law, AI and blockchain.

A 'Law and Artificial Intelligence' nano degree (online course, open to all)

The educational content is based on a network of international researchers.

According to Edgar Jacobs, coordinator of the law courses, 'The strength of SKEMA Law for Business is that it offers students completely different professional insertion perspectives, at the interface of law and new technologies, which they did not have until now. This is because SKEMA Law School for Business can combine traditional law teaching with all the areas of expertise of the business school: international and multiculturalism, management, ethics, new technologies, artificial intelligence, etc.'

For Geneviève Poulingue, Dean of SKEMA in Brazil, 'The law school focuses on developing skills and competencies in our students that go beyond the basics of law, with a focus on innovation in the curriculum and teaching practices. Our intention is to train professionals prepared to work in the global and digital context, with a focus on people, diversity, and ethics, without neglecting basic and soft skills. In Brazil, this is an ideal combination for a degree of excellence in the field of law.'

Established in Brazil since 2015, SKEMA has 1,000 students this year in its new city campus, located in the heart of Belo Horizonte, the capital of Minas Gerais.

CONTACT: Christine Cassabois, [email protected]

Logo - https://mma.prnewswire.com/media/931024/SKEMA_Logo.jpg

Photo - https://mma.prnewswire.com/media/1938556/SKEMA_Law_School_For_Business.jpg

SOURCE SKEMA Business School",artificial intelligence,prnewswire
72,High-tech tool to perform low-cost health screening for newborns and mothers - Pennsylvania State University,https://psu-gatsby-files-prod.s3.amazonaws.com/s3fs-public/styles/16_9_1000w/public/2022/11/GettyImages-952682282-FatCamera.jpg?h=58c8a5e7&itok=Ha34tNE0,08/11/2022,"A new, $1.9 million grant from the National Institute of Biomedical Imaging and Bioengineering will allow Penn State researchers to develop artificial intelligence-based software that can evaluate the health of a newborn and their mother with only a photograp…",https://www.psu.edu/news/health-and-human-development/story/high-tech-tool-perform-low-cost-health-screening-newborns-and,"The placenta, an organ that provides nutrients and oxygen to a developing fetus, is typically delivered minutes after a baby is born. Rapid evaluation of the placenta can provide valuable information about the health of both the baby and mother, but a pathological examination requires a specialized pathologist. This evaluation of the placenta only occurs in about 20% of births in the United States. In less wealthy nations where there are fewer pathologists per capita, evaluation of the placenta is usually less common and often completely unavailable.

“By understanding placentas, we can understand a lot about health — both on the mom’s side and the baby’s side,” said Alison Gernand, associate professor of nutritional sciences and one of the principal investigators on the project. “But placentas are hard to assess, and this work currently requires a pathologist. We are not trying to replace pathologists, but we want to create something easy to use that can provide good information about any placenta, anywhere.”

The researchers explored a broad array of funding possibilities to continue this work, and this new grant will make progress possible. The final software would make the evaluation of placentas possible in a wide range of birth settings around the world.

To evaluate a placenta with the software, the user only needs to blot excessive blood with a paper towel and then take a digital photograph of the placenta. The software will evaluate the basic characteristics of the placenta — including size, color, shape, and circumference — and check for signs of infection to identify potential pathologies. Health care providers can then use this information to help them assess the health of the newborn and mother.

“When it is available, information from placental pathology is already used to help understand and explain critical events in pregnancy,” said Kelly Gallagher, assistant research professor of nursing and investigator on this project. “This information is also used to counsel families for future pregnancies and in the clinical care of medically vulnerable newborns. Rapid access to placental pathology information has the potential to dramatically improve care.”

The creation of this software requires expertise across multiple domains. The team includes researchers from Penn State’s College of Health and Human Development, College of Information Sciences and Technology and Ross and Carol Nese College of Nursing.

Each member of the project’s leadership team contributes to the research in a separate way. Gernand studies the placenta and pregnancy outcomes in low-resource settings. James Wang, distinguished professor of information sciences and technology and one of the principal investigators on the project, studies how to interpret and use large, complex, visual data. Jeffery Goldstein, assistant professor of pathology at Northwestern University’s Feinberg School of Medicine and one of the principal investigators on this project, studies bioimaging and informatics to improve diagnosis and treatment of problems in maternal-child health. Gallagher, a nurse-midwife, will coordinate the clinical aspects of data collection and provide expertise on maternal and infant health outcomes.

The researchers have already developed a prototype of the artificial intelligence software needed to evaluate the placentas. The algorithm that powers their software was granted a patent in the United States. Once the software is complete, the researchers are hoping to develop a mobile app that can perform the same evaluations. Making the software available in a mobile app would truly allow people in almost any birth setting to evaluate placentas during birth.",artificial intelligence,psu.edu
73,AI: The Apex Technology Of The Information Age,https://imageio.forbes.com/specials-images/imageserve/61f030570018a072dc46d1ec/0x0.jpg?format=jpg&width=1200,08/11/2022,Business leaders no longer have the luxury to wait when it comes to adopting AI in their companies. AI is all but certain to reshuffle the competitive order across every market.,https://www.forbes.com/sites/forbesbusinesscouncil/2022/11/08/ai-the-apex-technology-of-the-information-age/,"Gaurav Tewari, founder and Managing Partner of Omega Venture Partners.
getty
While the field of artificial intelligence (AI) has made steady progress over the past few decades, only recently did pr… [+5468 chars]",artificial intelligence,forbes
74,How To Attract In-Demand Talent As A Tech Startup,https://imageio.forbes.com/specials-images/imageserve/62dae46f55a065951d9391bd/0x0.jpg?format=jpg&width=1200,07/11/2022,"With growing pressure on the talent supply side, offering competitive salary packages may not be enough to attract and retain tech talent.",https://www.forbes.com/sites/theyec/2022/11/07/how-to-attract-in-demand-talent-as-a-tech-startup/,"By Terry Tateossian, founding partner of Socialfix Media, MIT blockchain and AI-certified consultant, speaker and activist.
getty
The talent crisis that tech companies are struggling with is not on… [+6452 chars]",artificial intelligence,forbes
75,NHS Hires US “Spy-Tech” Firm Palantir to Extract Patient Data Without Patient Consent,,08/11/2022,"The U.S. spyware giant Palantir, with intimate ties to defense, intelligence and security industries around the world, is set to play an even larger role in the UK's crisis-ridden National Health System (NHS).",https://www.nakedcapitalism.com/2022/11/nhs-hires-cia-linked-spy-tech-firm-palantir-to-extract-patient-data-without-patient-consent.html,"Palantir, with intimate ties to defense, intelligence and security industries around the world, seems set to play an even larger role in the UK’s crisis-ridden National Health System (NHS).

Last summer, as readers may recall, executives at NHS England — the non-departmental government body that runs the National Health Service in England — came up with an ingenious plan to digitally scrape the general practice data of up to 55 million patients and share it with any private third parties willing to pay for it. NHS England allowed patients to opt out of the scheme; they just didn’t bother telling them about it until three weeks before the deadline, presumably because if they had, millions of patients would have opted out.

When the FT finally broke the story, a scandal erupted. NHS England officials responded by shelving the scheme, saying they needed to focus on reaching out to patients and reassuring them their data is safe. But that hasn’t happened. Instead, they have waited for the scandal to die down before embarking on an even more egregious scheme.

This time it is patient data from UK hospitals that is up for grabs. And patients will have no opt-out option. In fact, without even consulting patients, NHS England has instructed NHS Digital — which will soon be merged with NHS England as part of the UK’s governments accelerated reforms to the NHS’ “tech agenda” — to gather patient data from NHS hospitals and extract it to its data platform, which is based on Palantir’s Foundry enterprise data management platform.

The pretext for taking such a step is that researching and analyzing patients’ hospital data will help the NHS better understand and tackle the crisis in treatment waiting times resulting from the COVID-19 pandemic. But the result will be yet more private-sector involvement in essential NHS processes. And in this case, the company being involved in those processes is one of the darkest in the tech universe.

A Highly Coveted Prize

The NHS is the world’s seventh largest employer. And it is home to one of the richest repositories of patient data on the planet. “One of the great requirements for health tech is a single health database,” Damindu Jayaweera, head of technology research at UK investment bank Peel Hunt told Investors’ Chronicle. “There are only two places as far as I know that digitise the data of the whole population from birth to death… China and the UK.”

As the FT reported earlier this year, Palantir aspires to become the underlying data operating system for the NHS. To that end, it has already lured two senior NHS managers to its executive suites, including the former chief of artificial intelligence. It now has its sights set on the ultimate prize: a five-year, £360 million contract to manage the personal health data of millions of patients.

Palantir’s latest encroachment into NHS operations came to light thanks to the publication of board paper’s just hours before NHS Digital’s latest board meeting, on November 1. Those papers no longer seem to be accessible so I am relying on a report published on Friday 4 by The Register, a British technology news website, as well as a heavily detailed twitter thread by Phil Booth of MedConfidential, a group campaigning for confidentiality and consent in health and social care.

According to Booth, on page 158 of the board papers NHS England instructs NHS Digital to use Palantir Tech’s Foundry platform to “collect patient-level identifiable [hospital] data pertaining to admission, inpatient, discharge and outpatient activity from acute care settings on a daily basis.”

First, beginning on page 158, are some Directions that @NHSEngland must know will be HIGHLY controversial – given they are telling @NHSDigital to use @PalantirTech's #Foundry to collect *patient level identifiable data* from hospitals… pic.twitter.com/PM4mEl5z2e — Phil Booth (@EinsteinsAttic) November 1, 2022

Following previous data debacles, both the NHS and UK government ministers had pledged that in future any patient data shared for research and analysis purposes would be anonymized. But now they are talking about using “pseudonymized” data, which is completely different. In 2014, the Information Commissioner’s Office (ICO), the UK’s independent regulatory office (national data protection authority) dealing with the Data Protection Act 2018 and the General Data Protection Regulation, said the following about pseudonymized data:

Pseudonymising personal data can reduce the risks to the data subjects and help you meet your data protection obligations. However, pseudonymisation is effectively only a security measure. It does not change the status of the data as personal data. Recital 26 makes it clear that pseudonymised personal data remains personal data and within the scope of the UK GDPR. “…Personal data which have undergone pseudonymisation, which could be attributed to a natural person by the use of additional information should be considered to be information on an identifiable natural person…”

In other words, says Booth, “while NHS England may want to ignore people’s opt-outs from Research & Planning uses, and contorts itself to say their data’s not ‘confidential patient information’, the law(s) says otherwise.”

There are also serious questions about who exactly will be doing the pseudonymisation, and who will hold the keys, says Booth: “There’s a world of difference between an independent statutory Safe Haven (i.e. NHS Digital), NHS England which wants ALL the data to use for whatever it wants, and Palantir.”

A Dark Company

Named after the “seeing stones” used in The Lord of the Rings, Palantir was set up in 2003 with seed money from the CIA’s venture capital arm, In-Q-Tel (IQT). It is one of the darkest companies in the tech sphere. While it is making significant inroads in the corporate world, its main line of business is to provide data-mining technology to support US military operations, mass surveillance, and predictive policing. Its technology is also used by ICE to identify illegal migrants before detaining and deporting them.

When, in 2018, thousands of Google employees refused to participate in Project Maven, a secret Pentagon-funded AI pilot program aimed at the unmanned operation of aerial vehicles, the project was taken up by Palantir. Critics warn that the technology could pave the way to autonomous weapons that decide who to target without human input. In February 2021, Palantir’s chief operating officer boasted to investors that Palantir was driving towards being “inside of every missile, inside of every drone.”

This is a company that deals in death on a daily basis but is also rapidly building a stake in the health and life services sector. During the early months of the pandemic it was one of a number of companies chosen to help collect, store, process and share data for the United States Department of Health and Human Services (HHS) — a project that the Electronic Frontier Foundation (EFF) warned poses “a grave threat to the data privacy of all Americans.”

On the other side of the pond, the UK Government signed a deal in March 2020 with an assortment of private tech firms, including Palantir, to help run the NHS’s massive COVID-19 “data store”. It was supposed to be a short-term arrangement but in December of the same year the Department of Health and Social Care awarded Palantir an additional two-year contract, worth up to £23 million, to help run the NHS’ massive database.

Palantir’s gathering takeover of NHS data services has met strong resistance. In September 2021, the UK’s Department for Health and Social Care was forced to terminate a contract with Palantir over the management of social care data, following a massive protest campaign involving more than 50 groups. The move was taken as a tentative sign that the UK government may finally be pivoting away from using Palantir’s services, at least in the healthcare sector. That is clearly not the case.

But even if the UK government had made that pivot, Palantir had a back-up plan in place, as Bloomberg reported in late September. That plan was laid out by Palantir’s regional head Louis Mosley in a Sept. 24 email entitled “Buying our way in…!”, and it essentially involved “hoovering up” small businesses serving the NHS to “take a lot of ground and take down a lot of political resistance.”

As Cory Doctorow notes in his excellent post last month, How Palantir Will Steal the NHS, Palantir has essentially unfettered access to the capital markets, as well as the deep pockets of its founder, the “cartoon villain” Peter Thiel. While it is clear that good data management has a crucial role to play in the future of health and social care provision, Palantir’s unshakeable commitment to proprietary, secretive software development methodologies makes it woefully ill-suited for NHS service provision:

Compare the NHS to Ben Goldacre’s landmark “Better, broader, safer: using health data for research and analysis”: https://www.gov.uk/government/publications/better-broader-safer-using-health-data-for-research-and-analysis/better-broader-safer-using-health-data-for-research-and-analysis Goldacre argues that the only way to unlock the medical insights in aggregate NHS patient data is with public software: an open and free “trusted research platform” that anyone can audit and verify. While the code for this platform would be public, NHS patient data would never leave it. Instead, researchers who wanted to investigate hypotheses about the effectiveness of different interventions would send queries to the platform and get results back — without ever touching the data. This is a system that only works if it’s hosted by democratically accountable public services — not by private actors accountable to their shareholders, and certainly not secretive companies whose primary expertise is in helping spy agencies conduct mass surveillance.

As Doctorow notes, most people in the UK do not want the NHS to be privatised. For them the NHS, founded in 1948 on the principles of free and equal access to medical treatment, is sacrosanct:

But while the British people oppose privatisation, the British investor class are slavering for it. Oligarchs love to loot public services, which is why the IMF is so adamant that the countries it “helps” sell off their public water, housing, even their roads and schools and museums… [The NHS] has been subject to the death of a thousand literal cuts, as Tories and Labour alike have starved it of resources. More importantly, both parties have turned ever-larger chunks of the NHS over to private-sector looters who have taken over hospitals, services, record-keeping and more.

An Even Bigger Picture

But this is not just about the NHS. It is about our governments’ role as guardians of our most precious data, including our health and biometric information. As governments, central banks and global corporations trip over each other to rush into existence digital identity programs and central bank digital currencies, that role is set to grow exponentially (unless, of course, we can stop them in their tracks).

In the new digital age that is rapidly forming around us, citizens will be custodians of our own data. We will be the ones who get to decide which parts of our data get shared and with whom. At least that is what we are being told. But these are just words, and words can be hollow.

We have to judge our governments on their actions. And their actions to date — including NHS England’s decision to grant custodianship of NHS patients’ hospital data to Palantir without even informing patients, the US State Department’s decision to give intelligence and law enforcement agencies unfettered access to more than 145 million Americans’ personal data, and the US government’s plans to share the biometric data of its citizens with dozens of other governments — speak of a whole different reality.",artificial intelligence,nakedcapitalism.com
76,"Artificial Intelligence definition, governance on MEPs’ menu",https://www.euractiv.com/wp-content/uploads/sites/2/2022/11/shutterstock_1034235682-800x450.jpg,08/11/2022,The definition of Artificial Intelligence and how the new EU’s rulebook for this emerging technology will be implemented will be the focus of a political meeting on Wednesday (9 November).,https://www.euractiv.com/section/digital/news/artificial-intelligence-definition-governance-on-meps-menu/,"The definition of Artificial Intelligence and how the new EU’s rulebook for this emerging technology will be implemented will be the focus of a political meeting on Wednesday (9 November), according to a draft agenda seen by EURACTIV.

The AI Act is a flagship legislation to set the rules on Artificial Intelligence proportionate to their potential to harm people or properties. The discussions on the upcoming regulation have mainly progressed on the technical side in the past weeks.

However, more sensitive political topics need to be scaled up to the political level for political groups to reach a common position. The previous political debate occurred in October over the thorny facial recognition issues and the regulation’s scope.

AI Act: EU Parliament’s discussions heat up over facial recognition, scope EU lawmakers held their first political debate on the AI Act on Wednesday (5 October) as the discussion moved to more sensitive topics like the highly debated issue of biometric recognition.

AI definition

On the agenda for Wednesday’s discussion is the definition of AI systems, a fundamental building block to making the regulation future-proof since this technology is still at a relatively early stage of development.

In this regard, the most significant change is that the definition was moved from Annex I to an article. In the original proposal, the European Commission was empowered to modify the annexe later, an option that would no longer be available in this new setting.

EURACTIV understands that this change was because the definition is considered a part too crucial of the regulation to be changed via secondary legislation. The co-rapporteurs seem determined to ensure the definition is made future-proof via an outcome-oriented approach focused on what AI does rather than what it is and its techniques.

The rewritten article introduces three cumulative conditions. To qualify as AI, the system should be able to: receive machine or human-based data; infer how to achieve a given set of goals using learning, reasoning or modelling; generate outputs in the form of content, predictions, recommendations or decisions influencing the real or virtual environment it interacts with.

A final specification adds that “AI systems can be designed to operate with varying levels of autonomy.”

The AI definition will likely need further political discussions, as the European Parliament is still far from a shared view. Conservative MEPs, in particular, are pushing for a narrower definition of AI.

What might be able to progress faster is the second point on the agenda: the governance structure.

AI regulation filled with thousands of amendments in the European Parliament Each political group of the European Parliament submitted a few hundred amendments to the upcoming AI Act, setting the tone for future discussions.

AI Office

As EURACTIV reported last Friday (4 November), the co-rapporteurs proposed creating an AI Office that would play a centralising role in the enforcement architecture, notably as the body would have the power to issue binding decisions in competencies disputes between national competent authorities.

The arrangement is based mainly on the European Data Protection Board, the body that gathers data protection authorities to coordinate the enforcement of the General Data Protection Regulation. At the same time, the idea is to address what is deemed as significant flaws in the GDPR’s enforcement.

Therefore, MEPs will be called to discuss whether the AI Office should be independent and have a legal personality, its own funding and be adequately staffed, a robust advisory forum with ample stakeholders involvement and the capacity to decide on supervision disputes.

Leading MEPs push for European 'office' to enforce the EU's AI rulebook The lawmakers spearheading the work on the AI Act launched the idea of an AI Office to streamline enforcement and solve competency disputes on cross-border cases.

Political pressure

While several fundamental questions are a moving target in the European Parliament, the EU Council is about to formalise its position on the AI Act in a Committee of Permanent Representatives meeting on 18 November.

According to a European Parliament official, the fact that the other co-legislator has finalised its position will significantly increase the political pressure on EU lawmakers to reach an agreement. By contrast, a second official dismissed the allegation that political pressure was mounting.

“The co-rapporteurs know that with the current Council position, it’s important to have a solid majority behind you and properly discuss the proposals to make sure you have that solid majority,” a third parliamentary official said.

[Edited by Alice Taylor]",artificial intelligence,euractiv
77,Advancing To The Future Of Industrial Automation,https://imageio.forbes.com/specials-images/imageserve/612cfe722afc9777411adcb0/0x0.jpg?format=jpg&width=1200,09/11/2022,The ability to engage subject matter experts and operators by elevating classic industrial automation with modern AIoT concepts lets companies realize the best of human and ML/AI collaboration.,https://www.forbes.com/sites/forbestechcouncil/2022/11/09/advancing-to-the-future-of-industrial-automation/,"Kenneth Tran, founder and CEO of Koidra Inc.an AIoT tech company that modernizes industrial controls and manufacturing.
getty
Although factories and processing plants around the world are progressi… [+5237 chars]",artificial intelligence,forbes
78,Why Advanced Micro Devices Fell 5.2% in October,https://g.foolcdn.com/editorial/images/708059/microchip-technology-computer-chip-data-processing.jpg,06/11/2022,AMD gave an early warning on a subpar third quarter.,https://www.fool.com/investing/2022/11/06/why-advanced-micro-devices-fell-52-in-october/,"What happened

Shares of Advanced Micro Devices (AMD -6.16%) fell 5.2% in October, despite the overall S&P 500 increasing 8%, according to data from S&P Global Market Intelligence. AMD faced a slew of headwinds during the quarter, including a cratering PC market and the unveiling of new restrictions on advanced semiconductor sales to China. The stock took a big downturn when it pre-announced third-quarter revenue and earnings that missed the mark by a wide margin.

So what

On Oct. 6, AMD management pre-announced its third-quarter results as revenue and earnings wound up coming in far below their projections on the second-quarter conference call. Typically, when there is a wide gap between prior guidance and what actually happens, a company will pre-announce.

In the case of AMD, it pre-announced third-quarter revenue of $5.6 billion versus prior guidance of $6.7 billion, needless to say, a pretty wide chasm. Strikingly, the shortfall occurred really in one segment, the PC market, which came to an absolute standstill during the second half of the summer.

AMD ultimately reported a dismal 40% decline in its client segment (PCs), which accounted for pretty much the entire shortfall. That massive decline was actually enough to send that segment to a slight operating loss and for the client segment to fall below both the enterprise and gaming segments.

AMD was certainly not alone; just about every company involved in the PC market has taken a massive hit. According to IT research firm Gartner, PC shipments were down a stunning 19.5% year over year in the third quarter -- the steepest decline since Gartner began tracking results in the mid-1990s!

On the upside, the enterprise segment reported strong 45% growth and came in at $1.6 billion, gaming revenue was up 16% to $1.6 billion, and embedded chip revenue from the Xilinx acquisition came in at $1.3 billion, which was in line with original guidance.

So it wasn't a total disaster for AMD; however, given that client revenue was the largest segment prior to last quarter, its massive decline greatly affected AMD's overall revenue and profitability.

Now what

There's nothing particularly wrong with AMD's execution or its design chops -- the October weakness was really about the macroeconomic picture and, specifically, the PC market. Therefore, the broader economy will likely affect its fate over the near term.

The factor is the potential worsening of the economic slowdown, affecting even the strong data center segment. However, commentaries from large tech companies still indicate they will continue to spend on data centers and artificial intelligence (AI) in the upcoming year. The investors of the big FAANG names didn't really appreciate that on their earnings calls, but that is good news for AMD's data center segment. Of note, AMD will unveil its newest EPYC data center chips on Thursday, November 10.

Another factor is China. While Lisa Su said new restrictions on sales of chips to China would have only a ""minimal"" impact in the recent third-quarter earnings release, the new rules unveiled in early October didn't help sentiment. However, China sales have been very weak, which explains much of the PC shortfall. Should China reopen its economy and stop the endless COVID-19 lockdowns, that could be a positive. However, that likely wouldn't happen until spring.

Overall, there is still a lot of uncertainty surrounding the macroeconomic picture and China. However, AMD's stock price has fallen so much -- down 59% over the past year -- that it may be attractive to investors with a longer time horizon. However, AMD shareholders should just be prepared for a rocky road in the near term.",artificial intelligence,motley fool
79,Insights on the Accounting Software Global Market to 2030 - Increasing Investment for Artificial Intelligence Oriented Accounting Software is Driving Growth,https://media.zenfs.com/en/prnewswire.com/e75ef6f3096d7cb6f5dd43ba82eca2fe,09/11/2022,"The ""Accounting Software Market By Component, By Deployment Mode, By Enterprise Size, By Type, By Industry Vertical: Global Opportunity Analysis and Industry...",https://finance.yahoo.com/news/insights-accounting-software-global-market-173000431.html,"DUBLIN, Nov. 9, 2022 /PRNewswire/ -- The ""Accounting Software Market By Component, By Deployment Mode, By Enterprise Size, By Type, By Industry Vertical: Global Opportunity Analysis and Industry Forecast, 2020-2030"" report has been added to ResearchAndMarkets.com's offering.

Research_and_Markets_Logo

According to this report the accounting software market was valued at $11.9 billion in 2020, and is estimated to reach $70.2 billion by 2030, growing at a CAGR of 19.6% from 2021 to 2030.



The accounting software is a used by accounting professionals, bookkeepers, and business owners to process accounting transactions and manage accounts. It provides a variety of benefits such as, account receivable & payable, tax compliance, cash flow analysis, trial balance, balance sheet, invoicing, income and expanses statements, and payroll. Accounting software improves corporate performance and streamline the business process. In addition, it saves money and time and allows organizations to execute multiple tasks at the same time.

Furthermore, it allows efficient and fast processing of financial transaction. Moreover, it eliminates manual process and improve accuracy and productivity by reduction of approval process. Furthermore, the accounting software provides industries with flexibility and scalability to enable a smooth integration of business processes, which ultimately support the market growth.



Factor such as surging demand for cloud-based accounting software and increase adoption of innovative technology to increases business productivity, drive the growth of the market. In addition, automation in accounting processes for providing greater efficiency by eliminating manual tasks, drive the market growth. Furthermore, increase in investment for artificial intelligence-oriented accounting software and rise in adoption of mobile and app-based accounting software, are anticipated to strengthen the market growth. However, data security & privacy concerns and maintenance & customization costs hamper the market growth.



The global accounting software market is segmented into component, deployment mode, type, organization size, industry vertical, and region. By component, the market is bifurcated into software and services. On the basis of deployment mode, it is segregated into cloud and on-premises.

Depending on type, it is fragmented into spreadsheets, commercial accounting software, enterprise accounting software and custom accounting software. As per industry vertical, it is differentiated into BFSI, retail & e-commerce, manufacturing, IT & telecom, healthcare, government & public sector, energy & utilities, media & entertainment, and others. According to organization size it is categorized into small to medium enterprise (SMEs) and large-scale enterprise. Region wise, it is analyzed across North America, Europe, Asia-Pacific, and LAMEA.



The market players operating in the accounting software market, include Infor Inc., Intuit, Inc., Microsoft corporation, Oracle Corporation, Sage Group Plc, SAP SE, Thomson Reuters, Xero Ltd, Zeta Software LLC and Zoho Corporation. These major players have adopted various key development strategies such as business expansion, new product launches, and partnerships.



Key Benefits For Stakeholders

This report provides a quantitative analysis of the market segments, current trends, estimations, and dynamics of the accounting software market analysis from 2020 to 2030 to identify the prevailing accounting software market opportunities.

The market research is offered along with information related to key drivers, restraints, and opportunities.

Porter's five forces analysis highlights the potency of buyers and suppliers to enable stakeholders make profit-oriented business decisions and strengthen their supplier-buyer network.

In-depth analysis of the accounting software market segmentation assists to determine the prevailing market opportunities.

Major countries in each region are mapped according to their revenue contribution to the global market.

Market player positioning facilitates benchmarking and provides a clear understanding of the present position of the market players.

The report includes the analysis of the regional as well as global accounting software market trends, key players, Accounting Software Industry segments, application areas, and market growth strategies.

Key Topics Covered:



CHAPTER 1: INTRODUCTION



CHAPTER 2: EXECUTIVE SUMMARY



CHAPTER 3: MARKET OVERVIEW

3.1. Market definition and scope

3.2. Key findings

3.2.1. Top investment pockets

3.3. Porter's five forces analysis

3.4. Top player positioning

3.5. Market dynamics

3.5.1. Drivers

3.5.2. Restraints

3.5.3. Opportunities

3.6. COVID-19 Impact Analysis on the market

3.7. Key Regulation Analysis

3.8. Regulatory Guidelines



CHAPTER 4: ACCOUNTING SOFTWARE MARKET, BY COMPONENT

4.1 Overview

4.1.1 Market size and forecast

4.2 Solution

4.2.1 Key market trends, growth factors and opportunities

4.2.2 Market size and forecast, by region

4.2.3 Market analysis by country

4.3 Services

4.3.1 Key market trends, growth factors and opportunities

4.3.2 Market size and forecast, by region

4.3.3 Market analysis by country



CHAPTER 5: ACCOUNTING SOFTWARE MARKET, BY DEPLOYMENT MODE

5.1 Overview

5.1.1 Market size and forecast

5.2 On premise

5.2.1 Key market trends, growth factors and opportunities

5.2.2 Market size and forecast, by region

5.2.3 Market analysis by country

5.3 Cloud

5.3.1 Key market trends, growth factors and opportunities

5.3.2 Market size and forecast, by region

5.3.3 Market analysis by country



CHAPTER 6: ACCOUNTING SOFTWARE MARKET, BY ENTERPRISE SIZE

6.1 Overview

6.1.1 Market size and forecast

6.2 Large Enterprises

6.2.1 Key market trends, growth factors and opportunities

6.2.2 Market size and forecast, by region

6.2.3 Market analysis by country

6.3 SMEs

6.3.1 Key market trends, growth factors and opportunities

6.3.2 Market size and forecast, by region

6.3.3 Market analysis by country



CHAPTER 7: ACCOUNTING SOFTWARE MARKET, BY TYPE

7.1 Overview

7.1.1 Market size and forecast

7.2 Spreadsheets

7.2.1 Key market trends, growth factors and opportunities

7.2.2 Market size and forecast, by region

7.2.3 Market analysis by country

7.3 Commercial Accounting Software

7.3.1 Key market trends, growth factors and opportunities

7.3.2 Market size and forecast, by region

7.3.3 Market analysis by country

7.4 Enterprise Accounting Software

7.4.1 Key market trends, growth factors and opportunities

7.4.2 Market size and forecast, by region

7.4.3 Market analysis by country

7.5 Custom Accounting Software

7.5.1 Key market trends, growth factors and opportunities

7.5.2 Market size and forecast, by region

7.5.3 Market analysis by country



CHAPTER 8: ACCOUNTING SOFTWARE MARKET, BY INDUSTRY VERTICAL

8.1 Overview

8.1.1 Market size and forecast

8.2 BFSI

8.2.1 Key market trends, growth factors and opportunities

8.2.2 Market size and forecast, by region

8.2.3 Market analysis by country

8.3 Retail and Ecommerce

8.3.1 Key market trends, growth factors and opportunities

8.3.2 Market size and forecast, by region

8.3.3 Market analysis by country

8.4 Manufacturing

8.4.1 Key market trends, growth factors and opportunities

8.4.2 Market size and forecast, by region

8.4.3 Market analysis by country

8.5 IT and Telecom

8.5.1 Key market trends, growth factors and opportunities

8.5.2 Market size and forecast, by region

8.5.3 Market analysis by country

8.6 Healthcare

8.6.1 Key market trends, growth factors and opportunities

8.6.2 Market size and forecast, by region

8.6.3 Market analysis by country

8.7 Government and Public Sector

8.7.1 Key market trends, growth factors and opportunities

8.7.2 Market size and forecast, by region

8.7.3 Market analysis by country

8.8 Energy and Utilities

8.8.1 Key market trends, growth factors and opportunities

8.8.2 Market size and forecast, by region

8.8.3 Market analysis by country

8.9 Media and Entertainment

8.9.1 Key market trends, growth factors and opportunities

8.9.2 Market size and forecast, by region

8.9.3 Market analysis by country

9.0 Others

9.0.1 Key market trends, growth factors and opportunities

9.0.2 Market size and forecast, by region

9.0.3 Market analysis by country



CHAPTER 9: ACCOUNTING SOFTWARE MARKET, BY REGION



CHAPTER 10: COMPANY LANDSCAPE

10.1. Introduction

10.2. Top winning strategies

10.3. Product Mapping of Top 10 Player

10.4. Competitive Dashboard

10.5. Competitive Heatmap

10.6. Key developments



CHAPTER 11: COMPANY PROFILES

11.1 Infor Inc.

11.1.1 Company overview

11.1.2 Company snapshot

11.1.3 Operating business segments

11.1.4 Product portfolio

11.1.5 Business performance

11.1.6 Key strategic moves and developments

11.2 Intuit, Inc.

11.2.1 Company overview

11.2.2 Company snapshot

11.2.3 Operating business segments

11.2.4 Product portfolio

11.2.5 Business performance

11.2.6 Key strategic moves and developments

11.3 Microsoft corporation

11.3.1 Company overview

11.3.2 Company snapshot

11.3.3 Operating business segments

11.3.4 Product portfolio

11.3.5 Business performance

11.3.6 Key strategic moves and developments

11.4 Oracle Corporation

11.4.1 Company overview

11.4.2 Company snapshot

11.4.3 Operating business segments

11.4.4 Product portfolio

11.4.5 Business performance

11.4.6 Key strategic moves and developments

11.5 Sage Group Plc

11.5.1 Company overview

11.5.2 Company snapshot

11.5.3 Operating business segments

11.5.4 Product portfolio

11.5.5 Business performance

11.5.6 Key strategic moves and developments

11.6 Sage Group plc

11.6.1 Company overview

11.6.2 Company snapshot

11.6.3 Operating business segments

11.6.4 Product portfolio

11.6.5 Business performance

11.6.6 Key strategic moves and developments

11.7 SAP SE

11.7.1 Company overview

11.7.2 Company snapshot

11.7.3 Operating business segments

11.7.4 Product portfolio

11.7.5 Business performance

11.7.6 Key strategic moves and developments

11.8 Thomson Reuters

11.8.1 Company overview

11.8.2 Company snapshot

11.8.3 Operating business segments

11.8.4 Product portfolio

11.8.5 Business performance

11.8.6 Key strategic moves and developments

11.9 Xero Ltd

11.9.1 Company overview

11.9.2 Company snapshot

11.9.3 Operating business segments

11.9.4 Product portfolio

11.9.5 Business performance

11.9.6 Key strategic moves and developments

11.10 Zeta Software LLC

11.10.1 Company overview

11.10.2 Company snapshot

11.10.3 Operating business segments

11.10.4 Product portfolio

11.10.5 Business performance

11.10.6 Key strategic moves and developments

11.11 Zoho Corporation

11.11.1 Company overview

11.11.2 Company snapshot

11.11.3 Operating business segments

11.11.4 Product portfolio

11.11.5 Business performance

11.11.6 Key strategic moves and developments



For more information about this report visit https://www.researchandmarkets.com/r/a1pgac

Media Contact:

Research and Markets

Laura Wood, Senior Manager

press@researchandmarkets.com



For E.S.T Office Hours Call +1-917-300-0470

For U.S./CAN Toll Free Call +1-800-526-8630

For GMT Office Hours Call +353-1-416-8900



U.S. Fax: 646-607-1907

Fax (outside U.S.): +353-1-481-1716

Logo: https://mma.prnewswire.com/media/539438/Research_and_Markets_Logo.jpg

Cision

View original content:https://www.prnewswire.com/news-releases/insights-on-the-accounting-software-global-market-to-2030---increasing-investment-for-artificial-intelligence-oriented-accounting-software-is-driving-growth-301673262.html

SOURCE Research and Markets",artificial intelligence,yahoo entertainment
80,Why Nvidia Stock Popped Tuesday Morning,https://g.foolcdn.com/editorial/images/708394/two-colleagues-conferring-in-a-server-room.jpg,08/11/2022,The chipmaker has introduced a new processor to sidestep the U.S. government's China ban.,https://www.fool.com/investing/2022/11/08/why-nvidia-stock-popped-tuesday-morning/,"What happened

Shares of Nvidia (NVDA -5.66%) bounced Tuesday morning, jumping as much as 4.1%. As of 10:34 a.m. ET, the stock was still up 1.5%.

The catalyst that sent the semiconductor specialist higher was news that the company had created an alternative chip to comply with the U.S. export ban to China.

So what

Nvidia has developed a new high-end processor for customers in China, following a U.S. government export ban announced back in August. The newly designed graphics processing unit (GPU), dubbed the A800, has been modified to meet to new restrictions, while still providing users with ample processing power.

An Nvidia spokesperson said in a statement, ""The Nvidia A800 GPU, which went into production in Q3, is another alternative product to the Nvidia A100 GPU for customers in China. The A800 meets the U.S. government's clear test for reduced export control and cannot be programmed to exceed it.""

The modified processor appears to have many of the same capabilities as the A100, though the transfer rate has been reduced from 600 gigabytes per second to 400 gigabytes per second, a clear performance reduction. This is also below the threshold for exports, which restricted the sale of chips with rates of 600 gigabytes or higher.

The redesigned processor made its appearance on a distributor website in China and is listed among the components of two of the country's foremost server manufacturers.

Now what

In a regulatory filing in late August, Nvidia said the U.S. government had announced new licensing restrictions for its most advanced processors, forbidding exports to Russia and China, though the company confirmed at the time that it ""does not sell products to customers in Russia.""

The restrictions applied only to Nvidia's most advanced processor, a workhorse designed for servers and data centers used for artificial intelligence and supercomputing.

Nvidia initially reduced its guidance for the current quarter, saying the company could lose as much as $400 million in potential sales as the result of the new requirements. It isn't known how this new processor will impact its results. This latest development shows why Nvidia is the undisputed industry leader and remains a buy.",artificial intelligence,motley fool
81,Why Upstart Stock Crashed and Burned on Wednesday,https://g.foolcdn.com/editorial/images/708617/a-consumer-at-a-bankers-desk-applying-for-a-loan.jpg,09/11/2022,The broader economic meltdown was evident in the company's quarterly financial results.,https://www.fool.com/investing/2022/11/09/why-upstart-stock-crashed-and-burned-on-wednesday/,"What happened

Shares of Upstart Holdings (UPST -10.40%) cratered out of the gate on Wednesday, eventually recouping some of their losses. The stock plunged as much as 26.4% in early trading, but by 11:52 a.m. ET, the stock was down 13.4%.

The catalyst that sent the artificial intelligence (AI)-based lending platform lower was its third-quarter financial results, which were far worse than expectations.

So what

Upstart reported revenue of $157 million, down 31% year over year, while total fee revenue of $179 million slumped 15%. This resulted in an adjusted loss per share of $0.24.

To give those numbers context, analysts' consensus estimates were calling for revenue of $169.4 million and an adjusted loss per share of $0.08, so Upstart wasn't even in the ballpark.

The downtrodden economy weighed on Upstart's results, which was evident in other metrics. The company's banking and auto partners originated 188,519 loans, down 48% year over year. The total value of those loans was $1.85 billion, down 41%.

Conversion rates also took a hit, falling to 9.7%, down from 23% in the prior-year quarter. If there was a bright spot, contribution profits of $96 million edged higher from $95.9 million, pushing contribution margin to 54%, compared with 46% in the year-ago quarter.

Now what

If investors were looking for any solace in Upstart's fourth-quarter forecast, they didn't find it. Management is guiding for revenue in a range of $125 million to $145 million, a decline of 56% at the midpoint of its guidance.

Still, for investors with a long-term outlook, there are reasons to be bullish. Upstart's fintech platform is a giant step forward in accuracy in judging credit risk, using more than 1,500 variables instead of just a few used by the traditional system. By better determining risk, Upstart is bringing a far greater number of borrowers into the fold, which will benefit the company's partners.

Rising interest rates and fears regarding a spike in defaults are causing loan availability to shrink -- for now. This too shall pass when the economy improves. In the meantime, Upstart shares are currently trading at less than 1.5 times sales, a bargain price for a company disrupting the lending industry.",artificial intelligence,motley fool
82,Oil and gas emissions up to three times what is reported: monitor,https://scx2.b-cdn.net/gfx/news/2022/flared-natural-gas-is-1.jpg,09/11/2022,"Planet-heating emissions from oil and gas production could be three times higher than reported, according to a satellite monitoring project launched Wednesday that the UN chief said made it harder to ""cheat"".",https://phys.org/news/2022-11-oil-gas-emissions.html,"Flared natural gas is burned off at Apache Corporations operations at the Deadwood natural gas plant in the Permian Basin in 2015.

Planet-heating emissions from oil and gas production could be three times higher than reported, according to a satellite monitoring project launched Wednesday that the UN chief said made it harder to ""cheat"".

The new tool—unveiled at United Nations COP27 climate talks in Egypt—has pinpointed more than 70,000 sites spewing emissions into the atmosphere.

The project, run by a group of research institutions, charities and companies, monitors sites including heavy industry, energy production, agriculture, transport, waste and mining.

Using artificial intelligence to analyse data from more than 300 satellites, as well as thousands of sensors on land and in the sea, the Climate TRACE monitor found that the top 14 largest emitters are all oil and gas extraction sites.

Of those, the biggest emitter on the planet is the Permian Basin in Texas—one of the largest oilfields in the world—said former US vice president Al Gore, a project founder.

""With new data on methane and flaring, we now estimate that the actual emissions are three times higher than what they have reported,"" Gore said.

Flaring is the burning off of unwanted natural gas from oil and gas wells.

Methane, emitted by leaks from fossil fuel installations as well as from other human-caused sources like livestock and landfills, is responsible for roughly 30 percent of the global rise in temperatures to date.

Dozens of countries last year pledged to act to cut pollution from the potent greenhouse gas.

Former US vice president and climate campaigner Al Gore warned Wednesday that emissions from oil and gas production could be three times higher than reported.

'Wake-up call'

United Nations chief Antonio Guterres praised the initiative for shining a light on actual emissions using direct observations.

""You are making it more difficult to greenwash or—to be more clear—to cheat,"" he said.

""This should be a wake-up call to governments and the financial sector, especially those that continue to invest in and underwrite fossil fuel pollution,"" he said.

The contribution of industry sectors to global warming in 2021, according to data collected by Climate Trace.

Climate TRACE first determined what industrial activity was at a given site and therefore what type of emissions to look for, said Gavin McCormick, another co-founder and director of the US environmental technology nonprofit WattTime.

Every time a satellite passes over, they can then interpret ""what are we seeing"".

Gore, a Nobel Peace Prize winner for his climate advocacy, said the top 500 sources identified emit more per year than the United States—and half of the pollution is from power plants.

An aeroplane flies above the green zone at the Sharm el-Sheikh International Convention Centre, during the COP27 climate conference.

All the data from the project is available free online at climatetrace.org to increase ""transparency, collaboration and accountability for climate action"", Gore added.

The International Energy Agency has decried the enormous amount of methane that leaks from fossil fuel operations, estimating the amount lost last year globally was broadly similar to all the gas used in Europe's power sector.

In October, NASA said a methane plume about two miles (3.3 kilometres) long was detected southeast of Carlsbad, New Mexico, in the Permian Basin.

© 2022 AFP",artificial intelligence,phys.org
83,New approach extracts more data on steel alloys for materials databases,https://scx2.b-cdn.net/gfx/news/2022/new-data-extracted-fro.jpg,07/11/2022,A new approach uses data from one type of test on small metal alloy samples to extract enough information for building databases that can be used to predict the properties and potentials of new materials. The details were published in the journal Science and …,https://phys.org/news/2022-11-approach-steel-alloys-materials-databases.html,"Finite element model of instrumented indentation test. Credit: Science and Technology of Advanced Materials: Methods (2022). DOI: 10.1080/27660400.2022.2129508

A new approach uses data from one type of test on small metal alloy samples to extract enough information for building databases that can be used to predict the properties and potentials of new materials. The details were published in the journal Science and Technology of Advanced Materials: Methods.

The test is called instrumented indentation. It involves driving an indenter tip into a material to probe some of its properties, such as hardness and elastic stiffness. Scientists have been using the data extracted from instrumented indentation to estimate the stress-strain curve of materials using computational simulations.

This curve, and the data it provides, is important for understanding a material's properties. That data is also used for building massive materials databases, which can be used, in conjunction with artificial intelligence, for predicting new materials.

A problem scientists face is that this approach for estimating material properties is limited when it comes to materials called ""high work-hardening alloys"": metal alloys, like steel, that are strengthened through physical processes like rolling and forging. Only so much information can be estimated from the curve of these materials. To get the necessary additional information needed to determine their properties, more experiments would need to be done, which costs time, effort and money.

Ta-Te Chen of the University of Tsukuba and Ikumu Watanabe of the National Institute for Materials Science in Japan have developed a new computational approach to extract that additional information from instrumented indentation tests on work-hardening alloys.

""Our approach builds on an already-existing model, making it ready for use in industry. It is also applicable to existing data, including hardness,"" says Watanabe.

The approach involves combining the results from two computational models, the power-law and linear hardening models, which produce their own individual stress-plastic strain curves from information gathered from indentation tests. Combining the data from both curves provides the extra data that, when added to the original stress-strain curve, shows a more holistic picture of the work-hardening alloys' properties.

The scientists validated their approach by using it on a high-work-hardening stainless steel.

""We have extended this approach to also evaluate mechanical properties at elevated temperatures, which can contribute to the development of high-temperature alloys,"" says Chen.

More information: Ta-Te Chen et al, Data-driven estimation of plastic properties in work-hardening model combining power-law and linear hardening using instrumented indentation test, Science and Technology of Advanced Materials: Methods (2022). DOI: 10.1080/27660400.2022.2129508",artificial intelligence,phys.org
84,The Worldwide Augmented Intelligence Industry is Expected to Reach $54.7 Billion by 2027,https://media.zenfs.com/en/globenewswire.com/f934787b0086d5596dc6e95619a5a0ad,08/11/2022,"Global Augmented Intelligence Market Global Augmented Intelligence Market Dublin, Nov. 08, 2022 (GLOBE NEWSWIRE) -- The ""Augmented Intelligence Market with...",https://finance.yahoo.com/news/worldwide-augmented-intelligence-industry-expected-130800160.html,"Company Logo

Global Augmented Intelligence Market

Global Augmented Intelligence Market

Dublin, Nov. 08, 2022 (GLOBE NEWSWIRE) -- The ""Augmented Intelligence Market with COVID-19 Impact Analysis by Component, Technology (Machine Learning, Natural Language Processing, and Computer Vision), Organization Size, Deployment Mode, Vertical and Region - Global Forecast to 2027"" report has been added to ResearchAndMarkets.com's offering.



The Augmented intelligence market size is projected to grow from USD 17.9 billion in 2022 to USD 54.7 billion in 2027, at a Compound Annual Growth Rate (CAGR) of 25.1% during the forecast period.

The cloud segment to have the highest CAGR during the forecast period



Among deployment type, the cloud segment is estimated to grow with the highest CAGR during the forecast period. The increasing generation of data leads to various challenges for several organizations. These challenges include storage, privacy, and affordability. Most of the augmented intelligence market demands cloud-based solutions as they are cost-effective and easily scalable.



The SMEs segment to hold a higher CAGR during the forecast period



Among the organization size, the large enterprises are projected to dominate the market, while the SMEs segment is projected to record a higher growth rate during the forecast period.

The adoption of Augmented intelligence and services among large enterprises is high as large enterprises use augmented intelligence solutions for specific use cases. They are faced with the troublesome task of effectively managing security because of the diverse nature of IT infrastructure, which is complex in nature.



Among regions, Asia Pacific to hold highest CAGR during the forecast period



Asia Pacific is expected to grow at a good pace during the forecast period. Security spending in Asia Pacific is increasing significantly due to the ever-growing threat landscape.

Traditional methods are no longer adequate for advanced digitalization. Hence, Augmented Intelligence vendors in this region focus on innovations related to their product line. China, Japan, and India have displayed ample growth opportunities in the Augmented Intelligence market.



Key Topics Covered:



1 Introduction



2 Research Methodology



3 Executive Summary

Story continues

4 Premium Insights

4.1 Brief Overview of the Augmented Intelligence Market

4.2 Market: Top Three Verticals

4.3 Market, by Region

4.4 North America: Market, by Technology and Vertical

5 Market Overview and Industry Trends

5.1 Introduction

5.2 Market Dynamics

5.2.1 Drivers

5.2.1.1 Increasing Volume of Complex Business Data

5.2.1.2 Growing Adoption of Advanced Augmented Intelligence and Analytics Tools

5.2.1.3 Adoption and Scaling of Digital Initiatives

5.2.2 Restraints

5.2.2.1 Apprehension About Technologies Replacing Humans

5.2.2.2 Data Security Concerns

5.2.3 Opportunities

5.2.3.1 Increase in Adoption of Artificial Intelligence, Machine Learning, and Natural Language Processing Technologies

5.2.3.2 High Adoption of Augmented Intelligence Solutions Among SMEs

5.2.4 Challenges

5.2.4.1 Integration of Data from Data Silos

5.2.4.2 Ownership and Privacy of Collected Data

5.2.4.3 Lack of Skilled Workforce

5.2.5 Cumulative Growth Analysis

5.3 Augmented Intelligence: Evolution

5.4 Case Study Analysis

5.4.1 Banking, Financial Services, and Insurance

5.4.1.1 Case Study 1: Cognizant's AI and Automation Solution Helps An Insurance Company Improve the Insurance Claims Process

5.4.1.2 Case Study 2: Eiffage Becomes Proactive in Its Financial Management with Tibco Spotfire Software

5.4.2 It & Telecom

5.4.2.1 Case Study 1: Orange Builds a Sustainable Data Practice with the Help of Dataiku

5.4.3 Retail & Consumer Goods

5.4.3.1 Case Study 1: Asos Used Microsoft Azure Ml Service to Reduce Time-To-Market for a Recommendations Model

5.4.4 Energy & Utilities

5.4.4.1 Case Study 1: Intermediate Energy Company Drills Down into Data Insights for Better Performance

5.4.5 Transportation & Logistics

5.4.5.1 Case Study 1: Sisense Allows Air Canada to Extract Meaningful Insights and Has Become An Indispensable Operational Management Tool

5.4.6 Healthcare & Life Sciences

5.4.6.1 Case Study 1: the Company Focuses on Integrating Data to Get a 360-Degree View of Customers, Without Restoring Manual Processes

5.4.6.2 Case Study 2: Inspire Used Ml to Connect Millions of Patients and Caregivers on AWS

5.4.7 Manufacturing

5.4.7.1 Case Study 1: IBM Helped Shenzhen China Star Optoelectronics Technology Co Ltd. (Csot) Boost Production Quality and Throughput

5.4.8 Media & Entertainment

5.4.8.1 Case Study 1: One of the World's Leading Media Conglomerates Adopted Hcl's Augmented Intelligence Solution to Redefine User Experience Through Human-Centric Design

5.4.9 Government & Defense

5.4.9.1 Case Study 1: by Moving to Equinix's Ty3 Facility, Oanda Was Able to Improve this Time by 93%, Providing Its Japanese Customers with Real-Time Access to Its Foreign Exchange Trading Market

5.5 Supply/Value Chain Analysis

5.6 Technology Analysis

5.7 Patent Analysis

5.8 Augmented Intelligence Ecosystem

5.9 Pricing Model Analysis

5.10 Porter's Five Forces Analysis

5.11 Regulatory Implications

5.12 Augmented Intelligence Market: COVID-19 Impact

5.13 Key Conferences & Events in 2022-2023

5.14 Tariff and Regulatory Landscape

5.15 Key Stakeholders & Buying Criteria

6 Augmented Intelligence Market, by Component

6.1 Introduction

6.1.1 COVID-19 Impact on the Market, by Component

6.1.2 Component: Market Drivers

6.2 Software

6.3 Services

7 Augmented Intelligence Market, by Technology

7.1 Introduction

7.1.1 COVID-19 Impact on the Market, by Technology

7.1.2 Technology: Market Drivers

7.2 Machine Learning

7.3 Natural Language Processing

7.4 Computer Vision

7.5 Other Technologies

8 Augmented Intelligence Market, by Deployment Mode

8.1 Introduction

8.1.1 COVID-19 Impact on the Market, by Deployment Mode

8.1.2 Deployment Mode: Market Drivers

8.2 On-Premises

8.3 Cloud

9 Augmented Intelligence Market, by Organization Size

9.1 Introduction

9.1.1 COVID-19 Impact on the Market, by Organization Size

9.1.2 Organizations Size: Market Drivers

9.2 Small and Medium-Sized Enterprises

9.3 Large Enterprises

10 Augmented Intelligence Market, by Vertical

10.1 Introduction

10.1.1 COVID-19 Impact on the Market, by Vertical

10.2 Vertical: Market Drivers

10.3 Banking, Financial Services, and Insurance

10.4 Telecommunications & It

10.5 Retail & Consumer Goods

10.6 Healthcare & Life Sciences

10.7 Government & Defense

10.8 Media & Entertainment

10.9 Manufacturing

10.10 Transportation & Logistics

10.11 Energy & Utilities

10.12 Other Verticals

11 Augmented Intelligence Market, by Region

12 Competitive Landscape

12.1 Overview

12.2 Key Player Strategies

12.3 Revenue Analysis

12.4 Market Share Analysis

12.5 Company Evaluation Quadrant

12.5.1 Stars

12.5.2 Emerging Leaders

12.5.3 Pervasive Players

12.5.4 Participants

12.6 Startup/SME Evaluation Quadrant

12.6.1 Progressive Companies

12.6.2 Responsive Companies

12.6.3 Dynamic Companies

12.6.4 Starting Blocks

12.7 Competitive Benchmarking

12.8 Competitive Scenario

12.8.1 Product Launches

12.8.2 Deals

13 Company Profiles

13.1 Introduction

13.2 Major Players

13.2.1 IBM

13.2.2 Salesforce

13.2.3 Google

13.2.4 Microsoft

13.2.5 SAP

13.2.6 SAS

13.2.7 Cognitivescale

13.2.8 Qliktech International Ab

13.2.9 Tibco

13.2.10 AWS

13.2.11 Neoris

13.2.12 Sisense

13.2.13 Microstrategy

13.2.14 Dataiku

13.3 SMEs and Startups

13.3.1 Cosmo Tech

13.3.2 Jumio

13.3.3 Lucidworks

13.3.4 Squirro

13.3.5 Datarobot

13.3.6 Bondi Labs

13.3.7 Eazyml

13.3.8 Stradigi AI

13.3.9 Aible

13.3.10 Pecan AI

13.3.11 TelliUS

13.3.12 Binah.ai

13.3.13 Augmented Intelligence (Aui)

13.3.14 Pryon

13.3.15 Bioxplor

13.3.16 Causa Lens

14 Adjacent and Related Markets

15 Appendix

For more information about this report visit https://www.researchandmarkets.com/r/760upz

Attachment

CONTACT: CONTACT: ResearchAndMarkets.com Laura Wood,Senior Press Manager press@researchandmarkets.com For E.S.T Office Hours Call 1-917-300-0470 For U.S./ CAN Toll Free Call 1-800-526-8630 For GMT Office Hours Call +353-1-416-8900



",artificial intelligence,yahoo entertainment
85,Ben Bradley: Twitter abuse ‘putting off future MPs',https://media.zenfs.com/en/bbc_us_articles_995/46adb261c4af67ce9eeaf747fd750e6e,09/11/2022,Mansfield's Ben Bradley has the highest proportion of toxic mentions in a major survey of online abuse.,https://finance.yahoo.com/news/ben-bradley-twitter-abuse-putting-120847047.html,"Analysis found 13% of tweets mentioning Ben Bradley were abusive, with more than 2% classed as severe

An MP found to have received the highest proportion of abusive tweets in a BBC survey, said fear of insults and violence put people off public service.

The BBC analysed almost three million tweets where MPs were mentioned over a 12-week period earlier this year.

About 5%, were classed as toxic - being rude or unreasonable - with Mansfield MP Ben Bradley seeing the highest proportion of 13.5%.

Mr Bradley said threats and personal abuse marred an important job.

Ben Bradley said the murder of MP Jo Cox showed online threats could not be discounted

The BBC Shared Data Unit found that overall former Prime Minister Boris Johnson received the most abusive tweets - almost 19,000, or 3.5%, of the total received.

But when adjusted for proportionality, Mr Bradley received the most negative tweets, with 2.1% classed as ""severe"".

He was mentioned in hundreds of toxic-rated tweets after arguing for the privatisation of Channel 4.

The MP, who is also the leader of Nottinghamshire County Council, admitted there were a number of worrying aspects.

""It is frustrating because I can usually overlook people who are just sweary and angry because it doesn't mean a lot,"" he said.

""The ones I find the most upsetting are where people have made a real strong judgement about your character and what you are like having never met you, based on some Twitter things they have read that are often wrong.""

Kidnap threat

He added: ""The worst bit is I often have people say to me 'I wouldn't want to do your job because of all that stuff'.

""But being a Member of Parliament is a huge privilege and should be something that people want to do and aspire to.""

And he emphasised the abuse had real world impacts, which once included threats to kidnap his family.

""I don't think we are going to get out of this social environment where people are mean to each other from the privacy of their keyboard,"" he said.

""But where it does cross the line and what's really, really important is where we have colleagues - David Amess, Jo Cox - who have been killed off the back of that sort of hateful conversation.

Story continues

""It can grow and grow and we need to make sure people are kept safe.""

The BBC's Shared Data Unit used Perspective, a tool that uses artificial intelligence to spot toxic comments online.

Developed by Jigsaw, a research unit within Google, it defines a toxic comment as one which is ""rude, disrespectful or unreasonable"" and ""likely to make someone leave a conversation"".

Analysis also showed all 20 of the MPs receiving the highest proportion of toxic comments were not members of the cabinet or shadow cabinet.

Twitter was unavailable for comment but has previously said it was committed to combatting abuse as outlined in its Hateful Conduct Policy.

Follow BBC East Midlands on Facebook, on Twitter, or on Instagram. Send your story ideas to eastmidsnews@bbc.co.uk.",artificial intelligence,yahoo entertainment
86,"Musk Fires Half of Twitter's Workforce; Rights Orgs Urge Boycott of ""Superspreader of Misinformation""",https://www.democracynow.org/images/story/84/65084/full_hd/seg3-elon.jpg,07/11/2022,"Alarm is growing over how the world’s richest person, Elon Musk, is changing Twitter after he spent $44 billion to buy the influential social media platform. Musk fired nearly half of Twitter’s workforce in a mass layoff Friday that gutted teams dedicated to …",https://www.democracynow.org/2022/11/7/elon_musk_twitter_layoffs_misinformation_civil,"This is viewer supported news. Please do your part today.
Donate
Alarm is growing over how the world’s richest person, Elon Musk, is changing Twitter after he spent $44 billion to buy the influenti… [+972 chars]",artificial intelligence,democracy now!
87,Hayden AI Granted Patent for Safe Sense Traffic Violation Reporting App,https://mms.businesswire.com/media/20221109005175/en/1629970/23/Web_1920_%E2%80%93_1.jpg,09/11/2022,"SAN FRANCISCO--(BUSINESS WIRE)--Hayden AI, a global leader in artificial intelligence and machine learning technologies, has been awarded a patent for technology that collects, analyzes, and verifies user-generated traffic incident reports with artificial int…",https://www.businesswire.com/news/home/20221109005175/en/Hayden-AI-Granted-Patent-for-Safe-Sense-Traffic-Violation-Reporting-App,"SAN FRANCISCO--(BUSINESS WIRE)--Hayden AI, a global leader in artificial intelligence and machine learning technologies, has been awarded a patent for technology that collects, analyzes, and verifies user-generated traffic incident reports with artificial intelligence. The patent was awarded on October 18, 2022 and is labeled U.S. Patent number 11,475,766 B1.

Scaling traffic enforcement significantly enough to change driver behavior has long been a challenge for cities and towns. Hayden AI’s Safe Sense app, which deploys the technological systems and methods protected by this patent, empowers individuals to improve road safety and efficiency by reporting bike lane violations, bus lane violations, and other traffic incidents with their mobile phones.

“User-generated traffic incident reporting can fill a huge gap in traffic enforcement and make streets safer for vulnerable road users, like bicyclists and pedestrians,” said Bo Shen, CTO and Co-Founder of Hayden AI. “But evaluating and verifying a large number of reports is impossible for law enforcement agencies to do manually. Hayden AI’s now-patented solution to this problem makes it possible for civilians to contribute to road safety through incident reporting and for law and parking enforcement and planning agencies to understand where and why most incidents are occurring.”

The Safe Sense app uses artificial intelligence to analyze image evidence, incident types, timestamps, and other attributes of each report to verify if a violation occurred and to identify trends in incidents. This trend analysis allows government agencies to make data-informed decisions to improve road safety and efficiency.

About Hayden AI

At Hayden AI, we’re pioneering real world problem solving powered by AI and machine learning. From bus lane and bus stop enforcement to digital twin modeling and more, our clients use our mobile perception system to speed up transit, make streets safer, and create a more sustainable future. Our privacy first approach ensures that our technologies comply with security and privacy regulations and protect personal information while fostering innovation. For more information about Hayden AI visit www.hayden.ai.",artificial intelligence,business wire
88,Automotive Artificial Intelligence Global Market Report 2022: Growing Demand for Autonomous Vehicles Driving Sector - ResearchAndMarkets.com,https://mms.businesswire.com/media/20221109005835/en/1631458/23/logo.jpg,09/11/2022,"DUBLIN--(BUSINESS WIRE)--The ""Automotive Artificial Intelligence Global Market Report 2022, By Type, By Process, By Technology, By Application"" report has been added to ResearchAndMarkets.com's offering. The global automotive artificial intelligence market is…",https://www.businesswire.com/news/home/20221109005835/en/Automotive-Artificial-Intelligence-Global-Market-Report-2022-Growing-Demand-for-Autonomous-Vehicles-Driving-Sector---ResearchAndMarkets.com,"DUBLIN--(BUSINESS WIRE)--The ""Automotive Artificial Intelligence Global Market Report 2022, By Type, By Process, By Technology, By Application"" report has been added to ResearchAndMarkets.com's offering.

The global automotive artificial intelligence market is expected to grow from $1.42 billion in 2021 to $1.98 billion in 2022 at a compound annual growth rate (CAGR) of 39.62%. The growth is mainly due to the companies rearranging their operations and recovering from the COVID-19 impact, which had earlier led to restrictive containment measures involving social distancing, remote working, and the closure of commercial activities that resulted in operational challenges. The market is expected to reach $7.78 billion in 2026 at a CAGR of 40.79%.

The main types of automotive artificial intelligence include automotive drive and ADAS. The different process of automotive artificial intelligence includes signal recognition, image recognition, and data mining. The different technologies used in automotive artificial intelligence include deep learning, machine learning, context awareness, computer vision, and natural language processing. The automotive artificial intelligence are used in semi-autonomous driving, autonomous driving and human machine interface.

North America was the largest region in the automotive artificial intelligence market in 2021. Asia Pacific is expected to be the fastest-growing region in the forecast period. The regions covered in this report are Asia-Pacific, Western Europe, Eastern Europe, North America, South America, Middle East and Africa.

The growing demand for autonomous vehicles is expected to propel the growth of the automotive artificial intelligence market. Artificial intelligence has a wide range of applications in the automotive industry. As technology evolves, the automobile industry has taken advantage of new discoveries to provide new ways to make driving more autonomous. Using artificial intelligence to develop self-driving automobiles is one of them. A self-driving car (also known as an autonomous car or driverless car) is a vehicle that travels to locations without the need for a human driver by utilising a variety of sensors, radars, cameras, and artificial intelligence. For instance, according to Deloitte, the global automotive AI market will culminate in a total volume of around $27 billion in 2025. Therefore, a rise in demand for automotive cars drives the growth of automotive artificial intelligence.

Strategic collaborations between companies are a key trend gaining popularity in the automotive artificial intelligence market. Companies providing artificial automotive intelligence are undergoing partnerships and collaboration to develop new technologies and products. For instance, in May 2021, a mobile transportation company based in China and Volvo, an automobile manufacturing company based in Sweden, are involved in a partnership with automatic driving vehicles. Through this partnership, Volvo will provide Didi with XC90 SUVs fitted with steering and brake backup systems.

The vehicles will be the first to use Didi Gemini, the ride-hailing company's new self-driving hardware platform, and will be tested with human safety drivers. In the other partnership, in February 2021, Volkswagen, a German-based automobile manufacturer, and Microsoft, an American multinational technology corporation that produces computer software, consumer electronics, personal computers, and related services, partnered to develop self-driving car software.

Scope

Markets Covered:

1) By Component: Hardware; Software; Service

2) By Type: Automatic Drive; ADAS

3) By Process: Signal Recognition; Image Recognition; Data Mining

4) By Technology: Deep Learning; Machine Learning; Context Awareness; Computer Vision; Natural Language Processing

5) By Application: Semi-Automatic; Human Machine Interface; Autonomous Driving

Key Topics Covered:

1. Executive Summary

2. Automotive Artificial Intelligence Market Characteristics

3. Automotive Artificial Intelligence Market Trends And Strategies

4. Impact Of COVID-19 On Automotive Artificial Intelligence

5. Automotive Artificial Intelligence Market Size And Growth

6. Automotive Artificial Intelligence Market Segmentation

7. Automotive Artificial Intelligence Market Regional And Country Analysis

8. Asia-Pacific Automotive Artificial Intelligence Market

9. China Automotive Artificial Intelligence Market

10. India Automotive Artificial Intelligence Market

11. Japan Automotive Artificial Intelligence Market

12. Australia Automotive Artificial Intelligence Market

13. Indonesia Automotive Artificial Intelligence Market

14. South Korea Automotive Artificial Intelligence Market

15. Western Europe Automotive Artificial Intelligence Market

16. UK Automotive Artificial Intelligence Market

17. Germany Automotive Artificial Intelligence Market

18. France Automotive Artificial Intelligence Market

19. Eastern Europe Automotive Artificial Intelligence Market

20. Russia Automotive Artificial Intelligence Market

21. North America Automotive Artificial Intelligence Market

22. USA Automotive Artificial Intelligence Market

23. South America Automotive Artificial Intelligence Market

24. Brazil Automotive Artificial Intelligence Market

25. Middle East Automotive Artificial Intelligence Market

26. Africa Automotive Artificial Intelligence Market

27. Automotive Artificial Intelligence Market Competitive Landscape And Company Profiles

28. Key Mergers And Acquisitions In The Automotive Artificial Intelligence Market

29. Automotive Artificial Intelligence Market Future Outlook and Potential Analysis

30. Appendix

Companies Mentioned

DiDi Chuxing Technology

Otto Motors

Waymo LLC

Microsoft Corporation

Intel Coroporation

NVIDIA Corporation

BMW AG

IBM Corporation

Harman International Industries Inc.

Xilinx Inc.

Qualcomm Inc.

Tesla Inc.

Volvo Car Corporation

Micron Technology, Inc.

Toyota

Uber Technologies

For more information about this report visit https://www.researchandmarkets.com/r/zhcn6s",artificial intelligence,business wire
89,Lantern Pharma Reports Third Quarter 2022 Financial Results and Operational Highlights,https://mms.businesswire.com/media/20221107005752/en/1627594/23/Lantern_Logo_Stacked.jpg,07/11/2022,"DALLAS--(BUSINESS WIRE)---- $LTRN--Lantern Pharma Inc. (NASDAQ: LTRN), a clinical stage biopharmaceutical company using its proprietary RADR® artificial intelligence (""A.I."") and machine learning (“M.L.”) platform to transform the cost, pace, and timeline of …",https://www.businesswire.com/news/home/20221107005752/en/Lantern-Pharma-Reports-Third-Quarter-2022-Financial-Results-and-Operational-Highlights,"DALLAS--(BUSINESS WIRE)--Lantern Pharma Inc. (NASDAQ: LTRN), a clinical stage biopharmaceutical company using its proprietary RADR® artificial intelligence (""A.I."") and machine learning (“M.L.”) platform to transform the cost, pace, and timeline of oncology drug discovery and development, today announced operational highlights and financial results for the third quarter ended September 30, 2022.

“ Leveraging large scale biomarker and clinical data, machine learning and artificial intelligence to fundamentally transform the cost, timeline and risk in developing oncology medicines has been the focus of Lantern. We are now advancing two drug-candidates in the Phase 2 clinical stage, and expect to launch two additional drug-candidates into first in human clinical trials in early 2023. We have rapidly advanced our new drug-candidates, LP-184 and LP-284, and been focused on advancing our rescued drug-candidates, LP-100 and LP-300 towards precise and meaningful treatment indications. Also, we have several additional therapeutic programs that we expect to introduce in the coming quarters with both our existing molecules and with new molecules and combinations that we have been validating with both AI-guided development and in highly targeted wet-lab studies,” stated Panna Sharma, CEO and President of Lantern Pharma.

“ The compression of costs and timeline, that we are creating with our drug development process, have allowed us to grow our portfolio from 3 programs 15 months ago to 11 programs today. We expect many of these programs to create high-value opportunities for our investors and potentially life-transforming therapies for patients,” continued Sharma.

Portfolio Highlights:

LP-300 – Harmonic™ is a Phase 2 clinical trial for never smoker patients with relapsed NSCLC and will assess the effect of LP-300 in combination with standard-of-care (SOC) chemotherapy, pemetrexed and carboplatin, on patient overall and progression-free survival. This quarter Northwest Oncology and Hematology and Gabrail Cancer Center were activated as Harmonic™’s first two clinical trial sites. Both sites are in the process of screening patients and are targeting to enroll the first patients this quarter. Several additional trial sites across the US are expected to be activated in Q4 2022 and Q1 2023 and will bolster patient recruitment and enrollment. Additional trial information on the Harmonic™ trial can be found at the new Harmonic™ website and the clinicaltrials.gov website.



The United States Patent and Trademark Office (USPTO) issued U.S. Patent No. 11,471,431 for LP-300 uses, extending commercial protection for uses of LP-300 until late 2032. The patent is directed at increasing the survival time of cancer patients receiving LP-300 for cancers that are marked by overexpression of the regulatory proteins thioredoxin (TRX) or glutaredoxin (GRX) and/or exhibition of TRX- or GRX-mediated resistance to one or more chemotherapeutic interventions. Lantern’s current patent estate for LP-300 includes 43 patents, covering 8 patent families. Additionally, Lantern has multiple additional pending patent applications relating to LP-300 and is continuing to file patent applications in this area. The strengthened patent estate relating to LP-300 will stimulate the opportunity for future partnering discussions with biopharma companies.



LP-184 – The completion of IND enabling studies and the submission of the IND application to the US Food and Drug Administration (FDA) are anticipated for Q1 2023. LP-184 is under development for two major classes of cancers: solid tumors, including genetically defined pancreatic and bladder cancers, and several central nervous system (CNS) cancers, including glioblastoma (GBM) and brain metastases (brain mets.). Based on the differences in clinical needs and SOC for these cancer classes, two separate Phase 1 clinical trials are planned for LP-184 and are anticipated to launch in Q2 2023. In the US, the stand-alone market potential of these programs is estimated to be $5.0 billion for CNS cancers and over $1.0 billion for solid tumors.



In addition to LP-184’s adult cancer programs, LP-184 is also being developed for several rare pediatric cancers, including Atypical Teratoid Rhabdoid Tumors (ATRT), a highly aggressive and malignant pediatric CNS cancer with no existing SOC therapy. Lantern is in discussions with ATRT key opinion leaders (KOLs) about a pediatric trial design for a potential Phase 1 clinical trial.



Lantern presented new preclinical data at the American Association for Cancer Research (AACR) Special Conference for Pancreatic Cancer in collaboration with Igor Astsaturov, M.D., Ph.D. from The Marvin and Concetta Greenberg Pancreatic Cancer Institute at Fox Chase Cancer Center. The presentation highlighted results demonstrating that LP-184 has potent anti-tumor effects in pancreatic cancer mouse models harboring mutations in the DNA damage response genes ATR and BRCA1. Additionally, LP-184 was demonstrated to act synergistically in vitro and in vivo with several SOC agents including spironolactone and radiation therapy. These combined results exemplify the potential for LP-184 as a therapeutic agent for pancreatic cancer as a monotherapy or in combination with other approved therapies. The LP-184 AACR poster can be viewed on Lantern’s website.



LP-284 – The IND enabling studies for LP-284 are estimated to be completed in Q1 2023, with the IND filing to the US FDA and Phase 1 clinical trial launch anticipated for Q2 2023. Lantern is developing LP-284 for non-Hodgkin’s B-cell lymphomas (NHL), where LP-284 has shown nanomolar potency across multiple in vitro and in vivo studies and where there is a demonstrated clinical need. NHL indications for LP-284 are targeted to include: Mantle Cell Lymphoma (MCL), Double Hit Lymphoma (DHL), and other NHL cancer subtypes. Globally, MCL and DHL alone are estimated to impact over 45,000 patients each year, with virtually all patients relapsing 2-5 years after treatment. There is a significant clinical need for additional late stage therapeutic options for these patients.



At the Society of Hematology and Oncology (SOHO) annual meeting, Lantern scientists presented new research on LP-284 for NHLs. The poster presentation featured results demonstrating that LP-284 has nanomolar anti-tumor potency in several MCL cell lines, including those that are resistant to SOC agents Ibrutinib and Bortezomib. LP-284’s anti-tumor efficacy in MCL SOC resistant cell lines supports its potential for patients who relapse or are resistant to these agents. The LP-284 SOHO poster can be viewed on Lantern’s website.



RADR® Platform Growth and Development:

RADR®, Lantern’s A.I and M.L. platform, continues to rapidly expand its oncology focused datapoints, at a pace well ahead of our year end goal. RADR®’s data growth has advanced concurrently with significant upgrades to its functionality, computational infrastructure, and library of 200+ advanced machine learning algorithms, all of which continue to markedly accelerate and de-risk the drug programs of Lantern and its collaborators.

The RADR® collaboration between Lantern and Actuate Therapeutics is advancing for the development of Actuate’s drug candidate elraglusib (formerly 9-ING-41). RADR®-aided insights have accelerated development initiatives for elraglusib including identification of candidate biomarkers and development of M.L. models for clinical response. Highlights from the ongoing success of this collaboration are planned to be shared in an upcoming webinar.

Novel RADR®-driven research was recently published and provides foundational insights into how A.I. can be applied to discover new indications for cancer drugs in record times and at significantly reduced costs. The research was done in collaboration with the National Cancer Institute (NCI) and highlights how large scale biological data, A.I., and M.L. were leveraged to rapidly identify ATRT as an indication for LP-184. A PDF of the new publication can be downloaded here, or read online on the Frontiers in Drug Discovery website.

Scientific Collaborations Update:

Lantern and Johns Hopkins University extended their productive research collaboration until the second half 2023. The collaboration will continue to facilitate future work for Lantern’s drug candidates for GBM and other CNS cancers.

In December, Lantern will host a KOL webinar on synthetic lethality, a key mechanism of action of Lantern’s drug candidates LP-184, LP-284, and LP-100. The webinar will feature an internationally recognized expert in synthetic lethality, Zoltan Szallasi, M.D., who serves joint appointments as principal investigator at The Danish Cancer Research Center and as assistant professor of pediatrics at Boston Children’s Hospital, a Harvard Medical School affiliate. Additional details about the KOL webinar will be announced in the coming weeks.

During Childhood Cancer Awareness Month in September, Lantern hosted a KOL webinar featuring Dr. Peter Houghton, Ph.D., a leading expert in childhood cancers at the Greehey Children's Cancer Research Institute at the University of Texas Health Science Center - San Antonio. The webinar focused on challenges in drug development for pediatric cancers and preliminary results from Lantern’s drug candidates in preclinical pediatric cancer models. A replay of the KOL webinar can be found here.

Third Quarter 2022 Financial Overview

Balance Sheet: Cash, cash equivalents, and marketable securities were approximately $57.8 million as of September 30, 2022, compared to approximately $70.7 million as of December 31, 2021. The quarterly cash burn rate continues to reflect our capital-efficient, collaborator-centered business model.

R&D Expenses: Research and development expenses were approximately $0.7 million for the quarter ended September 30, 2022 compared to approximately $2.96 million for the quarter ended September 30, 2021.



A substantial portion of this decrease in expenses relates to a $935,000 payment we received in July 2022 from one of our service providers in connection with the resolution of a difference of views regarding the service provider agreement. This payment contributed to an approximately $1,555,000 reduction in product candidate manufacturing related expenses during the three months ended September 30, 2022. In addition, we made a $1,000,000 upfront payment to Allarity Therapeutics during the three months ended September 30, 2021, which is nonrecurring.



G&A Expenses: General and administrative expenses were approximately $1.4 million for the quarter ended September 30, 2022, compared to approximately $1.2 million for the quarter ended September 30, 2021.

Net Loss: Net loss was approximately $2.3 million (or $0.21 per share) for the quarter ended September 30, 2022, compared to a net loss of approximately $4.1 million (or $0.36 per share) for the quarter ended September 30, 2021.

Earnings Call and Webinar Details

Lantern will host its third quarter fiscal year 2022 earnings call and webinar today, Monday, November 7, 2022 at 4:30 p.m. ET.

https://us06web.zoom.us/webinar/register/3516649838262/WN_xlduE8e8Q_Wm_KgnTUDYVg

Related presentation materials will be accessible at: https://ir.lanternpharma.com

Replay Details

A replay of the Q3 2022 earnings call and webinar will be available at https://ir.lanternpharma.com.

About Lantern Pharma:

Lantern Pharma (NASDAQ: LTRN) is a clinical-stage oncology-focused biopharmaceutical company leveraging its proprietary RADR® A.I. and machine learning platform to discover biomarker signatures that identify patients most likely to respond to its pipeline of genomically-targeted therapeutics. Lantern is currently developing four drug candidates and an ADC program across eleven disclosed tumor targets, including two phase 2 programs. By targeting drugs to patients whose genomic profile identifies them as having the highest probability of benefiting from the drug, Lantern's approach represents the potential to deliver best-in-class outcomes.

Please find more information at:

Website: www.lanternpharma.com

LinkedIn: https://www.linkedin.com/company/lanternpharma/

Twitter: @lanternpharma

Monthly Newsletter: Sign-up here

Forward-looking Statements:

This press release contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements include, among other things, statements relating to: future events or our future financial performance; the potential advantages of our RADR® platform in identifying drug candidates and patient populations that are likely to respond to a drug candidate; our strategic plans to advance the development of our drug candidates and antibody drug conjugate (ADC) development program; estimates regarding the development timing for our drug candidates and ADC development program; expectations and estimates regarding clinical trial timing and patient enrollment; our research and development efforts of our internal drug discovery programs and the utilization of our RADR® platform to streamline the drug development process; our intention to leverage artificial intelligence, machine learning and genomic data to streamline and transform the pace, risk and cost of oncology drug discovery and development and to identify patient populations that would likely respond to a drug candidate; estimates regarding patient populations, potential markets and potential market sizes; sales estimates for our drug candidates and our plans to discover and develop drug candidates and to maximize their commercial potential by advancing such drug candidates ourselves or in collaboration with others. Any statements that are not statements of historical fact (including, without limitation, statements that use words such as ""anticipate,"" ""believe,"" ""contemplate,"" ""could,"" ""estimate,"" ""expect,"" ""intend,"" ""seek,"" ""may,"" ""might,"" ""plan,"" ""potential,"" ""predict,"" ""project,"" ""target,"" ""model,"" ""objective,"" ""aim,"" ""upcoming,"" ""should,"" ""will,"" ""would,"" or the negative of these words or other similar expressions) should be considered forward-looking statements. There are a number of important factors that could cause our actual results to differ materially from those indicated by the forward-looking statements, such as (i) the impact of the COVID-19 pandemic, (ii) the risk that our research and the research of our collaborators may not be successful, (iii) the risk that none of our product candidates has received FDA marketing approval, and we may not be able to successfully initiate, conduct, or conclude clinical testing for or obtain marketing approval for our product candidates, (iv) the risk that no drug product based on our proprietary RADR® A.I. platform has received FDA marketing approval or otherwise been incorporated into a commercial product, and (v) those other factors set forth in the Risk Factors section in our Annual Report on Form 10-K for the year ended December 31, 2021, filed with the Securities and Exchange Commission on March 10, 2022. You may access our Annual Report on Form 10-K for the year ended December 31, 2021 under the investor SEC filings tab of our website at www.lanternpharma.com or on the SEC's website at www.sec.gov. Given these risks and uncertainties, we can give no assurances that our forward-looking statements will prove to be accurate, or that any other results or events projected or contemplated by our forward-looking statements will in fact occur, and we caution investors not to place undue reliance on these statements. All forward-looking statements in this press release represent our judgment as of the date hereof, and, except as otherwise required by law, we disclaim any obligation to update any forward-looking statements to conform the statement to actual results or changes in our expectations.

Lantern Pharma Disclosure Channels to Disseminate Information:

Lantern Pharma’s investors and others should note that we announce material information to the public about our company and its technologies, clinical developments, licensing matters and other matters through a variety of means, including Lantern Pharma’s website, press releases, SEC filings, digital newsletters and social media, in order to achieve broad, non-exclusionary distribution of information to the public. We encourage our investors and others to review the information we make public in the locations above as such information could be deemed to be material information. Please note that this list may be updated from time to time.",artificial intelligence,business wire
90,"Midjourney 4 Released, Marking New Step Forward For AI Art",https://i.kym-cdn.com/news/posts/original/000/002/782/midjourney.jpg,07/11/2022,"The newest update to the artificial intelligence art system adds more depth and nuance, and social media is already sharing its latest wild creations from the generator.",https://knowyourmeme.com/news/midjourney-4-released-marking-new-step-forward-for-ai-art,,artificial intelligence,knowyourmeme.com
91,Gore announces fossil fuel emissions inventory at UN summit,https://scx2.b-cdn.net/gfx/news/hires/2022/gore-announces-fossil.jpg,09/11/2022,A detailed inventory of the top known sources of greenhouse gas emitters launched by former U.S. Vice President Al Gore at the U.N. climate summit in Egypt on Wednesday found that the top 14 individual polluters are all gas and oil fields and their associated…,https://phys.org/news/2022-11-gore-fossil-fuel-emissions-summit.html,"Former U.S. Vice President Al Gore speaks during a session at the COP27 U.N. Climate Summit, Wednesday, Nov. 9, 2022, in Sharm el-Sheikh, Egypt. Credit: AP Photo/Peter Dejong

A detailed inventory of the top known sources of greenhouse gas emitters launched by former U.S. Vice President Al Gore at the U.N. climate summit in Egypt on Wednesday found that the top 14 individual polluters are all gas and oil fields and their associated facilities, despite their emissions being ""significantly underreported.""

The inventory was compiled by Climate TRACE, a coalition of researchers, data analysts and non-governmental organizations who use multiple open sources including satellite coverage, remote sensing and artificial intelligence to track who exactly is polluting, and how much.

Emissions stemming from oil and gas production were already estimated to be about double what was reported to the U.N. last year and new data on methane leaks and flaring suggests that emissions are likely three times higher than what was reported, Gore said. Methane is a greenhouse gas which is around 80 times more potent in the short term than carbon dioxide.

Gore said the data shows the extent of the ""deep cut in greenhouse gas pollution we need to prevent the most catastrophic impacts of the climate crisis.""

Hailing the launch of the inventory, the U.N. Secretary General said the data was vital to address a problem ""in front of our eyes, but also hidden in plain sight.""

""We have huge emissions gaps, finance gaps, adaptation gaps. But those gaps cannot be effectively addressed without plugging the data gaps. After all, it is impossible to effectively manage and control what we cannot measure,"" Antonio Guterres said.

Some 56 billion tons of greenhouse gas emissions were produced in 2021, and the U.S. Permian Basin was at the top of emitters with with more than 200 million tons, the data said. Russia's Urengoyskoye gas field was second on the list with 152 million tons.

Saudi Arabia, which owns the giant energy company Aramco, produced 900 million tons of emissions from 252 oil and gas assets, the data showed. Egypt, the host of COP27, produces 383 million tons of emissions from 166 assets, with the country's giant offshore Zohr gas field was the top polluter followed by the capital city of Cairo.

Former U.S. Vice President Al Gore speaks during a session at the COP27 U.N. Climate Summit, Wednesday, Nov. 9, 2022, in Sharm el-Sheikh, Egypt. Credit: AP Photo/Peter Dejong

The data showed that power plants were responsible for just over 100 billion tons of emissions, or 26%, followed by manufacturing with around 68 billion tons, or 17%. Fossil fuel operations were responsible for around 65 billion tons of emissions.

Speaking to the plenary, U.N. Secretary-General António Guterres called the data a ""critical source"" of information that would help in fighting climate change.

""The problem is even greater than we were led to believe and that means we must work even harder to accelerate the phase out of all fossil fuels,"" he said.

Addressing Climate TRACE, he said: ""You are making it more difficult to greenwash or—to be more clear—to cheat.""

Gavin McCormick, a co-founder of Climate TRACE, said they estimated greenhouse gas emissions of nearly all the largest emitters globally.

McCormick added that climate negotiators and others working to combat climate change have described the data as ""a game changer that can help them make better decisions and decarbonize faster.""

The inventory was released as climate negotiators are convening in Sharm el-Sheikh in Egypt for two weeks to look for ways to implement global climate goals. The conference focuses on several prickly issues, including how to cut greenhouse gas emissions and boost finance for poor countries struggling with the impacts of climate change.

Al Gore said the world could reduce emissions by 50% by the end of this decade, and reach net zero by 2050, with the help of now-available technologies.

""We are capable of solving this crisis because once the world reaches true net-zero, temperatures will stop increasing in as little as three to five years,"" he said.

© 2022 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed without permission.",artificial intelligence,phys.org
92,"Inuvo to Host Third Quarter 2022 Financial Results Conference Call on Tuesday, November 15th at 10:00 A.M. ET",https://s.yimg.com/ny/api/res/1.2/N6.a6fZXj3Sclc8SyQ41wA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD0zNDA-/https://media.zenfs.com/en/globenewswire.com/ed12be34f5ac501d7f1f112b55eab7c0,09/11/2022,"LITTLE ROCK, Ark., Nov. 09, 2022 (GLOBE NEWSWIRE) -- Inuvo, Inc. (NYSE American: INUV), a leading provider of marketing technology, powered by artificial...",https://finance.yahoo.com/news/inuvo-host-third-quarter-2022-133000443.html,"Inuvo Inc.

LITTLE ROCK, Ark., Nov. 09, 2022 (GLOBE NEWSWIRE) -- Inuvo, Inc. (NYSE American: INUV), a leading provider of marketing technology, powered by artificial intelligence (AI) that serves brands and agencies, will host a conference call on Tuesday, November 15, 2022 at 10:00 a.m. Eastern Time (ET) to discuss its financial results for the third quarter ended September 30, 2022 and provide a business update.

Conference Call Details:

Date: Tuesday, November 15, 2022

Time: 10:00 a.m. Eastern Time

Toll-free Dial-in Number: 1-800-239-9838

International Dial-in Number: 1-323-794-2551

Conference ID: 8796372

Webcast Link: HERE

A telephone replay will be available through Tuesday, November 29, 2022. To access the replay, please dial 1-844-512-2921 (domestic) or 1-412-317-6671 (international). At the system prompt, please enter the code 8796372 followed by the # sign. You will then be prompted for your name, company, and phone number. Playback will then automatically begin.

About Inuvo

Inuvo®, Inc. (NYSE American: INUV) is a market leader in Artificial Intelligence built for advertising. Its IntentKey AI solution is a first-of-its-kind proprietary and patented technology capable of identifying and actioning to the reasons why consumers are interested in products, services, or brands, not who those consumers are. To learn more, visit www.inuvo.com or follow us on Twitter.

Safe Harbor / Forward-Looking Statements

This press release contains “forward-looking statements” within the meaning of the Private Securities Litigation Reform Act of 1995. These forward-looking statements are subject to risks and uncertainties that may cause actual results to differ materially, including, without limitation risks detailed from time to time in our filings with the Securities and Exchange Commission (the “SEC”), and represent our views only as of the date they are made and should not be relied upon as representing our views as of any subsequent date. You are urged to carefully review and consider any cautionary statements and other disclosures, including the statements made under the heading ""Risk Factors"" in Inuvo, Inc.'s Annual Report on Form 10-K for the fiscal year ended December 31, 2021 as filed on March 17, 2022, our Quarterly Reports on Form 10-Q, and our other filings with the SEC. Additionally, forward looking statements are subject to certain risks, trends, and uncertainties including the continued impact of Covid-19 on Inuvo’s business and operations. Inuvo cannot provide assurances that the assumptions upon which these forward-looking statements are based will prove to have been correct. Should one of these risks materialize, or should underlying assumptions prove incorrect, actual results may vary materially from those expressed or implied in any forward-looking statements, and investors are cautioned not to place undue reliance on these forward-looking statements, which are current only as of this date. Inuvo does not intend to update or revise any forward-looking statements made herein or any other forward-looking statements as a result of new information, future events or otherwise. Inuvo further expressly disclaims any written or oral statements made by a third party regarding the subject matter of this press release. The information, which appears on our websites and our social media platforms is not part of this press release.

Story continues

Inuvo Company Contact:

Wally Ruiz

Chief Financial Officer

Tel (501) 205-8397

wallace.ruiz@inuvo.com

Investor Relations:

David Waldman / Natalya Rudman

Crescendo Communications, LLC

Tel: (212) 671-1020

inuv@crescendo-ir.com



",artificial intelligence,yahoo entertainment
93,5 New Search Opportunities B2B Marketers Need To Know In 2023,https://www.toprankblog.com/wp-content/uploads/5-new-b2b-search-opportunities-imageA600w.jpg,09/11/2022,"What do B2B marketers need to know about search in 2023?
B2B marketing and search have always had a complex relationship, and 2023 will undoubtedly see new shifts arise in numerous areas, from how search engines deal with human versus artificial intelligence …",https://www.toprankblog.com/2022/11/5-new-search-opportunities-for-b2b-marketers-in-2023/,"What do B2B marketers need to know about search in 2023?

B2B marketing and search have always had a complex relationship, and 2023 will undoubtedly see new shifts arise in numerous areas, from how search engines deal with human versus artificial intelligence (AI)-generated content, to indexing a partially or fully-siloed metaverse, combating dwindling organic search opportunities, where to best invest paid search advertising dollars, and key SEO fine tuning challenges.

Let’s turn our attention to each of these five areas of search in B2B marketing, and take a look at the changes marketers will need to adapt to in 2023 and beyond.

1 — How Will Search Engines Deal With More AI-Generated Content?

One algorithm at a time, AI has continued to play an increasingly sizable role in our lives, and search technology is one of the areas at the forefront when it comes to using and iterating on it.

B2B marketers certainly find AI in search and a growing number of areas — not only search — as I recently explored in “Riding The Razor’s Edge of AI in B2B Marketing.”

There’s been a proliferation of AI-generated content, from AI-powered image generation applications including DALL-E, Meta AI’s Make-A-Scene, Stability AI, and the like, to AI writing tools such as Jasper.ai, Writesonic, Article Forge, Ink, WordAI and a growing cadre of others.

These AI content creation tools can produce fully automated content with very minimal human input, however most are still used to augment and fine-tune content produced by a human hand.

How are search engines dealing with the proliferation of AI-generated and AI-augmented content, and do people want to be able to identify or even filter out such content?

Danny Sullivan, public liaison for search at Google, has urged creators to focus on content that is primarily crafted by people and not AI.

“If you’re an SEO trying to figure out how AI fits in with being successful or not on Google, you’re too focused on the tool not the content,” Sullivan recently tweeted. “Is the content you’re producing helpful, reliable and people-first in nature?” he added, referencing Google Search Central’s guide to “Creating helpful, reliable, people-first content.”

One of the bigger challenges search technology faces is how to handle this type of content. Just as AI can create content, to some extent it can also help identify AI-augmented writing, images, and video.

In 2023 the amount of content touched by or entirely created through the use of AI will continue to explode, and it remains to be seen whether this will create a backlash among consumers, or whether AI-generated content will forever battle it out against human-created efforts, with the best-answer content rising to the top regardless of whether it was created by a computer program.

The combination of AI and search will certainly continue to evolve in 2023, as technologies such as neural search-as-a-service and others mature and expand.

Stock photography giant Getty Images recently announced that it was taking a stand against AI-generated imagery, due to the unsettled nature of the myriad copyright laws that protect stock photos and the artists who created them.

Another player in the stock photography business has taken a different approach altogether to AI-generated images, as Shutterstock announced an expanded partnership with OpenAI, that will see Shutterstock offering AI image generation from natural language text prompts.

The expanded Shutterstock partnership with OpenAI will use the DALL-E application programming interface (API), and even allow its users to manipulate certain existing images within its massive database, while also implementing a new framework to provide compensation to the photographers and artists who have played a part in helping develop the AI models.

It remains to be seen how search technology in the B2B landscape will handle ever-greater amounts of AI-generated content, however the vastly different approaches taken by the search functionality of Getty and Shutterstock show that this issue has only just begun bubbling to the surface.

2 — How Will Search Technology Index The Metaverse?

The metaverse — a term coined in a 1992 novel — isn’t quite done cooking yet, but with a world that needs to eat right now and chefs who need to cook, how will search technology adapt to indexing the metaverse, and how will this affect B2B brands?

A primary danger the metaverse faces is falling into the siloed social media platform trap, with walled gardens of innumerable metaverse-like instances each owned by separate entities and all not being able to — whether on purpose or otherwise — talk to one another, or even willfully trying to prevent people from leaving their particular slice of metaverse pie.

I explored this danger in detail in “5 Timely Ways B2B Brands Can Conquer Metaverse Marketing,” as well as some of the powerful opportunities the metaverse holds for B2B brands.

In 2023, search technology will increasingly be faced with indexing a partially or fully-siloed metaverse. Luckily, search itself seems more than up to the task, however the primary obstacles include the formation of a cohesive and unified metaverse, with each player allowing their portion to be indexed by traditional search engines such as Google and Bing, or forthcoming metaverse-specific search engines such as Hyperpeach or Nvidia’s DeepSearch.

3 — How Can B2B Marketers Combat Dwindling Organic Search Opportunities?

When I first went online in 1984 operating a 300-baud bulletin board system, it would be six years before Archie’s FTP site search arrived in 1990, followed three years later by Excite and the other early web search engine innovators, and if there’s one aspect of search and SEO that has remained constant throughout the ensuing decades, it’s been unending change.

The years and decades have also seen dwindling organic search opportunities, accompanied by rising search engine screen real estate dedicated to all manner of paid search placements.

As we’ll look at, there are thankfully still a plenty of viable ways for B2B marketers to overcome diminished organic search visibility — through SEO, content marketing and B2B influencer marketing, to name just a few.

Despite fewer organic entries appearing on today’s search engine result pages (SERPs), marketers can make the most of them by continuing to implement SEO best practices, and by making sure that B2B brands are visible on social media platforms including LinkedIn* and an ever-growing number of others.

4 — Where Should B2B Marketers Invest Paid Search Advertising Dollars?

In light of the dwindling organic search opportunities we’ve mentioned, there’s no denying that B2B brands that are able to dedicate budgets to paid search advertising do often gain increased findability in search results, however whether this is the best use of marketing dollars is not so clear-cut.

Search advertising is expected to account for 40.6 percent of overall digital ad spending in the U.S. in 2022, up some 1.5 percent from 2021, according to newly-released eMarketer and Insider Intelligence forecast data.

In 2023 B2B content marketing and B2B influencer marketing are both likely to continue vying for the title of the specific marketing tactic offering the greatest bang-for-the-buck, however, despite the growth of paid search spending.

Influence likely holds more value in B2B marketing today than ever before, which is why growing numbers of major B2B brands have turned to influencer marketing, as shown in our comprehensive 59-page 2022 B2B Influencer Marketing Report, rich with survey insights, case studies from B2B brands, predictions from leading marketers, a list of 20 top influencer marketing practitioners from major global B2B brands, and much more.

That doesn’t mean that savvy B2B marketers should ignore the opportunities paid search marketing presents, however with today’s often-restrained marketing budgets, alternative methods can at the very least augment paid search strategy.

5 — Where Should B2B Marketers Focus SEO Efforts In 2023?

When Sir Tim Berners-Lee invented the Web, as we detailed in “Classic Marketing Insights to Celebrate the Internet’s 50th Birthday,” one of his biggest goals was to make it easier for people to find information on the Internet — an ambition that has undoubtedly seen tremendous success perhaps beyond any other technology in history.

I was involved in the SEO industry from the time I accessed early websites in 1993 and then began building them in 1994, until just before I joined TopRank Marketing in 2018, after spending a decade as lead editor at search conference Pubcon. During those 25 years I witnessed vast changes in the search industry, including the rise and eventual mainstreaming of SEO.

SEO however isn’t a standardized practice with oversight by an administrative body, but rather a living and breathing practice that’s evolved in the back-and-forth between search engine firms and the webmasters, marketers, programmers, and others who have for decades kept SEO in a constant swirling sea of activity and change. Sometimes this sea is murky and tumultuous, and at others — at least for a brief while — clear and calm.

Where SEO shifts in 2023 will likely involve some of the areas we’ve touched on, and others yet to surface.

Certain SEO fundamentals remain, thankfully. When putting SEO to use in B2B marketing, there are a few elements to make note of when it comes to your efforts:

Some elements of SEO are ever-changing and require ongoing attention

Build smart SEO efforts into routine work

Utilize process checklists to operationalize efforts

Stay up-to-date on search industry changes

Part of what makes SEO and search compelling is that they are always changing, even as certain fundamental aspects remain the same.

“Search is never guaranteed, and there are tons of sites that are trying to push their updates into Google,” John Mueller, webmaster trends analyst at Google recently observed. “I think what ultimately works best is that you prove to Google — and users — that the updates you’re providing are valuable: unique, compelling, high-quality, and not something that’s already published elsewhere,” Mueller added.

Adjust & Benefit From An Energized 2023 B2B Search Strategy

via GIPHY

Whether you pursue one or all of the areas of search we’ve explored here in 2023, we hope that these insights will energize your own B2B marketing efforts on the search front.

2023 will be a fascinating year as B2B marketers see how search technology ends up dealing with AI-generated content, indexing the metaverse, combating dwindling organic search opportunities, paid search strategy, and continuing SEO challenges and opportunities.

More than ever, crafting award-winning B2B marketing that elevates, gives voice to talent, and humanizes with authenticity takes considerable time and effort, which is why more brands are choosing to work with a top digital marketing agency such as TopRank Marketing. Reach out to learn how we can help, as we’ve done for over 20 years for businesses ranging from LinkedIn, Dell and 3M to Adobe, Oracle, monday.com and many others.

*LinkedIn is a TopRank Marketing client.",artificial intelligence,toprankblog.com
94,Capture One Pro 23 Adds Smart Adjustments and New Workflow Tools,https://petapixel.com/assets/uploads/2022/11/Capture-One-Pro-23-Adds-New-Smart-Adjustments-and-Workflow-Enhancements.jpg,08/11/2022,"Capture One has announced Version 23 and says it gives users a much faster and more efficient workflow by reducing culling and editing time as well as more power and control when editing and working with layers.
[Read More]",https://petapixel.com/2022/11/08/capture-one-pro-23-adds-smart-adjustments-and-new-workflow-tools/,"Capture One has announced Version 23 and says it gives users a much faster and more efficient workflow by reducing culling and editing time as well as more power and control when editing and working with layers.

The new update introduces a variety of new features and improvements including the ability to cull, rate, tag, and browse images faster with automatic group views, improved control over editing with Layers in Styles, changes to Capture One Live to provide better reviewer management (as well as a free version for a single session at a time), and a new timesaving editing feature called Smart Adjustments which can automatically adjust exposure and white balance to match the look of your reference image across entire sets, massively reducing the need for manual editing or outsourcing.

In addition to these updates, the Capture One Pro 23 (version 16) gas several performance and UX/UI adjustments such as improved performance with Sony files, better exporting performance by leveraging multiple GPUs on certain Windows devices, new “touchpoints” for Capture One Live, the ability to change capture times, and the ability to add variants of an image into separate albums for better organization.

The full list of updates as well as some video demos can be found on the Capture One website, but below are more details on the more significant updates.

Smart Adjustments

Photographers can now leverage a sort of pseudo-artificial intelligence (AI) with their edits with the addition of Smart Adjustments. The company says this new feature will allow users to get consistency with their photo sets with just a few clicks where, once a users sets a reference file (edited the way they like), the smart adjustment will edit the subsequent files to match the exposure and white balance so the files sync up nicely. This includes both increasing and decreasing exposures and checking for skin tones in each file.

According to the company, the Smart Adjustments Tool is designed for editing workflows where copy/apply cannot give a consistent result because the starting points are different. Smart Adjustments can be added in a Style where additional adjustments can be included as well, getting closer to one-click editing. The first version of Smart Adjustments is designed for photographers shooting portraits, weddings, events, and other images of people.

Users can work with Smart Adjustments in two ways. The first by setting a reference file from an image with a visible face and preferred look (edits included) that can then be batch applied to the rest of the images in the set where the white balance or exposures will automatically be adjusted. The second use is by saving the Smart Adjustment reference as a “style” for continuous use as a “smart style.” These smart styles will work just like regular styles in Capture One Pro and can be applied to batches of images even during the import process.

It is worth noting that as of this release, Smart Adjustments are not supported on Layers. The company also says that this first version of Smart Adjustments relies heavily on faces, both for the reference and the images being adjusted. As such, if no faces are present or easily identified in the images, the adjustments will “vary greatly.”

Culling and Importing

Capture One Pro 23 makes sorting and culling faster with new dedicated functionality that was developed specifically with these workflow steps in mind. The company says users can view, rate, tag, and browse nearly immediately with no delay and get an overlay provided of similar groups of images for faster culling and selection. This feature is designed with high-volume shooters in mind to make large jobs go faster and smoother, freeing up the photographer to work on the more enjoyable parts of the process.

Within this improved import and culling screen, users can filter their images, add metadata/notes, and even change the capture time of the files (non-destructively) which can be a huge time saver and headache relief when working with multiple photographers and cameras that may be out of sync or from a different time zone.

The new culling features can be found within the actual Importer Tool or by opening the new “Cull View” if the images are already inside of Capture One. Clicking the cull view will open the tool and will show the selected collection of images only, allowing for faster grouping, previewing, and additional culling of files.

Layers in Styles, Capture One Live, and General Improvements

The improvements to Styles will allow Capture One Users to include layers when saving their own custom styles, expanding and offering a more efficient and flexible workflow for creatives by allowing quick edit applications that include multiple layers with predefined opacity. While masks can be saved, it is worth noting that if a layer includes a manually brushed mask, the layer mask will save but will be empty, additionally, heal, clone, luma range and gradient layers are not currently supported.

Capture One Live updates bring some impressive and useful enhancements that include managing who can access the online sharing session and what they can do through a new “Manage” option that is available for each session. The company says this will open a new window where you can manage the reviewers, change their access level between none at all, “can view” and “can rate, tag, and comment” allowing for much more control and faster collaboration between remote viewers.

Finally, in addition to all the above updates, Capture One Pro 23 adds more control over variants in albums where these clones can be put into separate albums without the others or original files being added. Also, Sony files will now load faster from the disk (this will of course vary from system to system) especially noticeable when working from a network disk, and exporting files on certain Windows-based machines will be up to 100% faster by leveraging multiple GPUs.

The Capture One Pro 23 update is available now for all users on perpetual or subscription licenses.

Image credits: Capture One",artificial intelligence,petapixel
95,These 3 Dow Stocks Are Set to Soar in 2022's Second Half and Beyond,https://g.foolcdn.com/editorial/images/708262/rocket-growing-graph-pink.jpg,09/11/2022,Never let it be said that the market doesn't sometimes misprice even the best-known of stocks.,https://www.fool.com/investing/2022/11/09/dow-stocks-set-to-soar-in-2022-2nd-half-beyond/,"The overall market is on a less-than-firm footing now. A handful of the blue chip stocks that make up the Dow Jones Industrial Average (^DJI), however, are poised to start reflecting their underlying companies' long-term resilience. Here's a closer look at the three top prospects from this group that you may want to add to your portfolio sooner than later.

1. Boeing

There's no denying Boeing (BA -0.52%) has been through the wringer over the past few years. First, it was the tragic design flaws that led to the grounding of its 737 MAX model. Then, just when it looked like the company might push past that challenge, the COVID-19 pandemic materialized, decimating demand for air travel and severely crimping demand for new aircraft.

The world is easing its way back to normal though, and on average, airlines' fleets are now about four years older than they were when the pandemic caused them to put orders on hold. Their aircraft replacement plans can't be postponed for much longer.

And those purchases aren't being put off anymore. Alaska Airlines just placed its biggest-ever order for Boeing-made planes, Delta recently requested 100 new 737 MAX jets, and United Airlines is reportedly mulling a triple-digit order for new widebody aircraft. Indeed, U.K.-based aerospace industry news outlet ADS reported that in the third quarter, total aircraft orders were the highest they've been since 2015, with Boeing accounting for 256 of them. That brings the company's backlog up to 5,236 passenger jets -- which amounts to years' worth of revenue. For perspective, Boeing delivered a little over 300 aircraft through the first three quarters of the year.

Driving this swell of demand for new aircraft is the post-COVID-19 rebound in air travel. Global consultancy Bain & Company estimates that the worldwide air travel and logistics market will be worth $525 billion this year. That's still shy of 2019's figure of $666 billion, but Bain forecasts that the market should exceed that level next year en route to resuming its pre-pandemic growth pace.

Connect the dots. Boeing's industrywide long-term expectation for the delivery of 41,170 passenger jet deliveries between now and 2041 is anything but out of line. In that light, the stock's 61% pullback from 2019's high to its current price doesn't make much sense.

2. IBM

International Business Machines (IBM -0.72%) may have missed out on some of its initial opportunities to capitalize on things like cloud computing, artificial intelligence, and cybersecurity when those markets were relatively new a decade ago. The company's making up for lost time now, though. Not only does it have strong plays in all of those arenas now, IBM is quickly becoming a powerhouse in hybrid cloud computing, which supports them all.

This success isn't necessarily easy to see in the company's recent quarterly reports. IBM has no specific hybrid cloud business unit, and even if it did, last quarter's top-line growth of 6% was fairly modest.

Dig deeper though, and the picture looks brighter.

IBM's hybrid cloud success isn't well-defined for good reason. The company sells what are largely turn-key solutions to complex technological problems built upon this tech. More than mere platforms, it offers combinations of hardware, software, and consulting that all support one another. As CFO Jim Kavanaugh explained at an investor conference earlier this year, ""when we land a hybrid cloud platform, there's an economic multiplier on top of that, $3 to $5 a software for every dollar of platform we land, $6 to $8 of services for every dollar of platform we land."" Some of IBM's specialties subject to this multiplier model include application management, automation, and the aforementioned cybersecurity and artificial intelligence offerings.

Its growth may still seem a bit muted, but that's to be expected. This business model is still relatively new, as is the underlying hardware and software, and they haven't yet had to chance to reach their full growth potential. They're moving faster than you might think, however. Last quarter's modest 6% growth? If you strip out the adverse impacts of foreign currency fluctuations and the strong dollar, IBM's top line actually grew 15% year over year.

Investors may start pricing in this strength soon too. In fact, the stock's recent rally suggests the market's already starting to figure out all the bullish details.

3. Visa

Credit card company Visa (V -3.68%) is another Dow 30 stock poised to start soaring before the end of the year, and it should continue rising well after 2022 ends.

It's easy to entertain doubts about this particular pick. The global economy isn't exactly firing on all cylinders, and a full-blown recession may be in the cards. Consumers and corporations are expected to clamp down on their spending in such an economic environment.

Except consumers rarely actually clamp down. They certainly haven't done so yet, despite the headwinds we've seen this year so far. Last quarter's revenue was up a hefty 19% year over year for Visa, capping off a 22% increase for the fiscal year ending in September. The total number of transactions the company handled was up 10% for the three-month stretch and higher to the tune of nearly 12% for the year. The year's total transaction figure was a whopping 33% higher than it was in pre-COVID fiscal 2019.

The driving force behind this growth isn't more discretionary spending -- that may well be on the verge of drying up. It's the decreasing use of cash to buy goods and services. The Federal Reserve Bank of San Francisco's most recent look at U.S. consumers' payment preferences indicated that cash was only used to make 20% of 2021's purchases, extending a downward streak that has dialed cash's use back from 31% of purchases in 2017. While the numbers are different overseas, the trend isn't. Don't be surprised to see cards continue to displace cash for the purchases of even the most basic things.

The analyst community clearly remains optimistic about Visa's near-term and distant futures. While its top-line growth is on pace to slow to only 9% this year, sales growth is expected to reaccelerate to more than 12% next year, pulling profits higher with it. This year's weakness in the stock offers investors a great chance to plug into Visa's persistent progress.",artificial intelligence,motley fool
96,Time to curb the data brokers,https://media.nature.com/lw1024/magazine-assets/d41586-022-03578-8/d41586-022-03578-8_23670714.jpg,07/11/2022,Governments should provide for digital public information infrastructure — but how?,https://www.nature.com/articles/d41586-022-03578-8,"Much of modern life depends on data stored and sold by private companies.Credit: Nikada/Getty

Data Cartels: The Companies That Control and Monopolize Our Information Sarah Lamdan Stanford Univ. Press (2022)

Information-technology platforms are ubiquitous in contemporary life. From friendships and genealogy to civic engagement, commercial transactions and charitable works, people rely on networked technologies that enable dialogue, authentication, payment and more. It is difficult to remember our daily lives before smartphones; those who have never known otherwise find those days impossible to imagine.

Sarah Lamdan’s Data Cartels is the latest in the genre of books that critically analyses such platforms, identifies bias, inequities and resultant harms, and asks why these for-profit companies are allowed to operate as they do. Lamdan focuses her attention on information and data brokers. These are relatively unknown, unlike social-media and search-engine companies (the respective targets of the 2018 books Antisocial Media by Siva Vaidhyanathan and Algorithms of Oppression by Safiya Umoja Noble).

Lamdan, a law scholar and librarian, concentrates particularly on RELX and Thomson Reuters, with some ancillary attention to Bloomberg and other commercial publishers. She unpacks their activities in unrelenting detail, examining their products and services across the arenas of data brokering, academic research, legal information, financial data and the news. Lamdan argues that these “perfectly legal” activities harm individuals and society, and erode democracy.

Everyone should decide how their digital data are used — not just tech companies

That this is a story of legal and regulatory failure is clear from the first, and evidenced throughout. The US government’s documented divestment from public media brings into particularly sharp relief how current practices differ from those of the previous century, which regulated radio and television. These days, for example, only around 1% of media organization NPR’s operating funds are contributed directly by the federal government. Congress has failed to enact laws that would constrain companies’ data practices, and the courts have repeatedly weakened protections. Individuals have been left to fend for themselves. Even when they can document mistreatment, there is limited accountability for firms. Data brokers have successfully asserted a free-speech defence in the face of legal action seeking redress for the dissemination of inaccurate information.

Lamdan’s solution is a legal and regulatory regime that treats information and data as public resources and that provides public digital infrastructures. In her vision of a functional information ecosystem, private companies would still operate, but public infrastructure would deliver essential information without the sacrifice of personal privacy. This kind of library-like public digital infrastructure would require considerable resources. Lamdan does not offer any cost estimates. But extrapolating from the more than $470-million annual budget of the US National Library of Medicine, which provides fairly robust public access to health information, it is quickly apparent that the price tag would be multiple billions.

The US track record with legal and financial information is, however, abysmal. Currently, “when the government provides information to the public, it does so with outdated, insufficient online tools and platforms”, Lamdan writes. These pale in comparison to paywalled corporate services. Any researcher using the government platforms PACER or EDGAR to find court records or financial data, respectively, will be frustrated with their limited information search, retrieval and management tools. As she notes, federal, state and local governments comprise a substantial customer base for many of the data brokers’ services.

Incremental reform

Unfortunately, as Lamdan observes, the kind of comprehensive and coordinated legal and regulatory reform that would be required to tackle the problems she has laid out — addressing copyright complexities, re-establishing previously strong antitrust doctrines and closing loopholes in constitutional law — is unlikely. As such, she also identifies a number of incremental changes that would be useful. These include treating data brokers as information fiduciaries and — when governments contract for their services — as state actors bound by constitutional obligations.

The book is replete with observations about how things should be and ideas for what the government could do. But the reader is left wondering why so many bills are introduced but not passed, and so many petitions for investigations filed but not acted on. If multiple attempts have failed, what are the barriers to success and what would it take to overcome them? Little attention is paid to these questions.

Scientists use big data to sway elections and predict riots — welcome to the 1960s

One also wonders why the discussion is almost entirely US-centric. RELX, based in London, and Thomson Reuters, headquartered in Toronto, Canada, are global companies used by researchers around the world. RELX’s information-retrieval system LexisNexis and Thomson Reuters’s research service Westlaw publish laws and related legal documents from many countries. Lamdan mentions in passing that European antitrust legislation focuses on fairness, whereas US laws concentrate on preventing economic harm to consumers. However, there is no vision of how the United States might pursue multilateral action or what might be the role of international organizations in responding to the problems outlined in the book. Is it even possible for the United States to act on its own?

A broader look beyond governmental solutions would have been welcome, too. In addition to the international Free Access to Law Movement, which Lamdan highlights, there are organizations pursuing guidelines and standards (such as the US National Information Standards Organization’s Consensus Principles on Users’ Digital Privacy in Library, Publisher, and Software-Provider Systems) and cross-industry collaborations (one is the Vendor & Library Community of Practice, sponsored by the Intellectual Freedom Committee of the American Library Association).

Don’t ask if artificial intelligence is good or fair, ask how it shifts power

The Institute of Museum and Library Services has awarded numerous grants on this topic. These include support for a project called Library Values & Privacy in the US National Digital Strategies: Field Guides, Convenings, and Conversations, and for a national forum on web privacy and analytics. There are enough library-led initiatives for the 2022 Electronic Resources and Libraries conference to have featured half a dozen in its keynote panel, including my own Licensing Privacy Project, funded by the Andrew W. Mellon Foundation in New York City. Philanthropic efforts such as Research4Life and INASP — both of which help researchers in low- and middle-income countries to access scholarly literature — as well as emerging shareholder and student activism, should not be overlooked.

Having been involved in efforts to raise awareness of the impacts of data brokers over the past decade, I appreciate Lamdan’s hopeful stance that it is not too late to reverse course and create a better world. Her rhetoric is powerful, her writing colourful and her critique vigorous. For those unfamiliar with the vast literature on challenges in the data and information arenas, this book is a useful compilation. Unfortunately, although Lamdan’s vision of what could and should be might inspire, her call to action falls short of offering a clear path forward.",artificial intelligence,nature.com
97,Spot the robot dog to help boost student interest in tech jobs - GSA Business,https://gsabusiness.com/core/files/scbiznews/articles/024aa7381f8a3e0a71de10d305c6280c.jpg,07/11/2022,"See Spot dance!

That was the phrase of the moment Nov. 3 at the S.C. Manufacturing Conference and Expo in Greenville as attendees got...",https://gsabusiness.com/news/technology/82786/,"Technology

See Spot dance!

That was the phrase of the moment Nov. 3 at the S.C. Manufacturing Conference and Expo in Greenville as attendees got to witness the dance moves of a bright yellow robotic dog named Spot who will soon be the face of artificial intelligence for thousands of students around the state.

Spot is part of a new approach to attracting young people to the tech workforce from SC Tech, an initiative of the South Carolina Council on Competitiveness designed to promote information technology and other tech jobs around the state.

The Council sponsored “Artificial Intelligence is a Game Changer,” a lunch event where people got to meet Spot and hear about efforts to get young people interested in learning the cutting-edge technology skills that will be needed by future workers in manufacturing and other industries.

“We’re working hard to get an AI curriculum into all of our schools, and this is going to be a big part of it,” said Kim Christ, director of SC Tech. “South Carolina is the first state that has procured Spot for use as part of an AI curriculum, and we hope this will be a pathway to get more students interested in the technology.”

Spot robots were introduced in 2019 by Boston Dynamics and about 400 are currently in use around the country in a variety of industries from manufacturing to mining. One of the robot canines even explored the volcanic ruins in Pompeii earlier this year, according to a report in Smithsonian Magazine. The robot is useful in situations that could be unsafe or difficult for human workers.

Spot won’t be facing any danger in South Carolina, however. Instead, the robot, which weighs more than 100 pounds, will be visiting school districts around the state beginning next year. Students will learn tech skills that enable them to work with Spot and in the process build an artificial intelligence curriculum centered around the robot.

While Spot might be a hard worker, the dog also has rhythm.

Techno music blared from nearby speakers at the conference and attendees got to see Spot “dance” to the music, following a series of moves programmed by a worker with a nearby laptop. The dog performed a series of gyrations and bends, extended its “neck” to look out over the audience, and even jumped into the air a few times.

Christ said once the robot dog is in the classroom, students will be able to learn how to write programs that will enable them to choreograph entire dances for it.

The name Spot is also not going to stick around long. To kick off the program, SC Tech is going to sponsor a naming contest for the dog at the beginning of the next school year.

Keynote speaker John McElligott told attendees this type of innovative approach to teaching AI technology is more crucial than ever because too many students lack skills to work with technology that is already being used on today’s factory floors and in other industries.

McElligott is founder and CEO of York Exponential, a Pennsylvania-based collaborative robotics and artificial intelligence company. He has been in South Carolina recently working with the Lakelands Emerging Technology Council in Greenwood.

He talks to middle- and high-school students frequently and said one of the most disturbing trends he encounters is a tendency for teenagers as young as 15 to not be open to learning the full spectrum of skills needed for emerging technologies like artificial intelligence.

“Studies show that in the near future, about one-third of the population is going to be unemployable because education and business can’t keep up with the way technology is evolving,” McElligott said. “We have teenagers today that have been told by their parents they were geniuses because they could work a tablet. They’re not. They’ve been told they’re tech-savvy and they’re not. They need to be learning skills to deal with future technology. One of the most important things we can do is make sure people don’t get left behind by it.”

In Greenwood, McElligott recently worked with students to help them use technology to create artwork that was displayed in the area’s first AI high school art contest. He said the key is to not only help students learn the tech skills they need to compete in manufacturing and other industries but also to spark a desire to use technology to enhance human life.

“I’m telling students that in the recent past, Google and Facebook got it wrong with how they used technology because they treated people like data points,” he said. “I want them to be able to use their tech skills to make a difference.”",artificial intelligence,gsa business
98,"iBio looks to exit CDMO business, cut staffing levels by 60% - BioPharma-Reporter.com",https://www.biopharma-reporter.com/var/wrbm_gb_food_pharma/storage/images/publications/pharmaceutical-science/biopharma-reporter.com/headlines/markets-regulations/ibio-looks-to-exit-cdmo-business-cut-staffing-levels-by-60/15921329-1-eng-GB/iBio-looks-to-exit-CDMO-business-cut-staffing-levels-by-60.jpg,08/11/2022,"Texas based, iBio, is divesting its CDMO business and cGMP biologics manufacturing facility. It is also set to reduce its workforce by 60%.",https://www.biopharma-reporter.com/Article/2022/11/08/ibio-looks-to-exit-cdmo-business-cut-staffing-levels-by-60,"The move, it said, will allow it to focus on its immuno-oncology assets; the US player expects the restructuring measures to result in around 50% annualized cost savings.

Offloading its contract development and manufacturing organization (CDMO) assets will enable it to fully “transform into an antibody discovery and development” ​company.

Proceeds and cost-savings from the divestiture of those operations will be invested into its portfolio including, IBIO-101, an immunotherapy for the depletion of regulatory T cells, and two differentiated, antibody candidates emanating from its antibody discovery platform.

The company also intends to continue to develop its artificial intelligence (AI) platform, one of the multiple assets it acquired in September from its AI drug discovery partner RubrYc.

Tom Isett, CEO of iBio, said: “We believe focusing our efforts on drug discovery and development to be the path to greatest value-creation for shareholders, especially given the recent addition of RubrYc Therapeutics’ pipeline and tools to engineer precision-targeting antibodies. Concurrently, given the strong demand for biomanufacturing capacity, we are providing the opportunity for another organization to more fully utilize the advanced bioanalytical and bioprocess capacity resident in our large-scale cGMP biologics production facility located in the growing Southeast Texas ‘Biocorridor’.​

CDMO assets ​

The CDMO assets up for sale include a 130,000 sq. ft [12077.3 sq. m] cGMP facility in Bryan, Texas, which is configurable for a variety of large-scale bioproduction systems and iBio’s proprietary FastPharming Expression System and Glycaneering Technology. iBio expects to complete the transaction in 2023.

In conjunction with the divestment, the company said it has commenced a comprehensive workforce reduction exercise of around 60% of current staffing levels.

Once the job shedding is finalized, it said the company will operate out of the new Drug Discovery Center in San Diego, California, which opened in September.

New CEO ​

It will also begin the search for a new chief executive, claiming there is a need to do so given the announced change in geographic location. Isett, the current CEO, is expected to stay on through this company’s ‘transformation’ phase.",artificial intelligence,biopharma-reporter.com
99,MOMENTUM GLOBAL INVESTMENT MANAGEMENT ANNOUNCES STRATEGIC PARTNERSHIP WITH MDOTM LTD TO DEVELOP ARTIFICIAL INTELLIGENCE (AI) CAPABILITIES AND INSIGHTS-DRIVEN INVESTMENT SOLUTIONS,https://media.zenfs.com/en/prnewswire.com/d0ea8d753a763ae274bcf32387738e04,09/11/2022,"Momentum Global Investment Management (MGIM) has appointed MDOTM Ltd., the global provider of AI-driven investment solutions, as a strategic partner to help ...",https://finance.yahoo.com/news/momentum-global-investment-management-announces-110000142.html,"Artificial Intelligence technology integrated into existing investment processes providing timely, unbiased asset allocation insights

NEW YORK, Nov. 9, 2022 /PRNewswire/ -- Momentum Global Investment Management (MGIM) has appointed MDOTM Ltd., the global provider of AI-driven investment solutions, as a strategic partner to help it develop AI-driven investment insights and triggers that can be integrated into and enhance MGIM's well established outcomes-based investment process.

The focus of the partnership will be to develop AI-enabled multi-asset investment insights, built around MGIM's outcomes-based investment philosophy, to assist and support portfolio manager decisions. The partnership will be developed as a strong collaboration between the expertise of the investment team at MGIM and the AI specialists of MDOTM Ltd, made up of physicists, data scientists and engineers as well as finance professionals.

The AI technology will provide asset allocation insights by analysing millions of data points and identifying new, differentiated information. By being incorporated in the existing investment process, it will help to compensate for natural human biases without losing the human expertise and touch that cannot be replicated by algorithms alone. AI has the ability to analyse and provide highly adaptive forecasts on asset classes' risks and returns, considering a multitude of variables in the environment, to a much larger extent than traditional human analysis can. MGIM believes that AI-enabled insights will support portfolio managers in building more resilient portfolios. MGIM will leverage MDOTM Ltd's predictive indicators to enhance the strategic and tactical asset allocation choices across its portfolio range and adapt them to potential shifts in market conditions.

Ferdi van Heerden, CEO of MGIM said:

""The strategic partnership with MDOTM Ltd is a key step forward for MGIM on our digitalisation journey. The MDOTM and MGIM teams have aligned well, setting out to explore and challenge the status quo. With MDOTM Ltd's experience and reputation in AI, we expect this partnership to further strengthen our investment process. This should help our portfolio managers to navigate an increasingly uncertain and volatile world more confidently, further assisting them in their asset allocation decisions. By integrating AI technology into our processes and decision-making, it will allow us to gain additional unbiased insights that will complement our existing tools and processes.""

Story continues

Tommaso Migliore, CEO and Co-founder of MDOTM Ltd, commented:

""MDOTM Ltd is excited about our partnership with MGIM. With our investment AI expertise and MGIM's global multi-asset investment expertise, we will be able to provide AI-enabled inputs and insights that will enhance investment outcomes for clients. We are proud to be associated with MGIM and look forward to collectively developing AI investment capabilities with them to support and complement their investment teams and global asset allocation decisions.""

For information: info@mdotm.eu

About MGIM

MGIM was established in the UK in 1998 and provides specialist investment management services to institutional clients, financial intermediaries and their clients in the UK and Europe, Asia, Middle East, South America, and South Africa.

MGIM has over £4.5 billion in assets under management and is a wholly owned subsidiary of Momentum Metropolitan Holdings Limited, a large South African insurance and investment business, listed on the Johannesburg Stock Exchange

MGIM Limited (Company Registration No. 3733094) has its registered office at The Rex Building, 62 Queen Street, London EC4R 1EB

MGIM Limited is authorised and regulated by the FCA in the UK, and is exempt from the requirements of section 7(1) of the FAIS 37 of 2002 in South Africa, in terms of the FSCA FAIS Notice 141 of 2021 (published 15 December 2021)

Momentum Global Investment Management

Shelly Durrant / Eva Rana

SEC Newgate UK

MGIM@secnewgate.co.uk

MDOTM Ltd | Media & Communications

Roberto Nido

robertonido@mediaecomunicazione.it

Logo: https://mma.prnewswire.com/media/1921707/MDOTM_Logo.jpg

Logo: https://mma.prnewswire.com/media/1942599/Momentum_Global_Investment_Management_Logo.jpg

Cision

View original content to download multimedia:https://www.prnewswire.com/news-releases/momentum-global-investment-management-announces-strategic-partnership-with-mdotm-ltd-to-develop-artificial-intelligence-ai-capabilities-and-insights-driven-investment-solutions-301672678.html

SOURCE MDOTM",artificial intelligence,yahoo entertainment
